// Meeting Preparation Data: 5 Meeting-Typen mit Checklisten und Fragen

export interface CheckItem {
  id: string;
  label: string;
}

export interface QuestionGroup {
  category: string;
  items: string[];
}

export interface MeetingType {
  id: string;
  name: string;
  emoji: string;
  goal: string;
  description: string;
  participants: string[];
  beforeMeeting: CheckItem[];
  questions: QuestionGroup[];
  redFlags: string[];
  afterMeeting: CheckItem[];
}

export const meetingTypes: MeetingType[] = [
  {
    id: "kickoff",
    name: "Projekt-Kickoff",
    emoji: "ğŸš€",
    goal: "Problem verstehen, Scope definieren, Erwartungen klÃ¤ren",
    description: "Das erste Meeting mit den Stakeholdern â€“ hier wird die Grundlage fÃ¼r das gesamte Projekt gelegt.",
    participants: [
      "Business Stakeholder / Sponsor",
      "Data Scientist / ML Engineer",
      "Product Manager / PM",
      "Optional: Data Engineer, Fachexperte, Legal",
    ],
    beforeMeeting: [
      { id: "k1", label: "Business Owner / Sponsor identifiziert" },
      { id: "k2", label: "Grundlegendes Problem-VerstÃ¤ndnis (aus Vorab-Infos)" },
      { id: "k3", label: "Teilnehmer und ihre Rollen bekannt" },
      { id: "k4", label: "Agenda vorbereitet und geteilt" },
      { id: "k5", label: "Zeitrahmen und Meilensteine grob Ã¼berlegt" },
    ],
    questions: [
      {
        category: "ProblemverstÃ¤ndnis",
        items: [
          "KÃ¶nnen Sie mir ein konkretes Beispiel geben, wo das Problem aufgetreten ist?",
          "Was passiert, wenn wir das Problem nicht lÃ¶sen?",
          "Wie wird das Problem heute gelÃ¶st (ohne ML)?",
          "Wie groÃŸ ist der Impact (â‚¬, Zeit, Kunden)?",
        ],
      },
      {
        category: "Entscheidung & Aktion",
        items: [
          "Wer trifft die Entscheidung auf Basis der Vorhersage?",
          "Wie oft wird diese Entscheidung getroffen?",
          "Was genau wÃ¼rde sich Ã¤ndern, wenn wir gute Vorhersagen hÃ¤tten?",
          "Gibt es KapazitÃ¤tsgrenzen (z.B. Team kann nur 100 FÃ¤lle/Woche bearbeiten)?",
        ],
      },
      {
        category: "Erfolgsmessung",
        items: [
          "Welchen Business-KPI wollen wir verbessern?",
          "Welche Verbesserung wÃ¤re ein Erfolg (z.B. +10% Conversion)?",
          "Wie messen wir den Erfolg der Intervention?",
          "Was ist die Baseline (heutiger Wert)?",
        ],
      },
      {
        category: "Scope & Timeline",
        items: [
          "Was ist explizit NICHT Teil des Projekts?",
          "Gibt es Deadlines oder externe AbhÃ¤ngigkeiten?",
          "Welche Ressourcen stehen zur VerfÃ¼gung?",
          "Wer muss Ã¼berzeugt werden fÃ¼r ein Go?",
        ],
      },
    ],
    redFlags: [
      "Zu vage Ziele: 'Wir wollen KI nutzen' â†’ Nachhaken: 'WofÃ¼r genau?'",
      "Kein klarer Sponsor/Owner: 'Das ist ein IT-Projekt' â†’ Business-Owner finden",
      "Unrealistische Erwartungen: '100% Accuracy' â†’ FrÃ¼h Erwartungen managen",
      "Keine Zeit fÃ¼r Fragen: Meeting dominiert von PrÃ¤sentationen â†’ Interaktion einfordern",
      "Zu viele Stakeholder ohne klare Rollen â†’ Rollen klÃ¤ren, Folgemeeting klein halten",
    ],
    afterMeeting: [
      { id: "k-after1", label: "Problem-Statement schriftlich festhalten" },
      { id: "k-after2", label: "Erfolgs-KPI definiert und kommuniziert" },
      { id: "k-after3", label: "Scope dokumentiert (inkl. Out-of-Scope)" },
      { id: "k-after4", label: "NÃ¤chste Schritte und Verantwortlichkeiten verteilt" },
      { id: "k-after5", label: "Folgetermine vereinbart (Data Review, Check-ins)" },
    ],
  },
  {
    id: "data-review",
    name: "Data Review",
    emoji: "ğŸ”",
    goal: "Daten verstehen, QualitÃ¤t prÃ¼fen, Risiken identifizieren",
    description: "Tiefes Eintauchen in die verfÃ¼gbaren Daten â€“ was haben wir, was fehlt, was ist kritisch?",
    participants: [
      "Data Scientist / ML Engineer",
      "Data Engineer",
      "Fachexperte (Domain Expert)",
      "Optional: Data Owner, IT-Security",
    ],
    beforeMeeting: [
      { id: "d1", label: "Erste explorative Analyse durchgefÃ¼hrt" },
      { id: "d2", label: "Datenquellen identifiziert und Zugang geklÃ¤rt" },
      { id: "d3", label: "Grundlegende Statistiken vorbereitet (Zeilen, Spalten, Missing Values)" },
      { id: "d4", label: "Fragen zur DatenqualitÃ¤t notiert" },
      { id: "d5", label: "Label-Definition mit Business abgestimmt" },
    ],
    questions: [
      {
        category: "Datenquellen",
        items: [
          "Welche Systeme liefern diese Daten?",
          "Wie aktuell sind die Daten (Echtzeit, tÃ¤glich, wÃ¶chentlich)?",
          "Wer ist Data Owner fÃ¼r jede Quelle?",
          "Gibt es bekannte DatenqualitÃ¤tsprobleme?",
        ],
      },
      {
        category: "Label & Features",
        items: [
          "Was genau ist das Label (Zielvariable)?",
          "Wann ist das Label bekannt (Label Delay)?",
          "Welche Features sind zum Vorhersagezeitpunkt verfÃ¼gbar?",
          "Gibt es Features, die auf das Label 'leaken'?",
        ],
      },
      {
        category: "DatenqualitÃ¤t",
        items: [
          "Warum fehlen diese Werte (MCAR, MAR, MNAR)?",
          "Was bedeuten die AusreiÃŸer â€“ echte Werte oder Fehler?",
          "Wie werden Kategorien codiert (IDs, Texte, ...)?",
          "Gibt es Duplikate oder Inkonsistenzen?",
        ],
      },
      {
        category: "Risiken & EinschrÃ¤nkungen",
        items: [
          "Gibt es Datenschutz-EinschrÃ¤nkungen?",
          "Wurden die Daten in der Vergangenheit geÃ¤ndert (Schema-Changes)?",
          "Gibt es saisonale oder zeitliche Muster zu beachten?",
          "Wie reprÃ¤sentativ sind die historischen Daten fÃ¼r die Zukunft?",
        ],
      },
    ],
    redFlags: [
      "Kein Zugang zu Rohdaten: 'Wir liefern nur aggregierte Reports' â†’ GranularitÃ¤t einfordern",
      "Label nicht klar: 'Das wissen wir noch nicht genau' â†’ Definition vor Modellierung klÃ¤ren",
      "Massive Missing Values: >50% fehlen â†’ Ursache klÃ¤ren, ggf. Feature verwerfen",
      "Daten zu alt: 'Die letzten 5 Jahre' â†’ Aber Muster von vor 5 Jahren noch relevant?",
      "Keine Domain-Expertise: Niemand kann erklÃ¤ren, was die Spalten bedeuten â†’ Fachexperten einbeziehen",
    ],
    afterMeeting: [
      { id: "d-after1", label: "Datenquellen und Owner dokumentiert" },
      { id: "d-after2", label: "Label-Definition schriftlich festgehalten" },
      { id: "d-after3", label: "DatenqualitÃ¤tsprobleme und LÃ¶sungen dokumentiert" },
      { id: "d-after4", label: "Feature-Liste mit VerfÃ¼gbarkeit erstellt" },
      { id: "d-after5", label: "Risiken und Mitigationsstrategien notiert" },
    ],
  },
  {
    id: "model-review",
    name: "Model Review",
    emoji: "ğŸ”¬",
    goal: "Modell-Performance bewerten, Fehleranalyse, nÃ¤chste Schritte",
    description: "Technische ÃœberprÃ¼fung des Modells â€“ funktioniert es, wo versagt es, was kÃ¶nnen wir verbessern?",
    participants: [
      "Data Scientists / ML Engineers",
      "Technical Lead / Senior DS",
      "Optional: Data Engineer, PM",
    ],
    beforeMeeting: [
      { id: "m1", label: "Baseline-Ergebnisse dokumentiert" },
      { id: "m2", label: "Modell-Ergebnisse reproduzierbar (Code, Daten, Config)" },
      { id: "m3", label: "Metriken auf Train, Validation, Test berechnet" },
      { id: "m4", label: "Fehleranalyse vorbereitet (wo versagt das Modell?)" },
      { id: "m5", label: "Feature Importance / SHAP Values berechnet" },
    ],
    questions: [
      {
        category: "Performance",
        items: [
          "Wie performt das Modell vs. Baseline?",
          "Wie vergleichen sich Train, Validation, Test Metriken (Overfitting)?",
          "Welche Metrik ist fÃ¼r das Business am wichtigsten?",
          "Wie stabil sind die Ergebnisse (Varianz Ã¼ber Folds)?",
        ],
      },
      {
        category: "Fehleranalyse",
        items: [
          "Welche FÃ¤lle werden falsch vorhergesagt (Error Analysis)?",
          "Gibt es Muster in den Fehlern (bestimmte Segmente, ZeitrÃ¤ume)?",
          "Wie sind False Positives vs. False Negatives verteilt?",
          "Was sagen die wichtigsten Features Ã¼ber die Fehler?",
        ],
      },
      {
        category: "Fairness & Robustheit",
        items: [
          "Wie performt das Modell auf verschiedenen Subgruppen?",
          "Gibt es Bias in den Vorhersagen?",
          "Wie sensitiv ist das Modell auf Input-Ã„nderungen?",
          "Wurden Adversarial Cases getestet?",
        ],
      },
      {
        category: "NÃ¤chste Schritte",
        items: [
          "Welche Features kÃ¶nnten noch hinzugefÃ¼gt werden?",
          "Lohnt sich ein komplexeres Modell?",
          "Sind die Ergebnisse gut genug fÃ¼r einen Piloten?",
          "Was sind die grÃ¶ÃŸten Verbesserungshebel?",
        ],
      },
    ],
    redFlags: [
      "Nur Train-Metriken: 'Accuracy 99%!' â†’ Wo ist Test? Overfitting prÃ¼fen",
      "Keine Baseline: 'Besser als vorher' â†’ Vorher was genau? Quantifizieren",
      "Black Box: 'Wir wissen nicht, warum' â†’ ErklÃ¤rbarkeit wichtig fÃ¼r Stakeholder",
      "Cherry-Picking: 'Funktioniert super fÃ¼r diesen einen Fall' â†’ Generalisierung prÃ¼fen",
      "Keine Reproduzierbarkeit: 'Das war auf meinem Laptop' â†’ Dokumentation und Versionierung",
    ],
    afterMeeting: [
      { id: "m-after1", label: "Modell-Performance dokumentiert (inkl. Baseline-Vergleich)" },
      { id: "m-after2", label: "Fehleranalyse-Erkenntnisse festgehalten" },
      { id: "m-after3", label: "Entscheidung: Weitermachen, Pivot, oder Stop" },
      { id: "m-after4", label: "Konkrete nÃ¤chste Experimente definiert" },
      { id: "m-after5", label: "Timeline fÃ¼r nÃ¤chsten Review festgelegt" },
    ],
  },
  {
    id: "go-nogo",
    name: "Go/No-Go Entscheidung",
    emoji: "ğŸš¦",
    goal: "Entscheidung treffen: Pilotphase starten oder nicht",
    description: "Das entscheidende Meeting â€“ geht das Modell in den Piloten oder brauchen wir mehr Iteration?",
    participants: [
      "Business Stakeholder / Sponsor",
      "Data Science Lead",
      "Product Manager",
      "Optional: IT, Legal, Operations",
    ],
    beforeMeeting: [
      { id: "g1", label: "Go/No-Go Kriterien (vorher definiert) Ã¼berprÃ¼ft" },
      { id: "g2", label: "Modell-Performance vs. Kriterien dokumentiert" },
      { id: "g3", label: "Business-Case-Rechnung vorbereitet (ROI)" },
      { id: "g4", label: "Pilotplan skizziert (Scope, Dauer, Metriken)" },
      { id: "g5", label: "Risiken und Mitigationen dokumentiert" },
    ],
    questions: [
      {
        category: "Performance vs. Kriterien",
        items: [
          "ErfÃ¼llt das Modell die vorab definierten Kriterien?",
          "Wenn nicht: Wie weit entfernt sind wir?",
          "Welche Trade-offs (Precision vs. Recall) haben wir gemacht?",
          "Wie vergleicht sich die Performance mit der Baseline?",
        ],
      },
      {
        category: "Business Impact",
        items: [
          "Wie Ã¼bersetzt sich die Modell-Performance in Business-Wert?",
          "Was ist der erwartete ROI des Piloten?",
          "Welche Kosten entstehen durch False Positives / Negatives?",
          "Was sind die OpportunitÃ¤tskosten von 'Nicht machen'?",
        ],
      },
      {
        category: "Pilotplan",
        items: [
          "Wie groÃŸ ist der Pilot (Nutzer, Region, Zeitraum)?",
          "Wie messen wir den Erfolg im Pilot?",
          "Was ist der Fallback, wenn der Pilot scheitert?",
          "Wer ist verantwortlich fÃ¼r den Pilot?",
        ],
      },
      {
        category: "Risiken",
        items: [
          "Was sind die grÃ¶ÃŸten Risiken des Piloten?",
          "Wie kÃ¶nnen wir diese Risiken mitigieren?",
          "Was passiert bei einem PR-Desaster (false positives Ã¶ffentlich)?",
          "Gibt es regulatorische Risiken?",
        ],
      },
    ],
    redFlags: [
      "Keine vordefinierten Kriterien: 'Sieht gut aus' â†’ Objektive Kriterien nachholen",
      "Nur technische Metriken: 'AUC 0.85' â†’ Business-Impact Ã¼bersetzen",
      "Kein Pilotplan: 'Einfach live schalten' â†’ Kontrollierte EinfÃ¼hrung planen",
      "Sponsor absent: Entscheidung ohne Budget-Owner â†’ Termin verschieben",
      "Gruppendenken: Alle dafÃ¼r, keiner fragt kritisch â†’ Devil's Advocate benennen",
    ],
    afterMeeting: [
      { id: "g-after1", label: "Entscheidung dokumentiert und kommuniziert" },
      { id: "g-after2", label: "Bei Go: Pilotplan finalisiert und geteilt" },
      { id: "g-after3", label: "Bei No-Go: NÃ¤chste Schritte (Iteration, Stop) definiert" },
      { id: "g-after4", label: "Verantwortlichkeiten fÃ¼r Pilot/Iteration zugewiesen" },
      { id: "g-after5", label: "Stakeholder informiert (inkl. Nicht-Anwesende)" },
    ],
  },
  {
    id: "retrospective",
    name: "Retrospektive",
    emoji: "ğŸ”„",
    goal: "Lernen aus dem Projekt â€“ was lief gut, was verbessern?",
    description: "Nach Abschluss des Projekts oder Piloten: Was haben wir gelernt, was machen wir beim nÃ¤chsten Mal anders?",
    participants: [
      "Gesamtes Projektteam",
      "Optional: Stakeholder, Sponsor",
    ],
    beforeMeeting: [
      { id: "r1", label: "Projekt-Timeline und Meilensteine zusammengestellt" },
      { id: "r2", label: "Erfolge und Misserfolge gesammelt" },
      { id: "r3", label: "Anonymes Feedback eingeholt (optional)" },
      { id: "r4", label: "Daten zum Projekt-Verlauf (Zeit, Aufwand, Ergebnisse)" },
      { id: "r5", label: "Vorherige Retrospektiven-Erkenntnisse (falls vorhanden)" },
    ],
    questions: [
      {
        category: "Was lief gut?",
        items: [
          "Was waren die grÃ¶ÃŸten Erfolge des Projekts?",
          "Was sollten wir unbedingt wiederholen?",
          "Wer hat besonders gut beigetragen?",
          "Welche Praktiken haben sich bewÃ¤hrt?",
        ],
      },
      {
        category: "Was lief nicht gut?",
        items: [
          "Wo haben wir Zeit verloren?",
          "Welche Annahmen waren falsch?",
          "Wo gab es Kommunikationsprobleme?",
          "Was hÃ¤tten wir frÃ¼her wissen mÃ¼ssen?",
        ],
      },
      {
        category: "Was kÃ¶nnen wir verbessern?",
        items: [
          "Was wÃ¼rden wir beim nÃ¤chsten Mal anders machen?",
          "Welche Prozesse sollten wir Ã¤ndern?",
          "Welche Tools oder Skills fehlen uns?",
          "Wie kÃ¶nnen wir Stakeholder besser einbinden?",
        ],
      },
      {
        category: "NÃ¤chste Schritte",
        items: [
          "Welche konkreten Action Items nehmen wir mit?",
          "Wer ist verantwortlich fÃ¼r jedes Action Item?",
          "Bis wann sollen die Verbesserungen umgesetzt sein?",
          "Wie teilen wir die Learnings mit anderen Teams?",
        ],
      },
    ],
    redFlags: [
      "Blame Game: 'XY hat versagt' â†’ Fokus auf Prozesse, nicht Personen",
      "Nur Positives: 'Alles super gelaufen' â†’ Kritische Reflexion einfordern",
      "Keine Action Items: 'War interessant' â†’ Konkrete nÃ¤chste Schritte festlegen",
      "Abwesende Teammitglieder: Key Player fehlen â†’ Termin verschieben",
      "Keine Vorbereitung: 'Was war nochmal das Projekt?' â†’ Vorher Infos teilen",
    ],
    afterMeeting: [
      { id: "r-after1", label: "Retrospektive-Ergebnisse dokumentiert" },
      { id: "r-after2", label: "Action Items mit Verantwortlichen und Deadlines" },
      { id: "r-after3", label: "Learnings fÃ¼r zukÃ¼nftige Projekte archiviert" },
      { id: "r-after4", label: "Erfolge gefeiert und kommuniziert" },
      { id: "r-after5", label: "Follow-up fÃ¼r Action Items geplant" },
    ],
  },
];

// Funktion: Meeting-Typ nach ID finden
export function getMeetingType(id: string): MeetingType | undefined {
  return meetingTypes.find(m => m.id === id);
}
