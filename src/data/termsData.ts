// Zusammengef√ºhrte Begriffsdaten aus Glossar und Translator

export interface Term {
  id: string;
  name: string;
  category: string;
  
  // Schnell-Modus (aus Glossar)
  shortDefinition: string;
  quickExample?: string;
  
  // Stakeholder-Modus (aus Translator)
  businessTranslation?: string;
  fullExplanation?: string;
  detailedExample?: {
    scenario: string;
    explanation: string;
    numbers?: string;
  };
  whenImportant?: string[];
  presentationText?: string;
  relatedTerms?: string[];
  
  // Zus√§tzliche Felder (aus Glossar)
  goodPractice?: string[];
  badPractice?: string[];
  tip?: string;
  subtypes?: { name: string; description: string }[];
  table?: { headers: string[]; rows: string[][] };
  problems?: string[];
  
  // NEU: Technische Details f√ºr Experten
  technicalDetails?: {
    formula?: string;
    calculation?: string;
    interpretation?: string;
    caveats?: string[];
  };
}

export interface TermCategory {
  id: string;
  name: string;
  icon: string;
}

export interface BusinessQuestion {
  id: string;
  question: string;
  category: string;
  dsAnswer: string;
  explanation: string;
  relatedTerms: string[];
}

export interface BusinessQuestionCategory {
  id: string;
  name: string;
  icon: string;
}

// DS-Kategorien
export const termCategories: TermCategory[] = [
  { id: "grundbegriffe", name: "ML Grundbegriffe", icon: "üß†" },
  { id: "statistik", name: "Statistik & Visualisierung", icon: "üìà" },
  { id: "metriken", name: "Metriken & Performance", icon: "üìä" },
  { id: "regression", name: "Regression", icon: "üìâ" },
  { id: "klassifikation", name: "Klassifikation", icon: "üéØ" },
  { id: "algorithmen", name: "Algorithmen & Clustering", icon: "‚öôÔ∏è" },
  { id: "fehler", name: "Fehler & Probleme", icon: "‚ö†Ô∏è" },
  { id: "modell", name: "Modell & Daten", icon: "üîß" },
  { id: "validierung", name: "Validierung & Test", icon: "üìà" },
  { id: "projekt", name: "Projekt & Prozess", icon: "üè¢" },
  { id: "rollen", name: "Data Science Rollen", icon: "üë•" },
  { id: "infrastruktur", name: "Daten & Infrastruktur", icon: "üèóÔ∏è" },
  { id: "konzepte", name: "Konzepte & Ph√§nomene", icon: "üí°" },
];

// Business-Fragen Kategorien
export const businessQuestionCategories: BusinessQuestionCategory[] = [
  { id: "genauigkeit", name: "Fragen zur Genauigkeit", icon: "üìä" },
  { id: "vertrauen", name: "Fragen zu Vertrauen & Erkl√§rbarkeit", icon: "ü§î" },
  { id: "risiken", name: "Fragen zu Fehlern & Risiken", icon: "‚ö†Ô∏è" },
  { id: "betrieb", name: "Fragen zu Betrieb & Updates", icon: "üîÑ" },
];

// Zusammengef√ºhrte Begriffe
export const terms: Term[] = [
  // === ML GRUNDBEGRIFFE ===
  {
    id: "machine-learning",
    name: "Machine Learning (ML)",
    category: "grundbegriffe",
    shortDefinition: "Teilgebiet der KI, bei dem Systeme aus Daten lernen, ohne explizit programmiert zu werden.",
    quickExample: "Ein Spam-Filter lernt aus Beispielen, welche E-Mails Spam sind.",
    businessTranslation: "Systeme lernen selbstst√§ndig aus Daten",
    fullExplanation: "Machine Learning erm√∂glicht es Computern, Muster in Daten zu erkennen und Vorhersagen zu treffen, ohne f√ºr jeden Fall explizit programmiert zu werden. Das unterscheidet es von traditioneller Software, bei der jede Regel manuell definiert werden muss.",
    relatedTerms: ["ki", "deep-learning", "modell-ml"],
  },
  {
    id: "ki",
    name: "K√ºnstliche Intelligenz (KI / AI)",
    category: "grundbegriffe",
    shortDefinition: "Oberbegriff f√ºr Systeme, die menschen√§hnliche Intelligenz simulieren.",
    quickExample: "Sprachassistenten, autonomes Fahren, Bilderkennung.",
    businessTranslation: "Computer, die 'intelligent' handeln",
    fullExplanation: "KI ist der Oberbegriff f√ºr alle Technologien, die es Maschinen erm√∂glichen, Aufgaben auszuf√ºhren, die normalerweise menschliche Intelligenz erfordern. Machine Learning ist ein Teilbereich der KI.",
    relatedTerms: ["machine-learning", "deep-learning"],
  },
  {
    id: "deep-learning",
    name: "Deep Learning",
    category: "grundbegriffe",
    shortDefinition: "Teilbereich des ML mit tiefen neuronalen Netzen (viele Schichten).",
    quickExample: "GPT (ChatGPT), Bilderkennung, Spracherkennung.",
    businessTranslation: "ML mit besonders komplexen Modellen",
    fullExplanation: "Deep Learning nutzt neuronale Netze mit vielen Schichten, um sehr komplexe Muster zu lernen. Es ist besonders erfolgreich bei Bild-, Text- und Sprachverarbeitung, ben√∂tigt aber viele Daten und Rechenleistung.",
    relatedTerms: ["machine-learning", "neuronales-netz"],
  },
  {
    id: "modell-ml",
    name: "Modell",
    category: "grundbegriffe",
    shortDefinition: "Das Ergebnis des Trainings ‚Äì eine mathematische Funktion, die Vorhersagen macht.",
    quickExample: "Ein trainiertes Modell kann den Hauspreis basierend auf Quadratmetern vorhersagen.",
    businessTranslation: "Der 'fertige Algorithmus' nach dem Lernen",
    fullExplanation: "Ein ML-Modell ist das Produkt des Trainingsprozesses. Es enth√§lt die gelernten Muster und kann auf neue Daten angewendet werden, um Vorhersagen zu machen.",
    relatedTerms: ["training", "inferenz", "prediction"],
  },
  {
    id: "inferenz",
    name: "Inferenz",
    category: "grundbegriffe",
    shortDefinition: "Die Anwendung eines trainierten Modells auf neue, ungesehene Daten.",
    quickExample: "Das trainierte Modell klassifiziert ein neues Bild als 'Katze'.",
    businessTranslation: "Das Modell im Einsatz ‚Äì Vorhersagen f√ºr neue Daten",
    fullExplanation: "Inferenz ist der Produktiveinsatz eines Modells. Im Gegensatz zum Training, wo das Modell lernt, wird bei der Inferenz das Gelernte auf neue Daten angewendet.",
    relatedTerms: ["prediction", "modell-ml", "deployment"],
  },
  {
    id: "prediction",
    name: "Prediction (Vorhersage)",
    category: "grundbegriffe",
    shortDefinition: "Das Ergebnis, das ein Modell f√ºr einen neuen Datenpunkt liefert.",
    quickExample: "'Dieser Kunde wird mit 73% Wahrscheinlichkeit k√ºndigen.'",
    businessTranslation: "Die Antwort des Modells",
    fullExplanation: "Eine Prediction ist das konkrete Ergebnis der Inferenz ‚Äì entweder eine Zahl (bei Regression) oder eine Kategorie/Wahrscheinlichkeit (bei Klassifikation).",
    relatedTerms: ["inferenz", "modell-ml"],
  },
  {
    id: "supervised-learning",
    name: "Supervised Learning",
    category: "grundbegriffe",
    shortDefinition: "ML-Ansatz, bei dem das Modell aus gelabelten Beispielen lernt.",
    quickExample: "Spam-Erkennung mit E-Mails, die als 'Spam'/'Kein Spam' markiert sind.",
    businessTranslation: "Lernen mit Beispielen und L√∂sungen",
    fullExplanation: "Bei Supervised Learning kennen wir die 'richtige Antwort' f√ºr die Trainingsdaten (Labels). Das Modell lernt, diese Zuordnung nachzuahmen. Typische Aufgaben sind Klassifikation und Regression.",
    relatedTerms: ["unsupervised-learning", "label", "ground-truth"],
  },
  {
    id: "unsupervised-learning",
    name: "Unsupervised Learning",
    category: "grundbegriffe",
    shortDefinition: "ML-Ansatz, bei dem das Modell ohne Labels Muster in Daten findet.",
    quickExample: "Kundensegmentierung ohne vordefinierte Gruppen.",
    businessTranslation: "Muster finden ohne Vorgaben",
    fullExplanation: "Bei Unsupervised Learning gibt es keine vordefinierten Labels. Das Modell entdeckt selbstst√§ndig Strukturen und Muster in den Daten ‚Äì z.B. Cluster oder Anomalien.",
    relatedTerms: ["supervised-learning", "clustering", "anomalie-erkennung"],
  },
  {
    id: "ground-truth",
    name: "Ground Truth",
    category: "grundbegriffe",
    shortDefinition: "Die tats√§chlich korrekten Labels ‚Äì die 'Wahrheit' gegen die das Modell gepr√ºft wird.",
    quickExample: "Die echten Diagnosen von √Ñrzten, gegen die ein Diagnose-Modell verglichen wird.",
    businessTranslation: "Die bekannte, richtige Antwort",
    fullExplanation: "Ground Truth sind die verifizierten, korrekten Werte in den Daten. Die Qualit√§t der Ground Truth bestimmt ma√ügeblich, wie gut ein Modell lernen kann.",
    relatedTerms: ["label", "supervised-learning"],
  },

  // === STATISTIK & VISUALISIERUNG ===
  // Lagema√üe
  {
    id: "mittelwert",
    name: "Mittelwert (Durchschnitt, Mean)",
    category: "statistik",
    shortDefinition: "Summe aller Werte geteilt durch Anzahl. Das bekannteste Lagema√ü.",
    quickExample: "Durchschnittlicher Bestellwert: (50‚Ç¨ + 100‚Ç¨ + 150‚Ç¨) / 3 = 100‚Ç¨",
    businessTranslation: "Der typische Wert ‚Äì aber Vorsicht bei Ausrei√üern",
    fullExplanation: "Der Mittelwert ist intuitiv verst√§ndlich, aber kann durch Ausrei√üer stark verzerrt werden. Ein einziger Million√§r ver√§ndert den Durchschnitts-Gehaltsreport einer Firma massiv.",
    detailedExample: {
      scenario: "Kundenausgaben analysieren",
      explanation: "Wenn ein Gro√ükunde mit 100.000‚Ç¨ Jahresumsatz dabei ist, verzerrt dieser den Durchschnitt aller Kunden stark nach oben.",
      numbers: "Ohne Gro√ükunde: √ò 500‚Ç¨, mit Gro√ükunde: √ò 2.000‚Ç¨",
    },
    badPractice: ["Bei schiefen Verteilungen den Mittelwert als 'typisch' bezeichnen"],
    goodPractice: ["Median und Mittelwert vergleichen ‚Äì gro√üe Differenz = Ausrei√üer-Problem"],
    tip: "Bei schiefen Verteilungen oder Ausrei√üern lieber den Median verwenden!",
    relatedTerms: ["median", "standardabweichung", "ausreisser"],
    technicalDetails: {
      formula: "Œº = Œ£x·µ¢ / n",
      calculation: "Alle Werte addieren, durch Anzahl teilen",
      caveats: [
        "Empfindlich gegen√ºber Ausrei√üern",
        "Bei schiefen Verteilungen oft irref√ºhrend",
        "Setzt metrische Daten voraus",
      ],
    },
  },
  {
    id: "median",
    name: "Median",
    category: "statistik",
    shortDefinition: "Der mittlere Wert, wenn alle Werte sortiert werden. Robust gegen√ºber Ausrei√üern.",
    quickExample: "Geh√§lter: 30k, 35k, 40k, 45k, 200k ‚Üí Median = 40k (nicht 70k wie der Mittelwert)",
    businessTranslation: "Der mittlere Wert ‚Äì robust bei Extremen",
    fullExplanation: "Der Median teilt einen Datensatz in zwei H√§lften. Er ist robust gegen√ºber Ausrei√üern und oft aussagekr√§ftiger als der Mittelwert bei schiefen Verteilungen.",
    detailedExample: {
      scenario: "Immobilienpreise",
      explanation: "Wenige Luxusimmobilien verzerren den Durchschnitt stark, der Median zeigt den 'typischen' Preis besser.",
      numbers: "Mittelwert: 800.000‚Ç¨, Median: 450.000‚Ç¨",
    },
    whenImportant: [
      "Bei Geh√§ltern, Preisen, Verm√∂gen (h√§ufig schief verteilt)",
      "Wenn Ausrei√üer im Datensatz sind",
      "F√ºr 'typische' Werte statt mathematische Durchschnitte",
    ],
    relatedTerms: ["mittelwert", "quartil", "perzentil"],
    technicalDetails: {
      formula: "Bei ungerader Anzahl n: x‚Çç‚Çô‚Çä‚ÇÅ‚Çé/‚ÇÇ | Bei gerader Anzahl: (x‚Çç‚Çô/‚ÇÇ‚Çé + x‚Çç‚Çô/‚ÇÇ‚Çä‚ÇÅ‚Çé) / 2",
      calculation: "1. Werte sortieren ‚Üí 2. Mittlere Position bestimmen ‚Üí 3. Bei gerader Anzahl: Mittel der beiden mittleren Werte",
      interpretation: "50% der Werte liegen unter dem Median, 50% dar√ºber",
      caveats: [
        "Robust gegen Ausrei√üer (im Gegensatz zum Mittelwert)",
        "Bei schiefen Verteilungen aussagekr√§ftiger als Mittelwert",
        "Entspricht dem 50. Perzentil = Q2",
      ],
    },
  },
  {
    id: "modus",
    name: "Modus (Modalwert)",
    category: "statistik",
    shortDefinition: "Der h√§ufigste Wert in einem Datensatz.",
    quickExample: "Schuhgr√∂√üen: 40, 42, 42, 42, 43, 44 ‚Üí Modus = 42",
    businessTranslation: "Der h√§ufigste Wert in den Daten",
    fullExplanation: "Der Modus ist der Wert, der am h√§ufigsten vorkommt. Bei kategorialen Daten oft die einzige sinnvolle Kennzahl. Bei stetigen Daten weniger n√ºtzlich.",
    whenImportant: [
      "Bei kategorialen Daten (z.B. beliebtestes Produkt)",
      "F√ºr Gr√∂√üentabellen (h√§ufigste Gr√∂√üe)",
      "Bei bimodalen Verteilungen (zwei Gipfel)",
    ],
    relatedTerms: ["mittelwert", "median"],
    technicalDetails: {
      interpretation: "Der am h√§ufigsten vorkommende Wert. Bei mehreren gleich h√§ufigen Werten: multimodal.",
      caveats: [
        "Unimodal: Ein Modus (z.B. 42, 42, 42, 43, 44)",
        "Bimodal: Zwei Modi (z.B. 40, 40, 42, 42, 43)",
        "Multimodal: Mehrere Modi",
        "Bei stetigen Daten oft wenig aussagekr√§ftig",
      ],
    },
  },
  {
    id: "gewichteter-mittelwert",
    name: "Gewichteter Mittelwert",
    category: "statistik",
    shortDefinition: "Durchschnitt, bei dem nicht alle Werte gleich z√§hlen.",
    quickExample: "Schulnote: (Klausur 70% √ó 2.0) + (M√ºndlich 30% √ó 1.0) = 1.7",
    businessTranslation: "Durchschnitt mit unterschiedlicher Gewichtung",
    fullExplanation: "Beim gewichteten Mittelwert haben einige Werte mehr Einfluss als andere. Wichtig bei Scores, Bewertungen und Indizes.",
    detailedExample: {
      scenario: "Kundenzufriedenheits-Score",
      explanation: "Wichtige Kunden (hohes Volumen) bekommen mehr Gewicht als Kleinkunden.",
      numbers: "5 Gro√ükunden (Gewicht 3) + 50 Kleinkunden (Gewicht 1)",
    },
    relatedTerms: ["mittelwert"],
    technicalDetails: {
      formula: "xÃÑ·µ• = Œ£(w·µ¢ √ó x·µ¢) / Œ£w·µ¢",
      calculation: "1. Jeden Wert mit seinem Gewicht multiplizieren ‚Üí 2. Summe bilden ‚Üí 3. Durch Summe der Gewichte teilen",
      interpretation: "Gewichte spiegeln die Wichtigkeit wider. Gr√∂√üere Gewichte = gr√∂√üerer Einfluss.",
      caveats: [
        "Gewichte m√ºssen positiv sein",
        "Summe der Gewichte muss > 0 sein",
        "Bei gleichen Gewichten = normaler Mittelwert",
      ],
    },
  },
  {
    id: "geometrisches-mittel",
    name: "Geometrisches Mittel",
    category: "statistik",
    shortDefinition: "Spezieller Durchschnitt f√ºr Wachstumsraten und Prozente.",
    quickExample: "Jahr 1: +50%, Jahr 2: -30% ‚Üí Nicht 10% Gewinn, sondern 5% (geometrisch)",
    businessTranslation: "Durchschnitt f√ºr Wachstumsraten und Prozente",
    fullExplanation: "Das geometrische Mittel ist der richtige Durchschnitt f√ºr Wachstumsraten. Das arithmetische Mittel f√ºhrt hier zu falschen Ergebnissen.",
    tip: "Bei Renditen, Wachstumsraten und Prozentzahlen immer das geometrische Mittel verwenden!",
    relatedTerms: ["mittelwert"],
    technicalDetails: {
      formula: "G = ‚Åø‚àö(x‚ÇÅ √ó x‚ÇÇ √ó ... √ó x‚Çô)",
      calculation: "Alle Werte multiplizieren, dann n-te Wurzel ziehen. Alternativ: exp(mean(log(x)))",
      interpretation: "Durchschnittliche Wachstumsrate. +50% und -30% ‚â† +10%, sondern ‚âà +2.5%",
      caveats: [
        "Alle Werte m√ºssen positiv sein",
        "Geometrisches Mittel ‚â§ Arithmetisches Mittel (immer)",
        "Bei Verh√§ltnissen und Prozentzahlen verwenden",
      ],
    },
  },

  // Streuungsma√üe
  {
    id: "varianz",
    name: "Varianz",
    category: "statistik",
    shortDefinition: "Durchschnittliche quadrierte Abweichung vom Mittelwert. Ma√ü f√ºr Streuung.",
    quickExample: "Hohe Varianz = Daten streuen stark um den Mittelwert.",
    businessTranslation: "Wie stark streuen die Werte? (technisch)",
    fullExplanation: "Die Varianz misst, wie weit die Daten im Durchschnitt vom Mittelwert entfernt sind. Da sie quadriert ist, hat sie keine intuitive Einheit ‚Äì deshalb nutzt man oft die Standardabweichung.",
    relatedTerms: ["standardabweichung", "mittelwert"],
    technicalDetails: {
      formula: "œÉ¬≤ = Œ£(x·µ¢ - Œº)¬≤ / n",
      calculation: "1. Mittelwert Œº berechnen ‚Üí 2. F√ºr jeden Wert x·µ¢: Abweichung (x·µ¢ - Œº) ‚Üí 3. Abweichungen quadrieren ‚Üí 4. Durchschnitt der Quadrate",
      interpretation: "H√∂here Varianz = gr√∂√üere Streuung. Einheit ist Originaleinheit¬≤ (z.B. ‚Ç¨¬≤)",
      caveats: [
        "Einheit ist quadriert ‚Üí schwer interpretierbar",
        "Empfindlich gegen√ºber Ausrei√üern",
        "Stichprobe: n-1 statt n (Bessel-Korrektur)",
      ],
    },
  },
  {
    id: "standardabweichung",
    name: "Standardabweichung (Std, SD)",
    category: "statistik",
    shortDefinition: "Wurzel der Varianz ‚Äì interpretierbare Streuung in Originaleinheiten.",
    quickExample: "Gehalt: Mittelwert 50.000‚Ç¨, Std 10.000‚Ç¨ ‚Üí Die meisten verdienen 40.000-60.000‚Ç¨",
    businessTranslation: "Wie stark streuen die Werte? (interpretierbar)",
    fullExplanation: "Die Standardabweichung ist das Standardma√ü f√ºr Streuung. Bei Normalverteilung liegen 68% der Werte innerhalb von ¬±1 Standardabweichung vom Mittelwert.",
    detailedExample: {
      scenario: "Lieferzeiten",
      explanation: "Durchschnitt: 3 Tage, Standardabweichung: 0.5 Tage ‚Üí 68% der Lieferungen in 2.5-3.5 Tagen.",
      numbers: "Mittelwert ¬± 1 SD = 68%, ¬± 2 SD = 95%, ¬± 3 SD = 99.7%",
    },
    whenImportant: [
      "Zur Beurteilung von Prozessstabilit√§t",
      "F√ºr Konfidenzintervalle",
      "Bei Qualit√§tskontrolle (Six Sigma)",
    ],
    relatedTerms: ["varianz", "konfidenzintervall", "normalverteilung"],
    technicalDetails: {
      formula: "œÉ = ‚àöœÉ¬≤ = ‚àö(Œ£(x·µ¢ - Œº)¬≤ / n)",
      interpretation: "Bei Normalverteilung: 68% in ¬±1œÉ, 95% in ¬±2œÉ, 99.7% in ¬±3œÉ (Empirische Regel)",
      caveats: [
        "Empirische Regel gilt exakt nur bei Normalverteilung",
        "Bei schiefen Verteilungen weniger aussagekr√§ftig",
        "Stichprobe: n-1 statt n im Nenner",
      ],
    },
  },
  {
    id: "spannweite",
    name: "Spannweite (Range)",
    category: "statistik",
    shortDefinition: "Differenz zwischen Maximum und Minimum.",
    quickExample: "Temperaturen: Min 10¬∞, Max 35¬∞ ‚Üí Spannweite = 25¬∞",
    businessTranslation: "Differenz zwischen gr√∂√ütem und kleinstem Wert",
    fullExplanation: "Die Spannweite ist das einfachste Streuungsma√ü, aber sehr anf√§llig f√ºr Ausrei√üer. Ein einzelner Extremwert ver√§ndert die Spannweite stark.",
    tip: "F√ºr robustere Streuungsma√üe lieber IQR oder Standardabweichung verwenden.",
    relatedTerms: ["iqr", "ausreisser"],
    technicalDetails: {
      formula: "R = max(x) - min(x)",
      interpretation: "Gesamtspannbreite der Daten. Einfachstes, aber empfindlichstes Streuungsma√ü.",
      caveats: [
        "Extrem empfindlich gegen√ºber Ausrei√üern",
        "Nutzt nur 2 von n Datenpunkten",
        "W√§chst tendenziell mit Stichprobengr√∂√üe",
      ],
    },
  },
  {
    id: "quartil",
    name: "Quartile (Q1, Q2, Q3)",
    category: "statistik",
    shortDefinition: "Teilen die Daten in vier gleich gro√üe Teile. Q2 = Median.",
    quickExample: "Q1=30k, Q2=45k, Q3=65k ‚Üí 25% verdienen unter 30k, 50% unter 45k, 75% unter 65k",
    businessTranslation: "Daten in 4 gleiche Teile aufgeteilt",
    fullExplanation: "Q1 (25. Perzentil), Q2 (Median, 50. Perzentil) und Q3 (75. Perzentil) teilen die Daten in vier gleiche Teile. Sie sind die Basis f√ºr Boxplots und IQR.",
    whenImportant: [
      "F√ºr Boxplots",
      "Zur Ausrei√üer-Erkennung",
      "Bei Gehalts- und Preisanalysen",
    ],
    relatedTerms: ["median", "iqr", "boxplot", "perzentil"],
    technicalDetails: {
      formula: "Q1 = 25. Perzentil, Q2 = 50. Perzentil (Median), Q3 = 75. Perzentil",
      calculation: "Bei n Werten: Position von Q‚Çñ = (k/4) √ó (n+1). Bei Dezimalstellen: Interpolieren.",
      interpretation: "Q1: 25% darunter | Q2: 50% darunter | Q3: 75% darunter",
      caveats: [
        "Verschiedene Berechnungsmethoden (R, Excel, Python unterscheiden sich leicht)",
        "Bei kleinen Datens√§tzen wenig aussagekr√§ftig",
        "Basis f√ºr IQR und Boxplots",
      ],
    },
  },
  {
    id: "iqr",
    name: "Interquartilsabstand (IQR)",
    category: "statistik",
    shortDefinition: "Spannweite der mittleren 50% der Daten (Q3 - Q1).",
    quickExample: "Q1=30k, Q3=65k ‚Üí IQR = 35k ‚Üí Die mittleren 50% verdienen in dieser Spanne.",
    businessTranslation: "Spannweite der mittleren 50%",
    fullExplanation: "Der IQR zeigt, wie weit die 'typischen' Werte auseinander liegen. Er ist robust gegen Ausrei√üer und wird oft zur Ausrei√üer-Erkennung genutzt (Werte au√üerhalb von Q1-1.5√óIQR bis Q3+1.5√óIQR).",
    whenImportant: [
      "Zur Ausrei√üer-Erkennung",
      "In Boxplots",
      "Als robustes Streuungsma√ü",
    ],
    relatedTerms: ["quartil", "boxplot", "ausreisser"],
    technicalDetails: {
      formula: "IQR = Q3 - Q1",
      calculation: "Ausrei√üer-Regel: Werte < Q1 - 1.5√óIQR oder > Q3 + 1.5√óIQR gelten als Ausrei√üer",
      caveats: [
        "Robust gegen Extremwerte",
        "Ignoriert die √§u√üeren 50% der Daten",
        "Gut geeignet f√ºr schiefe Verteilungen",
      ],
    },
  },
  {
    id: "konfidenzintervall",
    name: "Konfidenzintervall",
    category: "statistik",
    shortDefinition: "Unsicherheitsbereich einer Sch√§tzung ‚Äì 'Der wahre Wert liegt mit 95% Wahrscheinlichkeit in diesem Bereich.'",
    quickExample: "Konversionsrate: 5% ¬± 1% (95% KI: 4-6%)",
    businessTranslation: "Unsicherheitsbereich einer Sch√§tzung",
    fullExplanation: "Das Konfidenzintervall zeigt, wie unsicher eine Sch√§tzung ist. Ein 95%-KI bedeutet: Bei Wiederholung der Studie w√ºrde der wahre Wert in 95% der F√§lle im Intervall liegen.",
    detailedExample: {
      scenario: "A/B-Test",
      explanation: "Variante B hat 5% h√∂here Konversion, aber das 95%-KI ist 2-8%.",
      numbers: "Wir sind sicher, dass die Verbesserung zwischen 2% und 8% liegt.",
    },
    whenImportant: [
      "Bei A/B-Tests",
      "F√ºr Entscheidungen unter Unsicherheit",
      "In wissenschaftlichen Studien",
    ],
    relatedTerms: ["standardfehler", "p-wert", "signifikanzniveau"],
    technicalDetails: {
      formula: "KI = xÃÑ ¬± z √ó (œÉ/‚àön)",
      calculation: "z = 1.645 (90%), z = 1.96 (95%), z = 2.576 (99%)",
      interpretation: "Bei 95% KI: In 95 von 100 Wiederholungen enth√§lt das Intervall den wahren Wert",
      caveats: [
        "NICHT: 'Der wahre Wert liegt mit 95% im Intervall'",
        "Gr√∂√üere Stichprobe = engeres Intervall",
        "Setzt Normalverteilung oder gro√üe n voraus",
        "Breites KI = hohe Unsicherheit",
      ],
    },
  },
  {
    id: "standardfehler",
    name: "Standardfehler",
    category: "statistik",
    shortDefinition: "Unsicherheit des Mittelwerts ‚Äì wie stark w√ºrde er bei neuen Stichproben schwanken?",
    quickExample: "Mittelwert: 100, Standardfehler: 5 ‚Üí Mittelwert k√∂nnte bei neuer Stichprobe 95-105 sein.",
    businessTranslation: "Unsicherheit des Mittelwerts",
    fullExplanation: "Der Standardfehler zeigt, wie pr√§zise der berechnete Mittelwert ist. Er wird kleiner mit mehr Daten. Nicht zu verwechseln mit der Standardabweichung!",
    tip: "Standardfehler = Standardabweichung / ‚àön ‚Üí Mehr Daten = pr√§ziserer Mittelwert",
    relatedTerms: ["standardabweichung", "konfidenzintervall", "stichprobe"],
    technicalDetails: {
      formula: "SE = œÉ / ‚àön",
      calculation: "Standardabweichung geteilt durch Wurzel der Stichprobengr√∂√üe",
      interpretation: "Je gr√∂√üer n, desto kleiner der Standardfehler ‚Üí pr√§zisere Sch√§tzung",
      caveats: [
        "Nicht verwechseln mit Standardabweichung!",
        "SD misst Streuung in den Daten, SE misst Unsicherheit des Mittelwerts",
        "SE sinkt mit ‚àön ‚Üí 4√ó mehr Daten = halber SE",
      ],
    },
  },

  // Zusammenhangsma√üe
  {
    id: "kovarianz-statistik",
    name: "Kovarianz",
    category: "statistik",
    shortDefinition: "Gemeinsame Streuung zweier Variablen ‚Äì ohne Normierung.",
    quickExample: "Positive Kovarianz: Wenn X steigt, steigt auch Y tendenziell.",
    businessTranslation: "Gemeinsame Streuung zweier Variablen",
    fullExplanation: "Die Kovarianz zeigt, ob zwei Variablen zusammen variieren. Positiv = gemeinsam steigen/fallen, negativ = gegenl√§ufig. Problem: Die Gr√∂√üe ist schwer interpretierbar (abh√§ngig von Einheiten).",
    tip: "F√ºr interpretierbare Zusammenh√§nge lieber Korrelation verwenden (normiert zwischen -1 und 1).",
    relatedTerms: ["korrelation-statistik", "varianz"],
    technicalDetails: {
      formula: "Cov(X,Y) = Œ£(x·µ¢ - xÃÑ)(y·µ¢ - »≥) / n",
      interpretation: "Positiv = gemeinsam steigen/fallen. Negativ = gegenl√§ufig. 0 = kein linearer Zusammenhang.",
      caveats: [
        "Einheit: Produkt der Originaleinheiten (z.B. cm √ó kg)",
        "Nicht normiert ‚Üí Gr√∂√üe schwer interpretierbar",
        "Cov(X,X) = Var(X)",
      ],
    },
  },
  {
    id: "korrelation-statistik",
    name: "Korrelation (Pearson)",
    category: "statistik",
    shortDefinition: "St√§rke und Richtung des linearen Zusammenhangs zwischen zwei Variablen (-1 bis +1).",
    quickExample: "r = 0.8: Starker positiver Zusammenhang. r = -0.3: Schwacher negativer Zusammenhang.",
    businessTranslation: "Wie stark h√§ngen zwei Werte zusammen?",
    fullExplanation: "Die Pearson-Korrelation misst lineare Zusammenh√§nge auf einer Skala von -1 (perfekt negativ) √ºber 0 (kein Zusammenhang) bis +1 (perfekt positiv). WICHTIG: Korrelation ‚â† Kausalit√§t!",
    detailedExample: {
      scenario: "Marketing-Ausgaben vs. Umsatz",
      explanation: "r = 0.75 bedeutet starker positiver Zusammenhang ‚Äì aber nicht automatisch Ursache-Wirkung!",
      numbers: "r < 0.3: schwach, 0.3-0.7: mittel, > 0.7: stark",
    },
    badPractice: ["Korrelation als Beweis f√ºr Ursache-Wirkung interpretieren"],
    goodPractice: ["Korrelation als Hinweis nutzen, dann Kausalit√§t separat pr√ºfen"],
    relatedTerms: ["spearman-korrelation", "kovarianz-statistik", "scatterplot"],
    technicalDetails: {
      formula: "r = Œ£(x·µ¢ - xÃÑ)(y·µ¢ - »≥) / ‚àö[Œ£(x·µ¢ - xÃÑ)¬≤ √ó Œ£(y·µ¢ - »≥)¬≤]",
      interpretation: "|r| < 0.3: schwach, 0.3‚Äì0.7: mittel, > 0.7: stark. Vorzeichen zeigt Richtung.",
      caveats: [
        "Korrelation ‚â† Kausalit√§t!",
        "Misst nur lineare Zusammenh√§nge",
        "Ausrei√üer k√∂nnen stark verzerren",
        "r = 0 bedeutet nur: kein LINEARER Zusammenhang",
      ],
    },
  },
  {
    id: "spearman-korrelation",
    name: "Spearman-Korrelation",
    category: "statistik",
    shortDefinition: "Zusammenhang basierend auf R√§ngen ‚Äì funktioniert auch bei nicht-linearen Beziehungen.",
    quickExample: "Kundenzufriedenheit (1-5) vs. Wiederkaufrate ‚Äì nicht linear, aber monoton.",
    businessTranslation: "Zusammenhang bei nicht-linearen Beziehungen",
    fullExplanation: "Die Spearman-Korrelation misst monotone (immer steigend oder fallend) Zusammenh√§nge, auch wenn sie nicht linear sind. Robuster gegen√ºber Ausrei√üern als Pearson.",
    whenImportant: [
      "Bei ordinalen Daten (Rankings, Bewertungen)",
      "Wenn der Zusammenhang nicht linear ist",
      "Bei Ausrei√üern im Datensatz",
    ],
    relatedTerms: ["korrelation-statistik"],
    technicalDetails: {
      formula: "œÅ = 1 - (6 √ó Œ£d·µ¢¬≤) / (n √ó (n¬≤ - 1))",
      calculation: "d·µ¢ = Differenz der R√§nge. Werte werden in R√§nge umgewandelt, dann Pearson auf R√§ngen.",
      interpretation: "Wie Pearson, aber misst monotone (nicht nur lineare) Zusammenh√§nge",
      caveats: [
        "Werte in R√§nge umwandeln: Kleinster = 1, Gr√∂√üter = n",
        "Robuster gegen Ausrei√üer als Pearson",
        "Funktioniert auch bei nicht-linearen, aber monotonen Beziehungen",
      ],
    },
  },
  {
    id: "r-quadrat-statistik",
    name: "R¬≤ (Bestimmtheitsma√ü)",
    category: "statistik",
    shortDefinition: "Anteil der Varianz, die durch das Modell erkl√§rt wird (0-100%).",
    quickExample: "R¬≤ = 0.8 bedeutet: Das Modell erkl√§rt 80% der Variation in den Daten.",
    businessTranslation: "Wie viel erkl√§rt das Modell?",
    fullExplanation: "R¬≤ zeigt, welcher Anteil der Streuung in der Zielvariable durch das Modell erkl√§rt wird. R¬≤=1 w√§re perfekte Vorhersage, R¬≤=0 bedeutet das Modell ist nicht besser als der Mittelwert.",
    detailedExample: {
      scenario: "Umsatzprognose",
      explanation: "R¬≤ = 0.75 bedeutet: 75% der Umsatzschwankungen werden durch unsere Faktoren erkl√§rt, 25% durch andere Einfl√ºsse.",
      numbers: "R¬≤ > 0.7 gilt oft als 'gut'",
    },
    whenImportant: [
      "Zur Bewertung von Regressionsmodellen",
      "Zum Vergleich verschiedener Modelle",
      "Um zu verstehen, wie viel 'unerkl√§rte Variation' bleibt",
    ],
    relatedTerms: ["korrelation-statistik", "rmse", "residuum"],
    technicalDetails: {
      formula: "R¬≤ = 1 - (SS_res / SS_tot) = 1 - Œ£(y·µ¢ - ≈∑·µ¢)¬≤ / Œ£(y·µ¢ - »≥)¬≤",
      interpretation: "Anteil der erkl√§rten Varianz. R¬≤ = 0.8 bedeutet: 80% der Streuung wird erkl√§rt.",
      caveats: [
        "R¬≤ = 1: Perfekte Vorhersage (verd√§chtig!)",
        "R¬≤ = 0: Modell nicht besser als Mittelwert",
        "Kann bei mehr Features nur steigen (‚Üí Adjusted R¬≤ verwenden)",
        "R¬≤ = r¬≤ (Quadrat der Korrelation) bei einfacher Regression",
      ],
    },
  },
  {
    id: "p-wert",
    name: "p-Wert",
    category: "statistik",
    shortDefinition: "Wahrscheinlichkeit, das beobachtete Ergebnis (oder extremer) zu sehen, wenn es keinen echten Effekt gibt.",
    quickExample: "p = 0.03 bedeutet: Nur 3% Wahrscheinlichkeit, dass der Unterschied Zufall ist.",
    businessTranslation: "Ist das Ergebnis statistisch signifikant oder nur Zufall?",
    fullExplanation: "Ein niedriger p-Wert (typisch < 0.05) deutet darauf hin, dass das Ergebnis wahrscheinlich kein Zufall ist. ABER: statistisch signifikant ‚â† praktisch relevant! Ein Unterschied kann signifikant aber winzig sein.",
    detailedExample: {
      scenario: "A/B-Test einer Website",
      explanation: "Variante B hat 5% h√∂here Conversion. p = 0.02 bedeutet: Mit nur 2% Wahrscheinlichkeit w√§re dieser Unterschied Zufall.",
      numbers: "p < 0.05 = signifikant, p > 0.05 = nicht signifikant",
    },
    badPractice: ["p < 0.05 als einziges Entscheidungskriterium nutzen"],
    goodPractice: ["p-Wert zusammen mit Effektgr√∂√üe und praktischer Relevanz betrachten"],
    relatedTerms: ["hypothesentest", "signifikanzniveau", "konfidenzintervall"],
    technicalDetails: {
      formula: "p = P(Daten | H‚ÇÄ)",
      interpretation: "Je kleiner der p-Wert, desto unwahrscheinlicher ist es, dass der Unterschied Zufall ist. Typische Schwellen: 0.05 (5%), 0.01 (1%)",
      caveats: [
        "p < 0.05 ist willk√ºrliche Konvention, kein Naturgesetz",
        "Statistisch signifikant ‚â† praktisch relevant",
        "Multiple Comparisons Problem: Bei vielen Tests steigt Zufallstreffer-Rate",
        "p-Hacking: Daten 'massieren' bis p < 0.05 ist unseri√∂s",
      ],
    },
  },

  // Verteilungen
  {
    id: "normalverteilung",
    name: "Normalverteilung (Glockenkurve)",
    category: "statistik",
    shortDefinition: "Symmetrische Verteilung ‚Äì die meisten Werte um den Mittelwert, wenige Extreme.",
    quickExample: "K√∂rpergr√∂√üen, IQ-Werte, Messfehler folgen oft einer Normalverteilung.",
    businessTranslation: "Die 'Glockenkurve'",
    fullExplanation: "Bei der Normalverteilung liegen 68% der Werte innerhalb von ¬±1 Standardabweichung, 95% innerhalb von ¬±2 SD. Viele statistische Tests setzen Normalverteilung voraus.",
    whenImportant: [
      "Als Voraussetzung vieler statistischer Tests",
      "Zur Beurteilung von Datenqualit√§t",
      "F√ºr Konfidenzintervalle",
    ],
    relatedTerms: ["standardabweichung", "schiefe", "woelbung"],
    technicalDetails: {
      formula: "f(x) = (1 / (œÉ‚àö2œÄ)) √ó e^(-(x-Œº)¬≤/(2œÉ¬≤))",
      calculation: "Definiert durch zwei Parameter: Œº (Mittelwert) und œÉ (Standardabweichung)",
      interpretation: "Symmetrisch, glockenf√∂rmig. Empirische Regel: 68-95-99.7% in ¬±1/2/3 œÉ",
      caveats: [
        "Viele Ph√§nomene sind NICHT normalverteilt",
        "Normalverteilungsannahme immer pr√ºfen (Histogramm, QQ-Plot)",
        "Zentraler Grenzwertsatz: Mittelwerte tendieren zur Normalverteilung",
      ],
    },
  },
  {
    id: "schiefe",
    name: "Schiefe (Skewness)",
    category: "statistik",
    shortDefinition: "Ma√ü f√ºr Asymmetrie einer Verteilung ‚Äì links- oder rechtsschief.",
    quickExample: "Einkommensverteilung: Rechtsschief (langer Schwanz nach rechts zu den Reichen).",
    businessTranslation: "Ist die Verteilung symmetrisch oder verzerrt?",
    fullExplanation: "Positive Schiefe (rechtsschief): Langer Schwanz nach rechts, Mittelwert > Median. Negative Schiefe (linksschief): Langer Schwanz nach links, Mittelwert < Median.",
    detailedExample: {
      scenario: "Wartezeiten im Support",
      explanation: "Meist kurze Wartezeiten, aber einige sehr lange ‚Üí rechtsschief.",
      numbers: "Schiefe > 0: rechtsschief, Schiefe < 0: linksschief, Schiefe ‚âà 0: symmetrisch",
    },
    relatedTerms: ["normalverteilung", "woelbung", "mittelwert", "median"],
    technicalDetails: {
      formula: "Schiefe = E[(X - Œº)¬≥] / œÉ¬≥",
      interpretation: "Schiefe > 0: rechtsschief (Schwanz nach rechts). Schiefe < 0: linksschief. Schiefe ‚âà 0: symmetrisch.",
      caveats: [
        "Rechtsschief: Mittelwert > Median (z.B. Einkommen)",
        "Linksschief: Mittelwert < Median (z.B. Pr√ºfungsnoten)",
        "Faustregel: |Schiefe| > 1 gilt als stark schief",
      ],
    },
  },
  {
    id: "woelbung",
    name: "W√∂lbung (Kurtosis)",
    category: "statistik",
    shortDefinition: "Wie 'spitz' oder 'flach' ist die Verteilung im Vergleich zur Normalverteilung?",
    quickExample: "Hohe Kurtosis: Viele Werte nahe am Mittelwert, aber auch viele Extremwerte.",
    businessTranslation: "Wie 'spitz' oder 'flach' ist die Verteilung?",
    fullExplanation: "Kurtosis misst die 'Schwere' der R√§nder (tails) einer Verteilung. Hohe Kurtosis = mehr Ausrei√üer als bei Normalverteilung. In der Praxis oft weniger wichtig als Schiefe.",
    relatedTerms: ["normalverteilung", "schiefe", "ausreisser"],
    technicalDetails: {
      formula: "Kurtosis = E[(X - Œº)‚Å¥] / œÉ‚Å¥ - 3 (Excess Kurtosis)",
      interpretation: "Kurtosis = 0: Wie Normalverteilung. > 0: Spitzer, schwerere Tails. < 0: Flacher.",
      caveats: [
        "Excess Kurtosis: Normalverteilung als Referenz (= 0)",
        "Hohe Kurtosis = mehr Extremwerte als erwartet",
        "In der Praxis: Schiefe ist oft wichtiger",
      ],
    },
  },
  {
    id: "perzentil",
    name: "Perzentil",
    category: "statistik",
    shortDefinition: "Position eines Wertes in der Verteilung. Das 90. Perzentil = 90% der Werte sind kleiner.",
    quickExample: "Kind im 85. Perzentil der Gr√∂√üe = gr√∂√üer als 85% der Gleichaltrigen.",
    businessTranslation: "Position eines Wertes in der Verteilung",
    fullExplanation: "Perzentile teilen die Daten in 100 gleiche Teile. Sie sind n√ºtzlich f√ºr Benchmarking und Vergleiche. Das 50. Perzentil ist der Median.",
    whenImportant: [
      "F√ºr Benchmarking (z.B. 'Top 10%')",
      "Bei SLA-Definitionen (z.B. '99. Perzentil der Antwortzeiten')",
      "Zur Beschreibung von Verteilungen",
    ],
    relatedTerms: ["quartil", "median"],
    technicalDetails: {
      formula: "Position des k-ten Perzentils: P = (k/100) √ó (n + 1)",
      calculation: "Bei Dezimalstellen interpolieren zwischen den benachbarten Werten",
      interpretation: "k. Perzentil: k% der Werte sind kleiner oder gleich",
      caveats: [
        "P50 = Median",
        "P25 = Q1, P75 = Q3",
        "Verschiedene Interpolationsmethoden m√∂glich",
      ],
    },
  },
  {
    id: "ausreisser",
    name: "Ausrei√üer (Outlier)",
    category: "statistik",
    shortDefinition: "Datenpunkte, die deutlich vom Rest abweichen. K√∂nnen echte Extremf√§lle oder Datenfehler sein.",
    quickExample: "Ein Kunde mit 500 Support-Tickets, w√§hrend alle anderen unter 10 haben.",
    businessTranslation: "Extremwerte ‚Äì interessant oder problematisch?",
    fullExplanation: "Der Copilot identifiziert Ausrei√üer oft mit der IQR-Methode: Werte au√üerhalb von Q1 - 1.5√óIQR bis Q3 + 1.5√óIQR gelten als Ausrei√üer. WICHTIG: Ausrei√üer sind nicht automatisch 'falsch' ‚Äì sie k√∂nnen wertvolle Erkenntnisse liefern!",
    whenImportant: [
      "In der Datenaufbereitung (Data Preparation)",
      "Zur Entscheidung: Behalten, entfernen oder separat analysieren?",
      "F√ºr Anomalie-Erkennung (z.B. Betrug)",
    ],
    relatedTerms: ["iqr", "boxplot", "median"],
    technicalDetails: {
      formula: "IQR-Methode: Ausrei√üer wenn x < Q1 - 1.5√óIQR oder x > Q3 + 1.5√óIQR",
      calculation: "Z-Score-Methode: Ausrei√üer wenn |z| > 3 (z = (x - Œº) / œÉ)",
      interpretation: "K√∂nnen Datenfehler ODER echte Extremf√§lle sein ‚Äì immer pr√ºfen!",
      caveats: [
        "Nicht automatisch l√∂schen ‚Äì erst verstehen!",
        "Bei schiefen Verteilungen kann IQR-Methode zu viele 'Ausrei√üer' finden",
        "Alternativen: MAD (Median Absolute Deviation), Isolation Forest",
      ],
    },
  },
  {
    id: "stichprobe",
    name: "Stichprobe vs. Population",
    category: "statistik",
    shortDefinition: "Stichprobe = Teil der Daten, die analysiert werden. Population = alle Daten.",
    quickExample: "1.000 befragte Kunden (Stichprobe) repr√§sentieren 1 Million Kunden (Population).",
    businessTranslation: "Teil der Daten vs. alle Daten",
    fullExplanation: "In der Praxis analysieren wir fast immer Stichproben und schlie√üen auf die Population. Dabei entsteht Unsicherheit (Standardfehler). Je gr√∂√üer die Stichprobe, desto pr√§ziser die Sch√§tzung.",
    relatedTerms: ["standardfehler", "konfidenzintervall", "zufallsstichprobe"],
    technicalDetails: {
      calculation: "Stichprobengr√∂√üe beeinflusst Pr√§zision: SE = œÉ / ‚àön",
      interpretation: "Stichprobe = Subset. Population = Gesamtheit aller m√∂glichen Beobachtungen.",
      caveats: [
        "Stichprobe muss repr√§sentativ sein (Zufallsauswahl)",
        "Systematische Fehler (Bias) k√∂nnen nicht durch gr√∂√üere n behoben werden",
        "Convenience Sampling (z.B. nur online) kann verzerren",
      ],
    },
  },

  // Visualisierungen
  {
    id: "boxplot",
    name: "Boxplot (Box-Whisker-Diagramm)",
    category: "statistik",
    shortDefinition: "Visualisierung der Verteilung: zeigt Median, Quartile, Spannweite und Ausrei√üer auf einen Blick.",
    quickExample: "Ein Boxplot der Geh√§lter zeigt sofort, dass 50% zwischen 40.000‚Ç¨ und 60.000‚Ç¨ verdienen, mit einigen sehr hohen Ausrei√üern.",
    businessTranslation: "Schneller √úberblick √ºber Datenverteilung und Ausrei√üer",
    fullExplanation: "Der Boxplot fasst eine Datenverteilung kompakt zusammen: Die Box zeigt die mittleren 50% (IQR), der Strich in der Mitte ist der Median, und die 'Whisker' zeigen die Spannweite. Punkte au√üerhalb sind Ausrei√üer.",
    whenImportant: [
      "In der Datenexploration (Phase 1 des Copilots)",
      "Zum Erkennen von Ausrei√üern",
      "Zum Vergleich von Gruppen",
    ],
    relatedTerms: ["median", "quartil", "iqr", "ausreisser"],
    technicalDetails: {
      calculation: "Box: Q1 bis Q3 | Linie in Box: Median | Whisker: bis max 1.5√óIQR | Punkte: Ausrei√üer",
      interpretation: "Box = mittlere 50% | Whisker = 'normale' Streuung | Punkte = Extremwerte",
      caveats: [
        "Versteckt die Form der Verteilung (bimodal nicht sichtbar)",
        "Whisker-Definition variiert (manche nutzen min/max statt 1.5√óIQR)",
        "Ideal zum Vergleich mehrerer Gruppen",
      ],
    },
  },
  {
    id: "histogramm",
    name: "Histogramm",
    category: "statistik",
    shortDefinition: "H√§ufigkeitsverteilung als Balken ‚Äì zeigt wie oft Werte in bestimmten Bereichen vorkommen.",
    quickExample: "Altersverteilung der Kunden: Viele 25-35, wenige √ºber 65.",
    businessTranslation: "H√§ufigkeitsverteilung als Balken",
    fullExplanation: "Ein Histogramm teilt die Daten in Bereiche (Bins) und zeigt, wie viele Werte in jedem Bereich liegen. Ideal zum Erkennen von Verteilungsform, Schiefe und Modus.",
    whenImportant: [
      "Zum Verstehen der Datenverteilung",
      "Zur Erkennung von Normalverteilung oder Schiefe",
      "F√ºr erste Datenexploration",
    ],
    relatedTerms: ["normalverteilung", "schiefe", "modus"],
    technicalDetails: {
      calculation: "Sturges-Regel: k = ‚åàlog‚ÇÇ(n) + 1‚åâ Bins. Freedman-Diaconis: Binbreite = 2 √ó IQR / n^(1/3)",
      interpretation: "Y-Achse = H√§ufigkeit oder Dichte. Form zeigt Verteilung.",
      caveats: [
        "Bin-Anzahl beeinflusst Erscheinung stark",
        "Zu wenige Bins: Details gehen verloren",
        "Zu viele Bins: Rauschen dominiert",
      ],
    },
  },
  {
    id: "scatterplot",
    name: "Scatterplot (Streudiagramm)",
    category: "statistik",
    shortDefinition: "Zusammenhang zweier Variablen als Punktwolke visualisiert.",
    quickExample: "Werbebudget (X) vs. Umsatz (Y) ‚Äì Punkte zeigen jeden Monat.",
    businessTranslation: "Zusammenhang zweier Werte als Punkte",
    fullExplanation: "Der Scatterplot zeigt jeden Datenpunkt als Punkt mit X- und Y-Koordinate. Muster wie lineare Zusammenh√§nge, Cluster oder Ausrei√üer werden sofort sichtbar.",
    whenImportant: [
      "Zur Erkennung von Zusammenh√§ngen",
      "Vor Korrelationsberechnungen",
      "Zur Identifikation von Ausrei√üern",
    ],
    relatedTerms: ["korrelation-statistik", "ausreisser", "regression"],
  },
  {
    id: "heatmap",
    name: "Heatmap",
    category: "statistik",
    shortDefinition: "Werte als Farben in einer Matrix ‚Äì je intensiver, desto h√∂her/niedriger.",
    quickExample: "Korrelationsmatrix: Rot = starke Korrelation, Blau = schwache/negative.",
    businessTranslation: "Zusammenh√§nge als Farb-Matrix",
    fullExplanation: "Heatmaps machen gro√üe Datenmengen und Muster visuell erfassbar. Besonders n√ºtzlich f√ºr Korrelationsmatrizen, zeitliche Muster und Vergleiche √ºber Kategorien.",
    whenImportant: [
      "F√ºr Korrelationsanalysen vieler Variablen",
      "Bei zeitlichen Mustern (z.B. Umsatz pro Stunde/Wochentag)",
      "F√ºr schnelle Pattern-Erkennung",
    ],
    relatedTerms: ["korrelationsmatrix", "korrelation-statistik"],
  },
  {
    id: "barplot",
    name: "Balkendiagramm (Barplot)",
    category: "statistik",
    shortDefinition: "Kategorien als Balken vergleichen ‚Äì H√∂he entspricht dem Wert.",
    quickExample: "Umsatz pro Produktkategorie: Elektronik 50%, Kleidung 30%, M√∂bel 20%.",
    businessTranslation: "Kategorien als Balken vergleichen",
    fullExplanation: "Balkendiagramme eignen sich perfekt f√ºr kategoriale Vergleiche. Horizontal oder vertikal, gruppiert oder gestapelt ‚Äì je nach Fragestellung.",
    relatedTerms: ["histogramm", "pie-chart"],
  },
  {
    id: "liniendiagramm",
    name: "Liniendiagramm",
    category: "statistik",
    shortDefinition: "Trends √ºber Zeit als verbundene Punkte darstellen.",
    quickExample: "Monatlicher Umsatz der letzten 2 Jahre ‚Üí Trend und Saisonalit√§t sichtbar.",
    businessTranslation: "Trends √ºber Zeit darstellen",
    fullExplanation: "Liniendiagramme sind ideal f√ºr Zeitreihen. Sie zeigen Trends, Saisonalit√§t und Anomalien. Mehrere Linien erm√∂glichen Vergleiche.",
    relatedTerms: ["zeitreihe", "trend", "saisonalitaet"],
  },
  {
    id: "pie-chart",
    name: "Kreisdiagramm (Pie Chart)",
    category: "statistik",
    shortDefinition: "Anteile eines Ganzen als Tortenst√ºcke visualisiert.",
    quickExample: "Marktanteile: Unternehmen A 40%, B 35%, C 25%.",
    businessTranslation: "Anteile als Kuchenst√ºcke",
    fullExplanation: "Kreisdiagramme zeigen Anteile intuitiv, sind aber bei mehr als 5-6 Kategorien oder √§hnlichen Werten schwer lesbar. Balkendiagramme sind oft die bessere Wahl.",
    badPractice: ["Mehr als 6 Kategorien in einem Pie Chart", "3D-Pie-Charts (verzerren die Wahrnehmung)"],
    goodPractice: ["Bei wenigen, deutlich unterschiedlichen Kategorien verwenden"],
    relatedTerms: ["barplot"],
  },
  {
    id: "korrelationsmatrix",
    name: "Korrelationsmatrix",
    category: "statistik",
    shortDefinition: "√úbersicht aller paarweisen Korrelationen in einer Matrix.",
    quickExample: "Welche Features h√§ngen zusammen? Matrix zeigt alle Korrelationen auf einen Blick.",
    businessTranslation: "Alle Zusammenh√§nge auf einen Blick",
    fullExplanation: "Die Korrelationsmatrix zeigt die Korrelation jeder Variable mit jeder anderen. N√ºtzlich zur Feature-Auswahl und zum Erkennen von Multikollinearit√§t.",
    whenImportant: [
      "Vor dem Modellbau (Feature-Auswahl)",
      "Zur Erkennung redundanter Features",
      "F√ºr exploratorische Analyse",
    ],
    relatedTerms: ["korrelation-statistik", "heatmap", "multikollinearitaet"],
  },

  // Datenqualit√§t
  {
    id: "datenkonsistenz",
    name: "Datenkonsistenz",
    category: "statistik",
    shortDefinition: "Sind die Daten widerspruchsfrei? Gleiche Sachverhalte sollten gleich dargestellt sein.",
    quickExample: "'Deutschland', 'DE', 'GER' f√ºr dasselbe Land ‚Üí Inkonsistenz.",
    businessTranslation: "Sind die Daten widerspruchsfrei?",
    fullExplanation: "Inkonsistente Daten f√ºhren zu fehlerhaften Analysen. Der Copilot pr√ºft auf unterschiedliche Schreibweisen, Einheiten und Formate f√ºr gleiche Sachverhalte.",
    relatedTerms: ["datenintegritaet", "duplikate"],
  },
  {
    id: "datenintegritaet",
    name: "Datenintegrit√§t",
    category: "statistik",
    shortDefinition: "Sind die Daten vollst√§ndig und korrekt? Fehlende Werte und Fehler reduzieren die Integrit√§t.",
    quickExample: "30% fehlende Werte in der Spalte 'Einkommen' ‚Üí Eingeschr√§nkte Integrit√§t.",
    businessTranslation: "Sind die Daten vollst√§ndig und korrekt?",
    fullExplanation: "Datenintegrit√§t umfasst Vollst√§ndigkeit (keine fehlenden Werte), Korrektheit (keine Fehler) und Aktualit√§t. Niedrige Integrit√§t gef√§hrdet alle Analysen.",
    relatedTerms: ["datenkonsistenz", "missing-values"],
  },
  {
    id: "duplikate",
    name: "Duplikate",
    category: "statistik",
    shortDefinition: "Mehrfach vorhandene Datens√§tze ‚Äì k√∂nnen Analysen verzerren.",
    quickExample: "Gleicher Kunde 3x in der Datenbank ‚Üí Umsatzanalyse wird verf√§lscht.",
    businessTranslation: "Mehrfach vorhandene Datens√§tze",
    fullExplanation: "Duplikate entstehen oft durch fehlerhafte Importe oder fehlende Deduplizierung. Sie verzerren Z√§hlungen, Summen und Mittelwerte.",
    relatedTerms: ["datenkonsistenz", "datenintegritaet"],
  },
  {
    id: "datentyp",
    name: "Datentyp",
    category: "statistik",
    shortDefinition: "Art der Daten: Zahl, Text, Datum, Boolean etc.",
    quickExample: "Postleitzahl als Text speichern, nicht als Zahl (sonst wird '01234' zu '1234').",
    businessTranslation: "Art der Daten (Zahl, Text, Datum)",
    fullExplanation: "Der richtige Datentyp ist entscheidend f√ºr korrekte Analysen. Zahlen als Text gespeichert k√∂nnen nicht berechnet werden, Datumswerte ohne Datumsformat k√∂nnen nicht sortiert werden.",
    relatedTerms: ["kategorische-variable", "kontinuierliche-variable"],
  },
  {
    id: "kategorische-variable",
    name: "Kategorische Variable",
    category: "statistik",
    shortDefinition: "Variable mit festen Kategorien/Gruppen (nominal oder ordinal).",
    quickExample: "Geschlecht (nominal), Kundensegment (nominal), Schulnote (ordinal).",
    businessTranslation: "Daten in Gruppen/Kategorien",
    fullExplanation: "Kategorische Variablen haben begrenzte, diskrete Auspr√§gungen. Nominal = keine Rangfolge (Farben), Ordinal = mit Rangfolge (Zufriedenheit 1-5). F√ºr ML meist Encoding n√∂tig.",
    relatedTerms: ["kontinuierliche-variable", "datentyp"],
  },
  {
    id: "kontinuierliche-variable",
    name: "Kontinuierliche Variable",
    category: "statistik",
    shortDefinition: "Variable mit flie√üenden Zahlenwerten ‚Äì kann jeden Wert in einem Bereich annehmen.",
    quickExample: "Alter, Gewicht, Temperatur, Umsatz.",
    businessTranslation: "Flie√üende Zahlenwerte",
    fullExplanation: "Kontinuierliche Variablen k√∂nnen theoretisch unendlich viele Werte annehmen. Sie werden mit Mittelwert, Standardabweichung etc. beschrieben.",
    relatedTerms: ["kategorische-variable", "mittelwert", "standardabweichung"],
  },

  // Statistische Tests
  {
    id: "hypothesentest",
    name: "Hypothesentest",
    category: "statistik",
    shortDefinition: "Statistisches Verfahren, um eine Annahme zu pr√ºfen.",
    quickExample: "Hypothese: 'Variante B konvertiert besser' ‚Üí Test: Ist der Unterschied signifikant?",
    businessTranslation: "Annahme statistisch pr√ºfen",
    fullExplanation: "Hypothesentests pr√ºfen, ob ein beobachteter Unterschied wahrscheinlich echt ist oder nur Zufall. Das Ergebnis ist meist ein p-Wert.",
    relatedTerms: ["p-wert", "nullhypothese", "signifikanzniveau"],
    technicalDetails: {
      calculation: "1. Nullhypothese H‚ÇÄ formulieren ‚Üí 2. Alternativhypothese H‚ÇÅ ‚Üí 3. Teststatistik berechnen ‚Üí 4. p-Wert bestimmen ‚Üí 5. Mit Œ± vergleichen",
      interpretation: "p < Œ±: H‚ÇÄ ablehnen (signifikant). p ‚â• Œ±: H‚ÇÄ nicht ablehnen (kein Beweis f√ºr H‚ÇÄ!)",
      caveats: [
        "Nicht ablehnen ‚â† H‚ÇÄ ist wahr",
        "Signifikanz ‚â† praktische Relevanz",
        "Multiple Testing Problem beachten",
      ],
    },
  },
  {
    id: "signifikanzniveau",
    name: "Signifikanzniveau (Alpha, Œ±)",
    category: "statistik",
    shortDefinition: "Schwelle f√ºr p-Wert ‚Äì wie sicher m√ºssen wir sein? Typisch: 5% (Œ± = 0.05).",
    quickExample: "Œ± = 0.05 bedeutet: Wir akzeptieren 5% Risiko f√ºr einen Fehlalarm (False Positive).",
    businessTranslation: "Wie sicher m√ºssen wir sein?",
    fullExplanation: "Das Signifikanzniveau ist die Fehlertoleranz bei Hypothesentests. Œ± = 0.05 ist Standard, bei kritischen Entscheidungen nutzt man oft Œ± = 0.01.",
    relatedTerms: ["p-wert", "hypothesentest", "typ-1-fehler"],
    technicalDetails: {
      formula: "Œ± = P(H‚ÇÄ ablehnen | H‚ÇÄ wahr) = P(Typ-I-Fehler)",
      interpretation: "Œ± = 0.05 ‚Üí In 5% der F√§lle lehnen wir H‚ÇÄ f√§lschlicherweise ab",
      caveats: [
        "Œ± = 0.05 ist Konvention, kein Naturgesetz",
        "Bei vielen Tests: Bonferroni-Korrektur (Œ±' = Œ±/n)",
        "Œ≤ = Typ-II-Fehler (H‚ÇÄ nicht ablehnen, obwohl falsch)",
        "Power = 1 - Œ≤ = Wahrscheinlichkeit, echten Effekt zu finden",
      ],
    },
  },
  {
    id: "nullhypothese",
    name: "Nullhypothese (H‚ÇÄ)",
    category: "statistik",
    shortDefinition: "Die Annahme, die wir zu widerlegen versuchen ‚Äì meist 'kein Effekt' oder 'kein Unterschied'.",
    quickExample: "H‚ÇÄ: 'Variante A und B haben die gleiche Conversion-Rate.'",
    businessTranslation: "Die Annahme, die wir testen",
    fullExplanation: "Die Nullhypothese nimmt an, dass es keinen Unterschied oder Effekt gibt. Wir versuchen, sie durch Daten zu widerlegen. Gelingt das nicht, hei√üt es NICHT, dass sie wahr ist!",
    relatedTerms: ["hypothesentest", "p-wert"],
    technicalDetails: {
      interpretation: "H‚ÇÄ: 'Kein Effekt' oder 'Kein Unterschied'. H‚ÇÅ (Alternativhypothese): Das Gegenteil.",
      caveats: [
        "H‚ÇÄ nicht ablehnen ‚â† H‚ÇÄ beweisen",
        "Absence of evidence ‚â† evidence of absence",
        "Einseitig (H‚ÇÅ: Œº > Œº‚ÇÄ) vs. zweiseitig (H‚ÇÅ: Œº ‚â† Œº‚ÇÄ)",
      ],
    },
  },
  {
    id: "t-test",
    name: "t-Test",
    category: "statistik",
    shortDefinition: "Test, ob zwei Mittelwerte signifikant unterschiedlich sind.",
    quickExample: "Ist der Unterschied zwischen Gruppe A (√ò 100) und B (√ò 110) statistisch signifikant?",
    businessTranslation: "Sind zwei Durchschnitte wirklich unterschiedlich?",
    fullExplanation: "Der t-Test pr√ºft, ob der Unterschied zwischen zwei Mittelwerten gr√∂√üer ist, als man bei zuf√§lligen Schwankungen erwarten w√ºrde.",
    whenImportant: [
      "Bei A/B-Tests mit kontinuierlichen Metriken",
      "Zum Vergleich von zwei Gruppen",
      "Bei kleinen Stichproben",
    ],
    relatedTerms: ["p-wert", "hypothesentest"],
    technicalDetails: {
      formula: "t = (xÃÑ‚ÇÅ - xÃÑ‚ÇÇ) / ‚àö(s‚ÇÅ¬≤/n‚ÇÅ + s‚ÇÇ¬≤/n‚ÇÇ) (Zwei-Stichproben)",
      calculation: "Ein-Stichproben: t = (xÃÑ - Œº‚ÇÄ) / (s/‚àön)",
      interpretation: "|t| gro√ü ‚Üí Unterschied wahrscheinlich nicht zuf√§llig",
      caveats: [
        "Setzt (ann√§hernde) Normalverteilung voraus",
        "Gepaart vs. ungepaart unterscheiden",
        "Bei gro√üen n: z-Test statt t-Test m√∂glich",
        "Welch's t-Test bei ungleichen Varianzen",
      ],
    },
  },
  {
    id: "chi-quadrat-test",
    name: "Chi-Quadrat-Test (œá¬≤)",
    category: "statistik",
    shortDefinition: "Test, ob zwei kategorische Variablen zusammenh√§ngen.",
    quickExample: "H√§ngt Kundensegment (A/B/C) mit Produktwahl (X/Y/Z) zusammen?",
    businessTranslation: "H√§ngen zwei Kategorien zusammen?",
    fullExplanation: "Der Chi-Quadrat-Test vergleicht beobachtete mit erwarteten H√§ufigkeiten. Signifikantes Ergebnis = die Variablen sind nicht unabh√§ngig.",
    relatedTerms: ["p-wert", "hypothesentest", "kategorische-variable"],
    technicalDetails: {
      formula: "œá¬≤ = Œ£ (O·µ¢ - E·µ¢)¬≤ / E·µ¢",
      calculation: "O = beobachtete H√§ufigkeit, E = erwartete H√§ufigkeit (unter Unabh√§ngigkeit)",
      interpretation: "Gro√ües œá¬≤ ‚Üí Beobachtung weicht stark von Erwartung ab ‚Üí Zusammenhang wahrscheinlich",
      caveats: [
        "Nur f√ºr kategorische Daten",
        "Erwartete H√§ufigkeit pro Zelle sollte ‚â• 5 sein",
        "df = (Zeilen - 1) √ó (Spalten - 1)",
      ],
    },
  },

  // Sampling & Aggregation
  {
    id: "zufallsstichprobe",
    name: "Zufallsstichprobe (Random Sample)",
    category: "statistik",
    shortDefinition: "Jedes Element hat die gleiche Chance, ausgew√§hlt zu werden.",
    quickExample: "1.000 zuf√§llig ausgew√§hlte Kunden f√ºr eine Umfrage.",
    businessTranslation: "Repr√§sentative Auswahl",
    fullExplanation: "Zufallsstichproben sind die Basis f√ºr statistische Aussagen √ºber die Gesamtheit. Ohne Zufallsauswahl k√∂nnen Ergebnisse verzerrt sein (Bias).",
    relatedTerms: ["stichprobe", "stratifiziertes-sampling", "bias-daten"],
  },
  {
    id: "stratifiziertes-sampling",
    name: "Stratifiziertes Sampling",
    category: "statistik",
    shortDefinition: "Proportionale Auswahl aus vordefinierten Gruppen (Strata).",
    quickExample: "Stichprobe soll 60% Frauen und 40% M√§nner enthalten ‚Äì wie in der Population.",
    businessTranslation: "Proportionale Auswahl aus Gruppen",
    fullExplanation: "Stratifiziertes Sampling stellt sicher, dass wichtige Untergruppen in der Stichprobe angemessen vertreten sind. Wichtig bei kleinen Stichproben oder ungleichen Gruppengr√∂√üen.",
    relatedTerms: ["zufallsstichprobe", "stichprobe"],
  },
  {
    id: "aggregation",
    name: "Aggregation",
    category: "statistik",
    shortDefinition: "Daten zusammenfassen zu Summen, Durchschnitten oder Z√§hlungen.",
    quickExample: "Einzelne Transaktionen ‚Üí Monatlicher Gesamtumsatz pro Kunde.",
    businessTranslation: "Daten zusammenfassen (Summe, Durchschnitt)",
    fullExplanation: "Aggregation verdichtet viele Datenpunkte zu wenigen Kennzahlen. Typische Funktionen: SUM, COUNT, AVG, MIN, MAX, MEDIAN.",
    relatedTerms: ["gruppierung", "mittelwert"],
  },
  {
    id: "gruppierung",
    name: "Gruppierung (Group By)",
    category: "statistik",
    shortDefinition: "Daten nach Kategorien aufteilen und separat analysieren.",
    quickExample: "Umsatz nach Region gruppieren ‚Üí Umsatz Nord, S√ºd, Ost, West.",
    businessTranslation: "Daten nach Kategorien aufteilen",
    fullExplanation: "Gruppierung erm√∂glicht Vergleiche zwischen Kategorien. In SQL: GROUP BY. Oft kombiniert mit Aggregation (z.B. Summe pro Gruppe).",
    relatedTerms: ["aggregation", "pivot-tabelle"],
  },
  {
    id: "pivot-tabelle",
    name: "Pivot-Tabelle",
    category: "statistik",
    shortDefinition: "Flexible Datenansicht: Zeilen, Spalten und Werte beliebig kombinieren.",
    quickExample: "Zeilen: Produkte, Spalten: Monate, Werte: Umsatz ‚Üí Monatlicher Umsatz pro Produkt.",
    businessTranslation: "Daten aus verschiedenen Blickwinkeln betrachten",
    fullExplanation: "Pivot-Tabellen erm√∂glichen schnelle Datenexploration ohne Programmierung. Dimensionen (Zeilen/Spalten) und Metriken (Werte) sind frei w√§hlbar.",
    relatedTerms: ["gruppierung", "aggregation"],
  },

  // Zeitreihen-Analyse
  {
    id: "zeitreihe",
    name: "Zeitreihe",
    category: "statistik",
    shortDefinition: "Datenpunkte √ºber die Zeit ‚Äì z.B. t√§gliche Ums√§tze oder monatliche Kundenzahlen.",
    quickExample: "T√§gliche Website-Besucher der letzten 12 Monate.",
    businessTranslation: "Daten √ºber die Zeit",
    fullExplanation: "Zeitreihen haben eine zeitliche Ordnung und oft Muster wie Trends, Saisonalit√§t und Zyklen. Sie erfordern spezielle Analysemethoden.",
    relatedTerms: ["trend", "saisonalitaet", "gleitender-durchschnitt"],
  },
  {
    id: "trend",
    name: "Trend",
    category: "statistik",
    shortDefinition: "Langfristige Richtung der Daten ‚Äì steigend, fallend oder stabil.",
    quickExample: "Umsatz steigt √ºber 5 Jahre um durchschnittlich 10% pro Jahr ‚Üí positiver Trend.",
    businessTranslation: "Langfristige Richtung der Daten",
    fullExplanation: "Der Trend zeigt die grundlegende Entwicklungsrichtung, bereinigt um kurzfristige Schwankungen. Wichtig f√ºr Prognosen und Strategieentscheidungen.",
    relatedTerms: ["zeitreihe", "saisonalitaet", "gleitender-durchschnitt"],
    technicalDetails: {
      calculation: "Lineare Regression: y = a + b√ót. Exponentielle: y = a √ó e^(b√ót)",
      interpretation: "b > 0: steigender Trend. b < 0: fallender Trend. b ‚âà 0: stabil.",
      caveats: [
        "Trends k√∂nnen sich √§ndern (Trendbruch)",
        "Extrapolation in die Zukunft ist riskant",
        "Saisonalit√§t kann Trend √ºberlagern",
      ],
    },
  },
  {
    id: "saisonalitaet",
    name: "Saisonalit√§t",
    category: "statistik",
    shortDefinition: "Wiederkehrende Muster in regelm√§√üigen Zeitabst√§nden.",
    quickExample: "Weihnachtsgesch√§ft: Umsatzspitze jedes Jahr im November/Dezember.",
    businessTranslation: "Wiederkehrende Muster (z.B. Weihnachtsgesch√§ft)",
    fullExplanation: "Saisonale Muster wiederholen sich regelm√§√üig (t√§glich, w√∂chentlich, j√§hrlich). Sie m√ºssen bei Prognosen ber√ºcksichtigt werden, um Verzerrungen zu vermeiden.",
    detailedExample: {
      scenario: "E-Commerce",
      explanation: "Ohne Saisonbereinigung sieht Januar wie 'Einbruch' aus ‚Äì ist aber normal nach Weihnachten.",
      numbers: "Dezember: +40%, Januar: -30% ‚Üí Saisonales Muster, kein echtes Problem",
    },
    relatedTerms: ["zeitreihe", "trend"],
    technicalDetails: {
      interpretation: "Periodische Komponente: T√§glich (24h), W√∂chentlich (7d), J√§hrlich (12M)",
      calculation: "Saisonindex = Wert / Trendwert. Saisonbereinigung: Wert / Saisonindex",
      caveats: [
        "Mindestens 2 volle Zyklen f√ºr zuverl√§ssige Sch√§tzung",
        "Saisonalit√§t kann sich √ºber Zeit √§ndern",
        "Von Kalendereffekten unterscheiden (Ostern, Feiertage)",
      ],
    },
  },
  {
    id: "gleitender-durchschnitt",
    name: "Gleitender Durchschnitt (Moving Average)",
    category: "statistik",
    shortDefinition: "Durchschnitt √ºber ein rollierendes Zeitfenster ‚Äì gl√§ttet kurzfristige Schwankungen.",
    quickExample: "7-Tage-Durchschnitt der t√§glichen Verk√§ufe zeigt den Wochentrend.",
    businessTranslation: "Gegl√§tteter Trend",
    fullExplanation: "Der gleitende Durchschnitt reduziert Rauschen und macht Trends sichtbarer. L√§ngere Fenster = st√§rkere Gl√§ttung, aber mehr Verz√∂gerung.",
    relatedTerms: ["trend", "zeitreihe"],
    technicalDetails: {
      formula: "MA(k) = (1/k) √ó Œ£x·µ¢ (√ºber k Perioden)",
      calculation: "SMA = einfacher gleitender Durchschnitt. EMA = exponentiell gewichteter (neuere Werte st√§rker).",
      interpretation: "Gl√§ttet Rauschen. Gr√∂√üeres k = mehr Gl√§ttung, aber mehr Verz√∂gerung.",
      caveats: [
        "Verliert die ersten k-1 Datenpunkte",
        "Reagiert verz√∂gert auf Trend√§nderungen",
        "EMA reagiert schneller als SMA",
      ],
    },
  },
  {
    id: "yoy",
    name: "Year-over-Year (YoY)",
    category: "statistik",
    shortDefinition: "Vergleich zum gleichen Zeitraum im Vorjahr.",
    quickExample: "Umsatz M√§rz 2024 vs. M√§rz 2023 ‚Üí YoY-Wachstum.",
    businessTranslation: "Vergleich zum Vorjahr",
    fullExplanation: "YoY-Vergleiche neutralisieren saisonale Effekte, da gleiche Monate verglichen werden. Wichtig f√ºr faire Wachstumsbewertung.",
    relatedTerms: ["saisonalitaet", "trend"],
    technicalDetails: {
      formula: "YoY-Wachstum = (Wert_aktuell - Wert_Vorjahr) / Wert_Vorjahr √ó 100%",
      calculation: "M√§rz 2024 vs. M√§rz 2023: (120.000 - 100.000) / 100.000 √ó 100% = +20%",
      interpretation: "Positiv = Wachstum, Negativ = R√ºckgang. Vergleich gleicher Monate eliminiert Saisoneffekte.",
      caveats: [
        "Anomalien im Vorjahr verzerren Vergleich",
        "Kalendereffekte beachten (Ostern, Schaltjahr)",
        "Bei neuen Produkten/M√§rkten nicht aussagekr√§ftig",
      ],
    },
  },
  {
    id: "lag",
    name: "Lag (Verz√∂gerung)",
    category: "statistik",
    shortDefinition: "Zeitversetzter Zusammenhang ‚Äì Effekt tritt sp√§ter ein als Ursache.",
    quickExample: "Marketing-Kampagne im Januar ‚Üí Umsatzsteigerung erst im Februar (Lag = 1 Monat).",
    businessTranslation: "Zeitversetzter Zusammenhang",
    fullExplanation: "Lags sind wichtig bei Zeitreihen: Eine Aktion heute kann Auswirkungen erst in Wochen oder Monaten haben. Lag-Analyse hilft, diese Verz√∂gerungen zu quantifizieren.",
    relatedTerms: ["zeitreihe", "korrelation-statistik"],
    technicalDetails: {
      calculation: "Lag-k: Korrelation zwischen x‚Çú und x‚Çú‚Çã‚Çñ (Wert k Perioden vorher)",
      interpretation: "Hohe Lag-1 Autokorrelation: Wert h√§ngt stark vom Vortag ab.",
      caveats: [
        "Autokorrelation = Korrelation einer Zeitreihe mit sich selbst (verz√∂gert)",
        "ACF-Plot zeigt Autokorrelation f√ºr verschiedene Lags",
        "Wichtig f√ºr ARIMA-Modelle",
      ],
    },
  },

  // Explorative Datenanalyse
  {
    id: "eda",
    name: "EDA (Explorative Datenanalyse)",
    category: "statistik",
    shortDefinition: "Erste Erkundung der Daten ‚Äì Muster erkennen, bevor man Modelle baut.",
    quickExample: "Verteilungen anschauen, Korrelationen pr√ºfen, Ausrei√üer identifizieren.",
    businessTranslation: "Daten erstmal kennenlernen",
    fullExplanation: "EDA ist der erste Schritt jeder Analyse: Daten verstehen, bevor man Hypothesen aufstellt oder Modelle baut. Der Copilot f√ºhrt automatisch eine EDA durch.",
    whenImportant: [
      "Zu Beginn jedes Projekts",
      "Vor dem Modellbau",
      "Zur Identifikation von Datenqualit√§tsproblemen",
    ],
    relatedTerms: ["deskriptive-statistik", "data-profiling"],
    technicalDetails: {
      calculation: "Typische EDA-Checkliste: 1. Datentypen pr√ºfen ‚Üí 2. Fehlende Werte ‚Üí 3. Verteilungen (Histogramme) ‚Üí 4. Korrelationen (Heatmap) ‚Üí 5. Ausrei√üer (Boxplots)",
      interpretation: "Ziel: Daten verstehen, Probleme erkennen, Hypothesen generieren",
      caveats: [
        "EDA ist kein Ersatz f√ºr dom√§nenspezifisches Wissen",
        "Muster k√∂nnen zuf√§llig sein ‚Äì Hypothesen separat validieren",
        "Dokumentieren, was auff√§llt!",
      ],
    },
  },
  {
    id: "deskriptive-statistik",
    name: "Deskriptive Statistik",
    category: "statistik",
    shortDefinition: "Beschreibende Kennzahlen: Mittelwert, Median, Standardabweichung etc.",
    quickExample: "F√ºr jede Spalte: Min, Max, Mittelwert, Median, Standardabweichung.",
    businessTranslation: "Was sagen die Zahlen?",
    fullExplanation: "Deskriptive Statistik fasst Daten zusammen, ohne Schl√ºsse zu ziehen. Sie beschreibt, was ist ‚Äì nicht warum oder was sein wird.",
    relatedTerms: ["eda", "mittelwert", "standardabweichung"],
  },
  {
    id: "data-profiling",
    name: "Data Profiling",
    category: "statistik",
    shortDefinition: "Automatische Analyse von Datenqualit√§t, -struktur und -inhalt.",
    quickExample: "Report zeigt: 5% fehlende Werte, 3% Duplikate, 10 numerische und 5 kategorische Spalten.",
    businessTranslation: "Automatische Daten√ºbersicht",
    fullExplanation: "Data Profiling liefert auf Knopfdruck eine √úbersicht: Datentypen, fehlende Werte, Verteilungen, Korrelationen. Der Copilot f√ºhrt das automatisch in Phase 1 durch.",
    relatedTerms: ["eda", "datenintegritaet"],
  },
  {
    id: "verteilungsanalyse",
    name: "Verteilungsanalyse",
    category: "statistik",
    shortDefinition: "Untersuchung, wie die Werte einer Variable verteilt sind.",
    quickExample: "Sind die Daten normalverteilt? Gibt es mehrere Gipfel? Wie schief ist die Verteilung?",
    businessTranslation: "Wie sind die Werte verteilt?",
    fullExplanation: "Die Verteilungsanalyse zeigt, ob Daten normalverteilt, schief, multimodal oder andersartig verteilt sind. Wichtig f√ºr die Wahl der richtigen Analysemethoden.",
    relatedTerms: ["normalverteilung", "schiefe", "histogramm"],
  },

  // === METRIKEN ===
  {
    id: "precision",
    name: "Precision",
    category: "metriken",
    shortDefinition: "Wie zuverl√§ssig sind positive Vorhersagen? Precision misst, wie oft das Modell richtig liegt, wenn es eine positive Vorhersage macht.",
    quickExample: "Von 100 als Betrug markierten Transaktionen waren tats√§chlich 80 betr√ºgerisch = 80% Precision.",
    businessTranslation: "Wie zuverl√§ssig sind positive Vorhersagen?",
    fullExplanation: "Precision misst, wie oft das Modell richtig liegt, wenn es eine positive Vorhersage macht. Bei einer Precision von 80% sind 8 von 10 positiven Vorhersagen korrekt.",
    detailedExample: {
      scenario: "Betrugserkennung",
      explanation: "Von 100 als Betrug markierten Transaktionen waren tats√§chlich 80 betr√ºgerisch.",
      numbers: "80% Precision = 80 echte Betrugsf√§lle von 100 Alarmen",
    },
    whenImportant: [
      "Wenn False Positives teuer sind (z.B. Kundenkontakt bei Fehlalarmen)",
      "Bei begrenzten Ressourcen f√ºr Nachverfolgung",
      "Wenn Vertrauen in Alarme wichtig ist",
    ],
    presentationText: "Bei einer Precision von 80% k√∂nnen wir davon ausgehen, dass 8 von 10 Alarmen echte F√§lle sind. Das reduziert unn√∂tige Nacharbeit erheblich.",
    relatedTerms: ["recall", "f1-score", "false-positive"],
    technicalDetails: {
      formula: "Precision = TP / (TP + FP)",
      interpretation: "Von allen als positiv klassifizierten F√§llen: Wie viele sind tats√§chlich positiv?",
      caveats: [
        "TP = True Positives, FP = False Positives",
        "Hohe Precision, niedriger Recall m√∂glich (konservatives Modell)",
        "Trade-off mit Recall beachten",
      ],
    },
  },
  {
    id: "recall",
    name: "Recall",
    category: "metriken",
    shortDefinition: "Wie viel Prozent der relevanten F√§lle finden wir? Bei 90% Recall werden 9 von 10 echten F√§llen erkannt.",
    quickExample: "Von 100 tats√§chlichen Krebsf√§llen erkennt das Modell 90 = 90% Recall.",
    businessTranslation: "Wie viel Prozent der relevanten F√§lle finden wir?",
    fullExplanation: "Recall misst, welchen Anteil aller tats√§chlich positiven F√§lle das Modell findet. Bei 90% Recall werden 9 von 10 echten F√§llen erkannt.",
    detailedExample: {
      scenario: "Krebsfr√ºherkennung",
      explanation: "Von 100 tats√§chlichen Krebsf√§llen erkennt das Modell 90.",
      numbers: "90% Recall = 90 erkannte von 100 echten F√§llen",
    },
    whenImportant: [
      "Wenn es kritisch ist, keine F√§lle zu √ºbersehen (Medizin, Sicherheit)",
      "Bei hohen Kosten f√ºr verpasste F√§lle",
      "In regulierten Bereichen",
    ],
    presentationText: "Mit 90% Recall finden wir 9 von 10 relevanten F√§llen. Das minimiert das Risiko, wichtige F√§lle zu √ºbersehen.",
    relatedTerms: ["precision", "f1-score", "false-negative"],
    technicalDetails: {
      formula: "Recall = TP / (TP + FN)",
      interpretation: "Von allen tats√§chlich positiven F√§llen: Wie viele wurden erkannt?",
      caveats: [
        "TP = True Positives, FN = False Negatives",
        "Auch 'Sensitivit√§t' oder 'True Positive Rate' genannt",
        "Hoher Recall kann niedrige Precision bedeuten",
      ],
    },
  },
  {
    id: "f1-score",
    name: "F1-Score",
    category: "metriken",
    shortDefinition: "Ausgewogene Gesamtbewertung des Modells ‚Äì kombiniert Precision und Recall in einer einzigen Zahl.",
    quickExample: "F1 = 0.85 bedeutet gute Balance zwischen Precision und Recall.",
    businessTranslation: "Ausgewogene Gesamtbewertung des Modells",
    fullExplanation: "Der F1-Score kombiniert Precision und Recall in einer einzigen Zahl. Er ist n√ºtzlich, wenn beide Metriken wichtig sind und man einen Trade-off finden muss.",
    detailedExample: {
      scenario: "Spam-Erkennung",
      explanation: "Wir wollen sowohl wenig Fehlalarme (Precision) als auch wenig verpasste Spam-Mails (Recall).",
      numbers: "F1 = 0.85 bedeutet gute Balance zwischen beiden",
    },
    whenImportant: [
      "Wenn sowohl False Positives als auch False Negatives Kosten verursachen",
      "Bei unausgewogenen Datens√§tzen",
      "F√ºr Modellvergleiche",
    ],
    presentationText: "Ein F1-Score von 0.85 zeigt, dass unser Modell eine gute Balance zwischen Zuverl√§ssigkeit und Vollst√§ndigkeit erreicht.",
    relatedTerms: ["precision", "recall"],
    technicalDetails: {
      formula: "F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)",
      interpretation: "Harmonisches Mittel von Precision und Recall. F1 = 1 ist perfekt, F1 = 0 wenn Precision oder Recall = 0.",
      caveats: [
        "Bei stark asymmetrischen Kosten besser gewichteten F-Score nutzen",
        "F1 ignoriert True Negatives",
        "Bei Class Imbalance aussagekr√§ftiger als Accuracy",
      ],
    },
  },
  {
    id: "auc",
    name: "AUC",
    category: "metriken",
    shortDefinition: "Wie gut unterscheidet das Modell generell? Ein Wert von 1.0 ist perfekt, 0.5 ist Zufall.",
    quickExample: "AUC 0.85 = 85% korrekte Unterscheidung zwischen guten und schlechten Kunden.",
    businessTranslation: "Wie gut unterscheidet das Modell generell?",
    fullExplanation: "AUC (Area Under Curve) misst die F√§higkeit des Modells, zwischen zwei Klassen zu unterscheiden. Ein Wert von 1.0 ist perfekt, 0.5 ist Zufall.",
    detailedExample: {
      scenario: "Kreditrisiko-Scoring",
      explanation: "AUC von 0.85 bedeutet: Bei einem zuf√§lligen Paar (guter/schlechter Kunde) ordnet das Modell in 85% der F√§lle richtig ein.",
      numbers: "AUC 0.85 = 85% korrekte Unterscheidung",
    },
    whenImportant: [
      "F√ºr die Gesamtbewertung eines Klassifikationsmodells",
      "Beim Vergleich verschiedener Modelle",
      "Wenn der optimale Threshold noch nicht festgelegt ist",
    ],
    presentationText: "Mit einer AUC von 0.85 unterscheidet unser Modell in 85% der F√§lle korrekt zwischen guten und schlechten Risiken ‚Äì deutlich besser als Zufall (50%).",
    relatedTerms: ["threshold", "precision", "recall"],
    technicalDetails: {
      formula: "AUC = ‚à´ TPR d(FPR) = Fl√§che unter der ROC-Kurve",
      interpretation: "Wahrscheinlichkeit, dass ein zuf√§lliger positiver Fall h√∂her gerankt wird als ein negativer",
      caveats: [
        "AUC = 0.5: Nicht besser als Zufall",
        "AUC 0.7-0.8: Akzeptabel | 0.8-0.9: Gut | > 0.9: Sehr gut",
        "Unabh√§ngig vom gew√§hlten Threshold",
        "Bei stark unbalancierten Klassen: PR-AUC bevorzugen",
      ],
    },
  },
  {
    id: "accuracy",
    name: "Accuracy",
    category: "metriken",
    shortDefinition: "Gesamttrefferquote aller Vorhersagen. Bei unausgewogenen Klassen kann diese Metrik irref√ºhrend sein.",
    quickExample: "Von 1000 gepr√ºften Produkten wurden 950 korrekt klassifiziert = 95% Accuracy.",
    businessTranslation: "Gesamttrefferquote aller Vorhersagen",
    fullExplanation: "Accuracy zeigt den Anteil korrekter Vorhersagen an allen Vorhersagen. Bei unausgewogenen Klassen kann diese Metrik irref√ºhrend sein.",
    detailedExample: {
      scenario: "Produktqualit√§tspr√ºfung",
      explanation: "Von 1000 gepr√ºften Produkten wurden 950 korrekt klassifiziert.",
      numbers: "95% Accuracy = 950 von 1000 richtig",
    },
    whenImportant: [
      "Bei ausgewogenen Klassen (50/50 Verteilung)",
      "F√ºr einfache Kommunikation mit Stakeholdern",
      "Als Einstiegsmetrik",
    ],
    presentationText: "Unser Modell erreicht 95% Accuracy ‚Äì allerdings sollten wir bei seltenen Ereignissen auch Precision und Recall betrachten.",
    relatedTerms: ["precision", "recall", "baseline"],
    technicalDetails: {
      formula: "Accuracy = (TP + TN) / (TP + TN + FP + FN)",
      interpretation: "Anteil aller korrekten Klassifikationen (positiv und negativ)",
      caveats: [
        "‚ö†Ô∏è ACHTUNG: Bei unbalancierten Klassen irref√ºhrend!",
        "99% Accuracy bei 1% positiver Klasse = trivial ('immer negativ' erreicht 99%)",
        "Immer mit Baseline vergleichen",
        "Bei Imbalance: F1-Score, Precision, Recall bevorzugen",
      ],
    },
  },
  {
    id: "precision-at-k",
    name: "Precision@K",
    category: "metriken",
    shortDefinition: "Von den Top-K Vorhersagen: Wie viele waren korrekt?",
    quickExample: "Precision@200 = 52% bedeutet: Von 200 Angerufenen k√ºndigen 104 wirklich.",
    businessTranslation: "Wie viele der Top-K Vorhersagen sind korrekt?",
    fullExplanation: "Precision@K misst, wie viele der K am h√∂chsten bewerteten F√§lle tats√§chlich positiv sind. N√ºtzlich bei begrenzten Ressourcen f√ºr die Bearbeitung.",
    detailedExample: {
      scenario: "Kampagnenmarketing",
      explanation: "Wir k√∂nnen nur 1000 Kunden anrufen. Precision@1000 zeigt, wie viele davon wirklich kaufbereit sind.",
      numbers: "Precision@1000 = 45% ‚Üí 450 von 1000 angerufenen Kunden kaufen",
    },
    whenImportant: [
      "Bei begrenzten Ressourcen",
      "F√ºr Kampagnenplanung",
      "Bei Ranking-Aufgaben",
    ],
    presentationText: "Bei den Top-1000 Kunden erreichen wir eine Trefferquote von 45% ‚Äì das ist 9x besser als zuf√§llige Auswahl.",
    relatedTerms: ["precision", "lift", "threshold"],
    technicalDetails: {
      formula: "Precision@K = TP_in_Top_K / K",
      calculation: "Top K Vorhersagen nach Score sortieren, z√§hlen wie viele tats√§chlich positiv sind",
      interpretation: "Praktisch relevant: 'Von meinen Top-200, wie viele sind echte Treffer?'",
      caveats: [
        "K sollte zur Kapazit√§t passen (z.B. 200 Anrufe/Tag)",
        "Verschiedene K vergleichen (Precision@100, @500, @1000)",
        "Besonders n√ºtzlich bei begrenzten Ressourcen",
      ],
    },
  },
  {
    id: "lift",
    name: "Lift",
    category: "metriken",
    shortDefinition: "Wie viel besser ist das Modell als Zufall? Ein Lift von 3 bedeutet 3x besser als zuf√§llige Auswahl.",
    quickExample: "Zuf√§llig: 5% K√§ufer. Mit Modell: 15% K√§ufer. Lift = 3x.",
    businessTranslation: "Wie viel besser ist das Modell als Zufall?",
    fullExplanation: "Lift vergleicht die Performance des Modells mit einer zuf√§lligen Auswahl. Ein Lift von 3 bedeutet, dass das Modell 3x besser ist als Zufall.",
    detailedExample: {
      scenario: "Cross-Selling",
      explanation: "Zuf√§llig ausgew√§hlte Kunden kaufen zu 5%. Vom Modell ausgew√§hlte kaufen zu 15%.",
      numbers: "Lift = 15% / 5% = 3x",
    },
    whenImportant: [
      "F√ºr ROI-Berechnungen",
      "Zur Kommunikation des Modellwerts",
      "Bei begrenzten Budgets",
    ],
    presentationText: "Mit einem Lift von 3x erreichen wir mit demselben Budget dreimal so viele interessierte Kunden wie bei zuf√§lliger Auswahl.",
    relatedTerms: ["baseline", "precision-at-k"],
    technicalDetails: {
      formula: "Lift = Precision_Modell / Baseline_Rate",
      calculation: "Beispiel: 15% K√§ufer bei Modell-Auswahl / 5% K√§ufer bei Zufall = Lift 3.0",
      interpretation: "Lift = 1: Nicht besser als Zufall. Lift > 1: Modell ist besser.",
      caveats: [
        "Lift sinkt typischerweise mit gr√∂√üerem K",
        "Gain Chart / Lift Chart visualisiert Lift √ºber verschiedene K",
        "Wichtig f√ºr ROI-Berechnungen",
      ],
    },
  },
  {
    id: "mae",
    name: "MAE",
    category: "metriken",
    shortDefinition: "Mean Absolute Error ‚Äì durchschnittliche Abweichung der Vorhersage. Einfach interpretierbar.",
    quickExample: "MAE = 5.000‚Ç¨ bedeutet: Vorhersage weicht im Schnitt 5.000‚Ç¨ vom echten Umsatz ab.",
    businessTranslation: "Durchschnittliche Abweichung der Vorhersage",
    fullExplanation: "MAE (Mean Absolute Error) misst die durchschnittliche Abweichung zwischen Vorhersage und tats√§chlichem Wert. Einfach interpretierbar in Originaleinheiten.",
    detailedExample: {
      scenario: "Umsatzprognose",
      explanation: "MAE von 5.000‚Ç¨ bedeutet, dass die Vorhersage im Schnitt 5.000‚Ç¨ vom echten Umsatz abweicht.",
      numbers: "MAE = 5.000‚Ç¨ bei durchschnittlichem Umsatz von 100.000‚Ç¨",
    },
    whenImportant: [
      "Bei Regressionsaufgaben",
      "F√ºr intuitive Kommunikation",
      "Wenn alle Fehler gleich gewichtet werden sollen",
    ],
    presentationText: "Unsere Umsatzprognose weicht im Schnitt um 5.000‚Ç¨ ab ‚Äì das entspricht 5% des durchschnittlichen Monatsumsatzes.",
    relatedTerms: ["rmse"],
    technicalDetails: {
      formula: "MAE = (1/n) √ó Œ£|y·µ¢ - ≈∑·µ¢|",
      interpretation: "Durchschnitt der absoluten Fehler. In Originaleinheit interpretierbar.",
      caveats: [
        "Alle Fehler gleich gewichtet (linear)",
        "Robust gegen Ausrei√üer (im Vergleich zu RMSE)",
        "Kann nicht differenziert werden (f√ºr Gradientenoptimierung)",
      ],
    },
  },
  {
    id: "rmse",
    name: "RMSE",
    category: "metriken",
    shortDefinition: "Root Mean Squared Error ‚Äì Fehlermetrik, die gro√üe Abweichungen st√§rker bestraft.",
    quickExample: "RMSE = 50 Einheiten ‚Äì gro√üe Fehlprognosen fallen st√§rker ins Gewicht.",
    businessTranslation: "Fehlermetrik, die gro√üe Abweichungen st√§rker bestraft",
    fullExplanation: "RMSE (Root Mean Squared Error) gewichtet gro√üe Fehler st√§rker als kleine. N√ºtzlich, wenn gro√üe Abweichungen besonders problematisch sind.",
    detailedExample: {
      scenario: "Bestandsprognose",
      explanation: "RMSE von 50 Einheiten, wobei gro√üe Fehlvorhersagen (z.B. 200 statt 100) st√§rker ins Gewicht fallen.",
      numbers: "RMSE = 50 Einheiten bei Durchschnitt von 500",
    },
    whenImportant: [
      "Wenn gro√üe Fehler kritisch sind",
      "Bei Bestandsplanung (Ausverkauft vs. leichte √úberbest√§nde)",
      "F√ºr Optimierung auf weniger extreme Fehler",
    ],
    presentationText: "Mit einem RMSE von 50 Einheiten sind extreme Fehlprognosen selten ‚Äì das sch√ºtzt vor teuren Ausverkauft-Situationen.",
    relatedTerms: ["mae"],
    technicalDetails: {
      formula: "RMSE = ‚àö[(1/n) √ó Œ£(y·µ¢ - ≈∑·µ¢)¬≤]",
      interpretation: "Wurzel des mittleren quadratischen Fehlers. In Originaleinheit.",
      caveats: [
        "Gro√üe Fehler werden quadratisch bestraft",
        "Empfindlich gegen√ºber Ausrei√üern",
        "RMSE ‚â• MAE (immer)",
        "Differenzierbar (gut f√ºr Optimierung)",
      ],
    },
  },

  // === FEHLER ===
  {
    id: "false-positive",
    name: "False Positive",
    category: "fehler",
    shortDefinition: "Fehlalarm ‚Äì das Modell sagt 'positiv', aber der Fall ist tats√§chlich negativ.",
    quickExample: "Eine legitime Transaktion wird als Betrug markiert und blockiert.",
    businessTranslation: "Fehlalarm ‚Äì das Modell liegt falsch positiv",
    fullExplanation: "Ein False Positive tritt auf, wenn das Modell 'positiv' vorhersagt, der Fall aber tats√§chlich negativ ist. Diese Fehler verursachen oft unn√∂tige Aktionen.",
    detailedExample: {
      scenario: "Betrugserkennung",
      explanation: "Eine legitime Transaktion wird als Betrug markiert und blockiert.",
      numbers: "100 False Positives = 100 ver√§rgerte legitime Kunden",
    },
    whenImportant: [
      "Wenn Fehlalarme Kosten verursachen (Kundenfrustration, manuelle Pr√ºfung)",
      "Bei begrenzten Ressourcen f√ºr Nachverfolgung",
      "In kundennahen Prozessen",
    ],
    presentationText: "Durch die Optimierung auf weniger False Positives reduzieren wir Kundenfrustration, ohne kritische F√§lle zu √ºbersehen.",
    relatedTerms: ["precision", "false-negative", "threshold"],
    technicalDetails: {
      formula: "FPR (False Positive Rate) = FP / (FP + TN)",
      interpretation: "Je mehr False Positives, desto niedriger die Precision.",
      caveats: [
        "FP verursachen Kosten: manuelle Pr√ºfung, Kundenfrustration",
        "Trade-off: Weniger FP = oft mehr FN",
        "Threshold nach oben = weniger FP, aber auch weniger TP",
      ],
    },
  },
  {
    id: "false-negative",
    name: "False Negative",
    category: "fehler",
    shortDefinition: "√úbersehener Fall ‚Äì das Modell sagt 'negativ', obwohl der Fall positiv ist.",
    quickExample: "Ein Patient mit Krebs wird als gesund eingestuft.",
    businessTranslation: "√úbersehener Fall ‚Äì das Modell erkennt nicht",
    fullExplanation: "Ein False Negative ist ein tats√§chlich positiver Fall, den das Modell √ºbersieht. Diese Fehler sind oft kritischer als False Positives.",
    detailedExample: {
      scenario: "Krebsfr√ºherkennung",
      explanation: "Ein Patient mit Krebs wird als gesund eingestuft.",
      numbers: "5 False Negatives = 5 verpasste Diagnosen",
    },
    whenImportant: [
      "Bei hohen Kosten f√ºr verpasste F√§lle (Gesundheit, Sicherheit)",
      "In regulierten Bereichen",
      "Wenn Recall Priorit√§t hat",
    ],
    presentationText: "Wir haben die False Negative Rate auf unter 5% gesenkt, um sicherzustellen, dass wir kaum kritische F√§lle √ºbersehen.",
    relatedTerms: ["recall", "false-positive", "threshold"],
    technicalDetails: {
      formula: "FNR (False Negative Rate) = FN / (FN + TP) = 1 - Recall",
      interpretation: "Je mehr False Negatives, desto niedriger der Recall.",
      caveats: [
        "FN sind oft kritischer als FP (verpasste Diagnose > Fehlalarm)",
        "Trade-off: Weniger FN = oft mehr FP",
        "Threshold nach unten = weniger FN, aber mehr FP",
      ],
    },
  },
  {
    id: "overfitting",
    name: "Overfitting",
    category: "fehler",
    shortDefinition: "Das Modell lernt Trainingsdaten auswendig statt Muster zu erkennen ‚Äì funktioniert bei neuen Daten schlechter.",
    quickExample: "Training: 98% Genauigkeit ‚Üí Produktion: 60% Genauigkeit.",
    businessTranslation: "Das Modell lernt Trainingsdaten auswendig statt Muster",
    fullExplanation: "Overfitting bedeutet, dass ein Modell auf Trainingsdaten sehr gut funktioniert, aber bei neuen Daten versagt. Es hat Zufallsmuster statt echter Zusammenh√§nge gelernt.",
    detailedExample: {
      scenario: "Umsatzprognose",
      explanation: "Das Modell erreicht 98% Genauigkeit auf historischen Daten, aber nur 60% auf neuen Monatsdaten.",
      numbers: "Training: 98% ‚Üí Produktion: 60%",
    },
    whenImportant: [
      "Bei gro√üem Performance-Unterschied zwischen Training und Test",
      "Wenn das Modell in Produktion schlechter wird",
      "Bei kleinen Datens√§tzen",
    ],
    presentationText: "Wir haben Overfitting durch Kreuzvalidierung verhindert ‚Äì das Modell zeigt stabile 75% Genauigkeit sowohl auf Trainings- als auch auf Testdaten.",
    relatedTerms: ["training", "drift", "cross-validation"],
    technicalDetails: {
      interpretation: "Training-Accuracy >> Test-Accuracy = Overfitting. Beides niedrig = Underfitting.",
      calculation: "Erkennung: Vergleich Training- vs. Validation-Performance",
      caveats: [
        "Mehr Daten helfen gegen Overfitting",
        "Regularisierung (L1/L2) reduziert Overfitting",
        "Simpler Modelle neigen weniger zu Overfitting",
        "Early Stopping bei neuronalen Netzen",
      ],
    },
  },
  {
    id: "drift",
    name: "Drift",
    category: "fehler",
    shortDefinition: "Ver√§nderung der Daten oder Zusammenh√§nge √ºber Zeit ‚Äì das Modell passt nicht mehr zur Realit√§t.",
    quickExample: "Nach 3 Monaten sank die Precision von 52% auf 43% ‚Äì wahrscheinlich Drift.",
    businessTranslation: "Die Realit√§t √§ndert sich, das Modell nicht",
    fullExplanation: "Model Drift tritt auf, wenn sich die Beziehung zwischen Eingabedaten und Vorhersagen im Laufe der Zeit √§ndert. Das Modell verliert an Genauigkeit.",
    detailedExample: {
      scenario: "Nachfrageprognose w√§hrend COVID",
      explanation: "Ein Modell, das auf 2019-Daten trainiert wurde, versagt bei der Vorhersage f√ºr 2020.",
      numbers: "Accuracy sinkt von 85% auf 50% √ºber 6 Monate",
    },
    whenImportant: [
      "Nach signifikanten Marktver√§nderungen",
      "Bei saisonalen Gesch√§ften",
      "In dynamischen Umgebungen",
    ],
    presentationText: "Wir √ºberwachen kontinuierlich auf Drift und trainieren das Modell quartalsweise neu, um die Genauigkeit √ºber 80% zu halten.",
    relatedTerms: ["training", "overfitting", "monitoring"],
    subtypes: [
      { name: "Data Drift", description: "Feature-Verteilungen √§ndern sich (z.B. neue Tarife eingef√ºhrt)" },
      { name: "Concept Drift", description: "Der Zusammenhang zwischen Features und Ziel √§ndert sich (z.B. Wettbewerber-Angebote √§ndern K√ºndigungsverhalten)" },
    ],
    tip: "Vor dem Nachtrainieren erst analysieren ‚Äì blindes Nachtrainieren kann das Problem verschlimmern!",
    technicalDetails: {
      interpretation: "Data Drift: Feature-Verteilungen √§ndern sich. Concept Drift: Zusammenhang Feature‚ÜíLabel √§ndert sich.",
      calculation: "Erkennung: PSI (Population Stability Index), KS-Test, Performance-Monitoring",
      caveats: [
        "Sudden Drift (pl√∂tzlich) vs. Gradual Drift (schleichend)",
        "Nicht jeder Drift erfordert Retraining",
        "Erst analysieren, dann entscheiden ob/wie Retraining",
      ],
    },
  },
  {
    id: "data-leakage",
    name: "Data Leakage",
    category: "fehler",
    shortDefinition: "Du nutzt versehentlich Informationen, die du zur Vorhersagezeit noch nicht h√§ttest.",
    quickExample: "Feature 'K√ºndigungsgrund' ‚Üí Den kennst du erst NACH der K√ºndigung!",
    businessTranslation: "Illegitimes Wissen aus der Zukunft oder dem Ziel",
    fullExplanation: "Data Leakage bedeutet, dass das Modell Informationen nutzt, die in der Praxis zum Vorhersagezeitpunkt nicht verf√ºgbar w√§ren. Das f√ºhrt zu unrealistisch guten Ergebnissen.",
    detailedExample: {
      scenario: "Churn-Vorhersage",
      explanation: "Das Modell nutzt 'K√ºndigungsdatum' als Feature ‚Äì Information, die erst nach der K√ºndigung existiert.",
      numbers: "Mit Leakage: 99% Accuracy ‚Üí Ohne: 70%",
    },
    whenImportant: [
      "Bei verd√§chtig guten Ergebnissen",
      "Vor dem Produktiveinsatz",
      "Bei Feature-Auswahl",
    ],
    presentationText: "Wir haben alle Features auf temporale Leakage gepr√ºft ‚Äì das Modell nutzt nur Daten, die zum Vorhersagezeitpunkt verf√ºgbar sind.",
    relatedTerms: ["feature", "training", "overfitting"],
    badPractice: [
      "Feature \"K√ºndigungsgrund\" ‚Üí Den kennst du erst NACH der K√ºndigung!",
      "Feature \"Letzte Rechnung = 0 ‚Ç¨\" ‚Üí Kann bedeuten, Vertrag ist bereits beendet.",
    ],
    goodPractice: [
      "\"Zahlungsverzug in den letzten 3 Monaten\" ‚Üí War VOR der K√ºndigung bekannt.",
    ],
    tip: "Frage dich bei jedem Feature: \"H√§tte ich diese Info zum Vorhersagezeitpunkt schon?\"",
    technicalDetails: {
      interpretation: "Target Leakage: Information aus dem Ziel. Temporal Leakage: Information aus der Zukunft.",
      caveats: [
        "Leakage f√ºhrt zu unrealistisch guten Metriken",
        "In Produktion funktioniert das Modell dann nicht",
        "Alle Features einzeln auf Leakage pr√ºfen!",
        "Verd√§chtig: Features mit perfekter Korrelation zum Ziel",
      ],
    },
  },
  {
    id: "confusion-matrix",
    name: "Confusion Matrix",
    category: "fehler",
    shortDefinition: "√úbersicht aller Vorhersagetypen: True Positives, False Positives, True Negatives, False Negatives.",
    quickExample: "TP=80, FP=50, TN=850, FN=20 bei 1000 Transaktionen.",
    businessTranslation: "√úbersicht aller Vorhersagetypen (richtig/falsch)",
    fullExplanation: "Die Confusion Matrix zeigt alle vier Kombinationen aus Vorhersage und Realit√§t: True Positives, False Positives, True Negatives, False Negatives.",
    detailedExample: {
      scenario: "Betrugserkennung bei 1000 Transaktionen",
      explanation: "TP: 80 (Betrug erkannt), FP: 50 (Fehlalarm), TN: 850 (korrekt OK), FN: 20 (Betrug √ºbersehen)",
      numbers: "TP=80, FP=50, TN=850, FN=20",
    },
    whenImportant: [
      "F√ºr detaillierte Modellbewertung",
      "Zur Berechnung von Precision/Recall",
      "Bei der Threshold-Optimierung",
    ],
    presentationText: "Von 100 Betrugsf√§llen erkennen wir 80, bei 50 Fehlalarmen. Die 20 verpassten F√§lle analysieren wir n√§her.",
    relatedTerms: ["false-positive", "false-negative", "precision", "recall"],
    technicalDetails: {
      calculation: "Matrix 2√ó2: Zeilen = Tats√§chlich (P/N), Spalten = Vorhergesagt (P/N)",
      interpretation: "TP: Richtig positiv | FP: Falsch positiv (Fehlalarm) | TN: Richtig negativ | FN: Falsch negativ (√ºbersehen)",
      caveats: [
        "Precision = TP / (TP + FP)",
        "Recall = TP / (TP + FN)",
        "Accuracy = (TP + TN) / (TP + TN + FP + FN)",
        "Spezifit√§t = TN / (TN + FP)",
      ],
    },
  },

  // === MODELL & DATEN ===
  {
    id: "feature",
    name: "Feature",
    category: "modell",
    shortDefinition: "Eingabevariable ‚Äì ein Datenpunkt, den das Modell zur Vorhersage nutzt.",
    quickExample: "Features k√∂nnten sein: Alter, Einkommen, Zahlungshistorie, Besch√§ftigungsdauer.",
    businessTranslation: "Eingabevariable ‚Äì was das Modell zur Vorhersage nutzt",
    fullExplanation: "Features sind die Datenpunkte, die ein Modell f√ºr seine Vorhersagen verwendet. Die Qualit√§t und Relevanz der Features bestimmt ma√ügeblich die Modellqualit√§t.",
    detailedExample: {
      scenario: "Kreditscoring",
      explanation: "Features k√∂nnten sein: Alter, Einkommen, bisherige Zahlungshistorie, Besch√§ftigungsdauer.",
      numbers: "20 Features ‚Üí nach Selektion: 8 relevante Features",
    },
    whenImportant: [
      "Bei der Datenanforderung",
      "F√ºr Erkl√§rbarkeit des Modells",
      "Bei Compliance-Anforderungen (welche Daten werden genutzt?)",
    ],
    presentationText: "Unser Modell nutzt 8 Kernfeatures, die wir mit dem Fachbereich abgestimmt haben. Die wichtigsten sind Zahlungshistorie und Besch√§ftigungsdauer.",
    relatedTerms: ["label", "feature-importance", "data-leakage"],
  },
  {
    id: "feature-engineering",
    name: "Feature Engineering",
    category: "modell",
    shortDefinition: "Das Erstellen neuer Variablen aus Rohdaten, um die Vorhersagekraft zu verbessern.",
    quickExample: "Aus 'letzter Login' und 'heute' berechnen wir 'Tage seit letztem Login'.",
    businessTranslation: "Neue Variablen aus Rohdaten erstellen",
    fullExplanation: "Feature Engineering ist die Kunst, aus vorhandenen Daten neue, aussagekr√§ftigere Variablen zu erstellen, die dem Modell helfen, bessere Vorhersagen zu treffen.",
    whenImportant: [
      "Wenn Rohdaten allein nicht aussagekr√§ftig genug sind",
      "F√ºr Dom√§nenwissen im Modell",
      "Zur Verbesserung der Modellperformance",
    ],
    relatedTerms: ["feature", "data-leakage"],
    technicalDetails: {
      calculation: "Techniken: Binning, Log-Transformation, Interaktions-Features, Zeitbasierte Features",
      interpretation: "Gutes Feature Engineering kann Performance mehr verbessern als Modellwahl",
      caveats: [
        "Dom√§nenwissen ist entscheidend",
        "Auf Data Leakage achten",
        "Nicht zu viele Features ‚Üí Curse of Dimensionality",
        "Features m√ºssen zur Produktionsumgebung passen",
      ],
    },
  },
  {
    id: "label",
    name: "Label (Zielvariable)",
    category: "modell",
    shortDefinition: "Das, was dein Modell vorhersagen soll ‚Äì die Zielgr√∂√üe.",
    quickExample: "Label: 'Kunde hat aktiv gek√ºndigt UND Vertrag endet in 30-60 Tagen'.",
    businessTranslation: "Die Zielgr√∂√üe ‚Äì was wir vorhersagen wollen",
    fullExplanation: "Das Label ist die Variable, die das Modell lernen soll vorherzusagen. Die Definition des Labels bestimmt, was das Modell optimiert.",
    detailedExample: {
      scenario: "Kundenabwanderung",
      explanation: "Label: 'Hat der Kunde innerhalb von 90 Tagen gek√ºndigt?' (Ja/Nein)",
      numbers: "5% der Kunden mit Label 'Ja' (gek√ºndigt)",
    },
    whenImportant: [
      "Bei der Problemdefinition",
      "F√ºr klare Erfolgskriterien",
      "Bei der Datenvorbereitung",
    ],
    presentationText: "Wir definieren 'Abwanderung' als keine Bestellung in 90 Tagen ‚Äì diese klare Definition erm√∂glicht eine pr√§zise Modellbewertung.",
    relatedTerms: ["feature", "baseline"],
    badPractice: ["\"Kunde ist weg\" ‚Üí Zu ungenau. Vertragspause? Umzug? Tod?"],
    goodPractice: ["\"Kunde hat aktiv gek√ºndigt UND Vertrag endet in 30‚Äì60 Tagen\""],
    tip: "Frage immer: Wann genau gilt ein Fall als positiv?",
  },
  {
    id: "training",
    name: "Training",
    category: "modell",
    shortDefinition: "Das Modell lernt aus historischen Daten, um Muster zu erkennen.",
    quickExample: "Training mit 100.000 Datenpunkten √ºber 3 Jahre f√ºr Nachfrageprognose.",
    businessTranslation: "Das Modell lernt aus historischen Daten",
    fullExplanation: "Beim Training analysiert das Modell historische Daten, um Muster zu erkennen. Die Qualit√§t des Trainings h√§ngt von Datenmenge, -qualit√§t und -relevanz ab.",
    detailedExample: {
      scenario: "Nachfrageprognose",
      explanation: "Das Modell lernt aus 3 Jahren historischer Verkaufsdaten, welche Faktoren die Nachfrage beeinflussen.",
      numbers: "Training mit 100.000 Datenpunkten √ºber 3 Jahre",
    },
    whenImportant: [
      "Bei der Planung von Datensammlungen",
      "F√ºr das Verst√§ndnis von Modellaktualisierungen",
      "Bei Performance-Diskussionen",
    ],
    presentationText: "Das Modell wurde auf 3 Jahren historischer Daten trainiert und erfasst dadurch saisonale Muster und Trends.",
    relatedTerms: ["overfitting", "drift", "feature"],
  },
  {
    id: "threshold",
    name: "Threshold",
    category: "modell",
    shortDefinition: "Ab welchem Score handeln wir? Der Schwellenwert steuert Precision vs. Recall.",
    quickExample: "Threshold 0.5: mehr Alarme, mehr Fehlalarme. Threshold 0.8: weniger, aber sicherere Alarme.",
    businessTranslation: "Ab welchem Score handeln wir?",
    fullExplanation: "Der Threshold (Schwellenwert) bestimmt, ab welcher Modell-Wahrscheinlichkeit eine positive Vorhersage ausgel√∂st wird. Er steuert das Verh√§ltnis zwischen Precision und Recall.",
    detailedExample: {
      scenario: "Betrugserkennung",
      explanation: "Bei Threshold 0.5: Mehr Alarme, mehr False Positives. Bei 0.8: Weniger Alarme, aber sicherere.",
      numbers: "Threshold 0.5 ‚Üí 80% Recall, 60% Precision | Threshold 0.8 ‚Üí 50% Recall, 90% Precision",
    },
    whenImportant: [
      "Bei der Business-Integration",
      "Zur Steuerung von Precision/Recall",
      "F√ºr Kapazit√§tsplanung (wie viele F√§lle m√ºssen bearbeitet werden?)",
    ],
    presentationText: "Wir haben den Threshold auf 0.7 gesetzt ‚Äì das optimiert f√ºr weniger Fehlalarme bei akzeptabler Erkennungsrate, passend zu unseren Kapazit√§ten.",
    relatedTerms: ["precision", "recall", "auc"],
    technicalDetails: {
      calculation: "Vorhersage = 'Positiv' wenn Score ‚â• Threshold, sonst 'Negativ'",
      interpretation: "Hoher Threshold ‚Üí weniger Positiv-Vorhersagen ‚Üí h√∂here Precision, niedrigerer Recall",
      caveats: [
        "Standard: 0.5, aber oft nicht optimal",
        "Optimalen Threshold anhand Business-Kosten w√§hlen",
        "PR-Kurve oder ROC-Kurve zur Threshold-Wahl nutzen",
        "Threshold kann nach Deployment angepasst werden",
      ],
    },
  },
  {
    id: "baseline",
    name: "Baseline",
    category: "modell",
    shortDefinition: "Ein einfaches Referenzmodell, gegen das komplexere Modelle verglichen werden.",
    quickExample: "'Kunden mit Beschwerde = Risiko' erreicht 40% Precision. ML muss das schlagen.",
    businessTranslation: "Der Vergleichsma√üstab ‚Äì was passiert ohne Modell?",
    fullExplanation: "Die Baseline ist der einfachste Benchmark, oft das Ergebnis einer naiven Strategie wie 'immer die h√§ufigste Klasse vorhersagen' oder der aktuelle manuelle Prozess.",
    detailedExample: {
      scenario: "Kundenabwanderung",
      explanation: "Ohne Modell k√∂nnten wir alle Kunden anrufen (100% Recall, aber hohe Kosten) oder niemanden (0% Kosten, aber 0% Pr√§vention).",
      numbers: "Baseline: 5% Abwanderungsrate = naive Accuracy von 95% durch 'niemand geht'",
    },
    whenImportant: [
      "Um den Mehrwert des Modells zu demonstrieren",
      "F√ºr realistische Erwartungen",
      "Bei ROI-Berechnungen",
    ],
    presentationText: "Unsere aktuelle Baseline erkennt 30% der Abwanderer. Das Modell verbessert dies auf 75% ‚Äì das entspricht einer Verdoppelung der Kundenbindung.",
    relatedTerms: ["accuracy", "lift"],
  },
  {
    id: "feature-importance",
    name: "Feature Importance",
    category: "modell",
    shortDefinition: "Welche Faktoren beeinflussen die Vorhersage am meisten? Wichtig f√ºr Transparenz.",
    quickExample: "Top 3: Zahlungshistorie (35%), Schulden-Einkommens-Verh√§ltnis (25%), Besch√§ftigungsdauer (15%).",
    businessTranslation: "Welche Faktoren beeinflussen die Vorhersage am meisten?",
    fullExplanation: "Feature Importance zeigt, welche Eingabevariablen den gr√∂√üten Einfluss auf die Modellvorhersagen haben. Wichtig f√ºr Erkl√§rbarkeit und Vertrauen.",
    detailedExample: {
      scenario: "Kreditentscheidung",
      explanation: "Top 3 Faktoren: 1. Zahlungshistorie (35%), 2. Schulden-Einkommens-Verh√§ltnis (25%), 3. Besch√§ftigungsdauer (15%)",
      numbers: "Top 3 Features erkl√§ren 75% der Vorhersage",
    },
    whenImportant: [
      "F√ºr Modelltransparenz",
      "Bei Compliance-Anforderungen",
      "Zur Validierung mit Fachexperten",
    ],
    presentationText: "Die drei wichtigsten Faktoren f√ºr die Kreditentscheidung sind Zahlungshistorie, Schuldenquote und Besch√§ftigungsdauer ‚Äì das entspricht der Fachlogik.",
    relatedTerms: ["feature", "label"],
  },
  {
    id: "hyperparameter",
    name: "Hyperparameter",
    category: "modell",
    shortDefinition: "Stellschrauben zur Modelloptimierung ‚Äì werden vor dem Training festgelegt.",
    quickExample: "Nach Tuning: Accuracy steigt von 75% auf 82%.",
    businessTranslation: "Stellschrauben zur Modelloptimierung",
    fullExplanation: "Hyperparameter sind Einstellungen, die vor dem Training festgelegt werden und das Modellverhalten steuern. Ihre Optimierung verbessert die Performance.",
    detailedExample: {
      scenario: "Random Forest Modell",
      explanation: "Hyperparameter wie 'Anzahl B√§ume' oder 'maximale Tiefe' beeinflussen Genauigkeit und Geschwindigkeit.",
      numbers: "Nach Tuning: Accuracy steigt von 75% auf 82%",
    },
    whenImportant: [
      "Bei der Modelloptimierung",
      "F√ºr Performance-Verbesserungen",
      "Beim finalen Feinschliff",
    ],
    presentationText: "Durch Hyperparameter-Tuning konnten wir die Modellgenauigkeit um 7 Prozentpunkte steigern.",
    relatedTerms: ["training", "cross-validation", "overfitting"],
  },

  // === VALIDIERUNG ===
  {
    id: "cross-validation",
    name: "Cross-Validation",
    category: "validierung",
    shortDefinition: "Robuste Modellpr√ºfung durch mehrfaches Testen auf verschiedenen Datenteilen.",
    quickExample: "5-fache CV: Accuracy 78%, 81%, 79%, 80%, 82% ‚Üí Mittel: 80% ¬± 1.5%.",
    businessTranslation: "Robuste Modellpr√ºfung durch mehrfaches Testen",
    fullExplanation: "Cross-Validation teilt die Daten mehrfach auf und testet das Modell auf verschiedenen Teilmengen. Das gibt ein realistischeres Bild der Performance.",
    detailedExample: {
      scenario: "Modellauswahl",
      explanation: "5-fache Cross-Validation: Das Modell wird 5x auf verschiedenen 80/20 Splits getestet.",
      numbers: "Accuracy: 78%, 81%, 79%, 80%, 82% ‚Üí Mittel: 80% ¬± 1.5%",
    },
    whenImportant: [
      "F√ºr robuste Performance-Sch√§tzung",
      "Bei kleinen Datens√§tzen",
      "Beim Modellvergleich",
    ],
    presentationText: "Die Cross-Validation zeigt stabile 80% Genauigkeit √ºber alle Testdurchl√§ufe ‚Äì das Modell ist robust.",
    relatedTerms: ["overfitting", "training"],
    technicalDetails: {
      formula: "k-Fold: Daten in k Teile, k Trainingsl√§ufe mit je k-1 Teilen Training, 1 Teil Test",
      calculation: "Endergebnis = Mittelwert der k Durchl√§ufe ¬± Standardabweichung",
      interpretation: "Geringe Streuung = robustes Modell. Hohe Streuung = instabil.",
      caveats: [
        "Typisch: k = 5 oder k = 10",
        "Leave-One-Out: k = n (sehr rechenintensiv)",
        "Stratified CV bei unbalancierten Klassen",
      ],
    },
  },
  {
    id: "ab-test",
    name: "A/B-Test",
    category: "validierung",
    shortDefinition: "Kontrollierter Vergleich zweier Varianten in Produktion mit echten Nutzern.",
    quickExample: "Gruppe A: 3% Conversion. Gruppe B (mit ML): 4.5% = 50% Steigerung.",
    businessTranslation: "Kontrollierter Vergleich zweier Varianten in Produktion",
    fullExplanation: "Ein A/B-Test vergleicht zwei Versionen (z.B. mit und ohne Modell) auf echten Nutzern, um den tats√§chlichen Gesch√§ftseffekt zu messen.",
    detailedExample: {
      scenario: "Produktempfehlungen",
      explanation: "Gruppe A: Bestseller-Empfehlungen, Gruppe B: ML-basierte Empfehlungen. Vergleich der Kaufrate.",
      numbers: "A: 3% Conversion ‚Üí B: 4.5% Conversion = 50% Steigerung",
    },
    whenImportant: [
      "Vor dem Produktivgang neuer Modelle",
      "Zur Messung des tats√§chlichen Business-Impacts",
      "Bei kritischen Entscheidungen",
    ],
    presentationText: "Im A/B-Test hat das neue Modell die Conversion-Rate um 50% gesteigert ‚Äì bei statistischer Signifikanz von 95%.",
    relatedTerms: ["baseline", "lift"],
  },
  {
    id: "test-production",
    name: "Test ‚â† Production",
    category: "validierung",
    shortDefinition: "Kritische Erkenntnis: 52% Precision im Test bedeutet nicht 52% in Production!",
    quickExample: "Im Test 52% Precision ‚Äì in Production nur noch 47%. Typisch!",
    problems: [
      "Test-Daten nicht repr√§sentativ",
      "Overfitting auf Testdaten",
      "Daten √§ndern sich √ºber Zeit (Drift)",
    ],
    tip: "Erst der A/B-Test in Production zeigt den wahren Wert!",
    relatedTerms: ["ab-test", "drift", "overfitting"],
  },

  // === PROJEKT & PROZESS ===
  {
    id: "crisp-dm",
    name: "CRISP-DM",
    category: "projekt",
    shortDefinition: "Cross-Industry Standard Process for Data Mining ‚Äì ein standardisiertes Vorgehensmodell mit 6 Phasen.",
    quickExample: "Wir sind gerade in Phase 3 (Data Preparation) ‚Äì die Daten werden aufbereitet.",
    businessTranslation: "Standardisiertes Vorgehensmodell f√ºr Data-Science-Projekte",
    fullExplanation: "CRISP-DM definiert sechs Phasen f√ºr Data-Science-Projekte: Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, Deployment.",
    relatedTerms: ["stakeholder", "deployment"],
  },
  {
    id: "stakeholder",
    name: "Stakeholder",
    category: "projekt",
    shortDefinition: "Alle Personen, die ein Interesse am Projekt haben oder davon betroffen sind.",
    quickExample: "Unsere Stakeholder: Vertriebsleitung (Sponsor), Retention-Team (Nutzer), IT (Betrieb).",
    businessTranslation: "Beteiligte und Betroffene des Projekts",
    fullExplanation: "Stakeholder sind alle Personen, die ein Interesse am Projekt haben ‚Äì Auftraggeber, Nutzer, Management, IT, betroffene Abteilungen.",
    relatedTerms: ["crisp-dm", "deployment"],
  },
  {
    id: "deployment",
    name: "Deployment",
    category: "projekt",
    shortDefinition: "Die √úberf√ºhrung eines Modells vom Entwicklungs- in den Produktivbetrieb.",
    quickExample: "Das Modell l√§uft jetzt produktiv und liefert jeden Montag die Top-200 Liste.",
    businessTranslation: "Das Modell in Produktion bringen",
    fullExplanation: "Deployment bezeichnet den Prozess, ein trainiertes Modell f√ºr den produktiven Einsatz bereitzustellen ‚Äì z.B. als API, Batch-Job oder Integration in Gesch√§ftsprozesse.",
    relatedTerms: ["monitoring", "drift", "fallback"],
  },
  {
    id: "monitoring",
    name: "Monitoring",
    category: "projekt",
    shortDefinition: "√úberwachung eines Modells im Produktivbetrieb auf Performance und Drift.",
    quickExample: "Jeden Freitag pr√ºfen wir: Ist die Precision noch √ºber 45%?",
    businessTranslation: "Kontinuierliche √úberwachung des Modells in Produktion",
    fullExplanation: "Monitoring √ºberwacht, ob das Modell in Produktion noch gut funktioniert ‚Äì Performance-Metriken, Datenqualit√§t, Drift-Indikatoren werden regelm√§√üig gepr√ºft.",
    relatedTerms: ["drift", "deployment"],
  },
  {
    id: "fallback",
    name: "Fallback",
    category: "projekt",
    shortDefinition: "Ein Notfall-Plan, wenn das Modell oder die Pipeline ausf√§llt.",
    quickExample: "Wenn der Batch-Prozess abst√ºrzt, bekommt das Team automatisch die alte regelbasierte Liste.",
    businessTranslation: "Notfallplan bei Modell- oder Pipeline-Ausfall",
    fullExplanation: "Ein Fallback ist ein Backup-Mechanismus f√ºr den Fall, dass das ML-System ausf√§llt ‚Äì z.B. R√ºckfall auf regelbasierte Logik oder die letzte g√ºltige Vorhersage.",
    relatedTerms: ["deployment", "monitoring"],
  },
  {
    id: "churn",
    name: "Churn",
    category: "projekt",
    shortDefinition: "Kundenabwanderung ‚Äì die Rate, mit der Kunden aufh√∂ren, ein Produkt zu nutzen.",
    quickExample: "Unsere Churn-Rate liegt bei 12% pro Jahr ‚Äì jeder 8. Kunde verl√§sst uns.",
    businessTranslation: "Kundenabwanderungsrate",
    fullExplanation: "Churn bezeichnet den Verlust von Kunden √ºber einen bestimmten Zeitraum. Die Churn-Rate ist ein wichtiger KPI f√ºr Subscription-basierte Gesch√§ftsmodelle.",
    relatedTerms: ["label", "precision-at-k"],
  },
  {
    id: "label-delay",
    name: "Label Delay",
    category: "projekt",
    shortDefinition: "Zeitraum zwischen dem Ereignis und dem Moment, wo du davon erf√§hrst.",
    quickExample: "K√ºndigungen werden erst 2 Wochen sp√§ter im CRM erfasst ‚Äì das ist unser Label Delay.",
    tip: "Entweder weiter in die Zukunft vorhersagen oder akzeptieren, dass du mit 'veralteten' Labels trainierst.",
    relatedTerms: ["label", "training"],
  },
  {
    id: "kpi-vs-metrik",
    name: "KPI vs. Modell-Metrik",
    category: "projekt",
    shortDefinition: "Unterscheidung zwischen Business-Kennzahlen (KPI) und technischen Modell-Metriken.",
    quickExample: "Precision@200 ist unsere Modell-Metrik, Retention-Rate ist der Business-KPI.",
    table: {
      headers: ["", "KPI", "Modell-Metrik"],
      rows: [
        ["Was", "Business-Kennzahl", "Technische Kennzahl"],
        ["Beispiel", "Retention-Rate, Umsatz", "Precision, Recall, AUC"],
        ["Wer kontrolliert", "Modell + Team + externe Faktoren", "Modell direkt"],
        ["Optimierbar", "Indirekt", "Direkt"],
      ],
    },
    tip: "Eine gute Modell-Metrik garantiert nicht automatisch einen guten KPI! Das Modell erstellt nur eine Liste ‚Äì ob die Retention-Rate steigt, h√§ngt auch vom Team und den Angeboten ab.",
    relatedTerms: ["precision-at-k", "recall"],
  },

  // === REGRESSION ===
  {
    id: "residuum",
    name: "Residuum",
    category: "regression",
    shortDefinition: "Die Differenz zwischen dem vorhergesagten Wert und dem tats√§chlichen Wert.",
    quickExample: "Vorhersage $200.000, tats√§chlich $230.000 ‚Üí Residuum = $30.000",
    businessTranslation: "Die Abweichung zwischen Vorhersage und Realit√§t",
    fullExplanation: "Das Residuum zeigt, wie weit eine einzelne Vorhersage vom echten Wert entfernt liegt. Bei positiven Residuen hat das Modell untersch√§tzt, bei negativen √ºbersch√§tzt.",
    relatedTerms: ["mse", "rmse", "mae"],
    tip: "Formel: Residuum = y - ≈∑ (tats√§chlich minus vorhergesagt)",
    technicalDetails: {
      formula: "e·µ¢ = y·µ¢ - ≈∑·µ¢",
      interpretation: "Positiv: Modell untersch√§tzt. Negativ: Modell √ºbersch√§tzt.",
      caveats: [
        "Residuen sollten normalverteilt sein (Modellannahme)",
        "Residuen sollten keine Muster zeigen (Homoskedastizit√§t)",
        "Residuen-Plot zur Diagnose von Modellproblemen",
      ],
    },
  },
  {
    id: "least-squares",
    name: "Least Squares (Kleinste Quadrate)",
    category: "regression",
    shortDefinition: "Methode zur Berechnung der Regressionsgeraden durch Minimierung der quadrierten Residuen.",
    quickExample: "Die Linie wird so gelegt, dass die Summe aller (Residuum¬≤) minimal ist.",
    businessTranslation: "Die mathematische Methode, um die beste Linie zu finden",
    fullExplanation: "Least Squares findet die Regressionsgerade, bei der die Summe der quadrierten Abweichungen (Residuen) am kleinsten ist. Quadrieren verhindert, dass positive und negative Fehler sich aufheben.",
    relatedTerms: ["residuum", "mse", "rmse"],
    technicalDetails: {
      formula: "Minimiere: Œ£(y·µ¢ - ≈∑·µ¢)¬≤ = Œ£e·µ¢¬≤",
      calculation: "Analytische L√∂sung: Œ≤ = (X'X)‚Åª¬πX'y",
      interpretation: "Die 'beste' Linie minimiert die Summe der quadrierten Residuen",
      caveats: [
        "Quadrieren bestraft gro√üe Fehler √ºberproportional",
        "Empfindlich gegen√ºber Ausrei√üern",
        "Alternative: Least Absolute Deviation (robuster)",
      ],
    },
  },
  {
    id: "steigung",
    name: "Steigung (Slope)",
    category: "regression",
    shortDefinition: "Das 'm' in der Regressionsformel y = mx + b. Gibt an, wie stark y sich √§ndert, wenn x um 1 steigt.",
    quickExample: "Steigung = 107 bedeutet: Pro zus√§tzlichem Quadratmeter steigt der Preis um $107.",
    businessTranslation: "Wie stark √§ndert sich das Ergebnis pro Einheit?",
    fullExplanation: "Die Steigung zeigt den Zusammenhang zwischen Eingabe und Ausgabe. Eine Steigung von 107 bei Hauspreisen bedeutet: Jeder zus√§tzliche Quadratmeter erh√∂ht den Preis um $107.",
    relatedTerms: ["achsenabschnitt", "residuum"],
    tip: "Auch 'Koeffizient' oder 'Slope' genannt.",
    technicalDetails: {
      formula: "m = Œ£(x·µ¢ - xÃÑ)(y·µ¢ - »≥) / Œ£(x·µ¢ - xÃÑ)¬≤ = Cov(X,Y) / Var(X)",
      interpretation: "√Ñnderung von y pro Einheit √Ñnderung von x",
      caveats: [
        "Gilt nur f√ºr lineare Zusammenh√§nge",
        "Bei mehreren Features: Partielle Steigung (ceteris paribus)",
        "Einheit: [y-Einheit] / [x-Einheit]",
      ],
    },
  },
  {
    id: "achsenabschnitt",
    name: "Achsenabschnitt (Intercept)",
    category: "regression",
    shortDefinition: "Das 'b' in der Regressionsformel y = mx + b. Der y-Wert, wenn x = 0.",
    quickExample: "Achsenabschnitt = 18.500 bedeutet: Basispreis ohne Fl√§che w√§re $18.500.",
    businessTranslation: "Der Startwert, wenn alle Eingaben null sind",
    fullExplanation: "Der Achsenabschnitt ist der vorhergesagte Wert, wenn alle Features gleich null sind. Oft nicht sinnvoll interpretierbar (z.B. Haus mit 0 qm), aber mathematisch notwendig.",
    relatedTerms: ["steigung", "residuum"],
    tip: "Nicht immer sinnvoll interpretierbar ‚Äì ein Haus mit 0 qm gibt es nicht.",
    technicalDetails: {
      formula: "b = »≥ - m √ó xÃÑ",
      interpretation: "Vorhergesagter y-Wert, wenn alle x = 0",
      caveats: [
        "Oft keine sinnvolle Interpretation (x=0 unrealistisch)",
        "Mathematisch notwendig f√ºr die Gerade",
        "Bei standardisierten Daten: b = 0",
      ],
    },
  },

  // === KLASSIFIKATION ===
  {
    id: "decision-boundary",
    name: "Decision Boundary (Entscheidungsgrenze)",
    category: "klassifikation",
    shortDefinition: "Die Grenze, die ein Klassifikationsmodell zwischen den Klassen zieht.",
    quickExample: "Bei logistischer Regression eine Linie, bei komplexeren Modellen eine Kurve.",
    businessTranslation: "Die Trennlinie zwischen 'Ja' und 'Nein'",
    fullExplanation: "Die Decision Boundary trennt den Merkmalsraum in Bereiche f√ºr verschiedene Klassen. Punkte auf einer Seite werden Klasse A zugeordnet, auf der anderen Klasse B.",
    relatedTerms: ["threshold", "precision", "recall"],
    technicalDetails: {
      interpretation: "Bei logistischer Regression: Lineare Grenze. Bei komplexeren Modellen: Beliebige Kurven.",
      caveats: [
        "Einfache Grenze = interpretierbar, aber evtl. nicht pr√§zise",
        "Komplexe Grenze = pr√§ziser, aber Overfitting-Gefahr",
        "Decision Tree: Stufenf√∂rmige (achsenparallele) Grenzen",
      ],
    },
  },

  // === ALGORITHMEN & CLUSTERING ===
  {
    id: "centroid",
    name: "Centroid (Cluster-Zentrum)",
    category: "algorithmen",
    shortDefinition: "Der Mittelpunkt eines Clusters bei K-Means ‚Äì der Durchschnitt aller Punkte im Cluster.",
    quickExample: "K-Means verschiebt Centroids iterativ, bis sie stabil sind.",
    businessTranslation: "Das Zentrum einer Kundengruppe",
    fullExplanation: "Bei K-Means Clustering wird jeder Cluster durch seinen Centroid repr√§sentiert ‚Äì den Durchschnitt aller zugeh√∂rigen Datenpunkte. Der Algorithmus verschiebt die Centroids, bis sie stabil sind.",
    relatedTerms: ["feature"],
    tip: "Bei Kundensegmentierung: Der Centroid beschreibt den 'typischen' Kunden einer Gruppe.",
    technicalDetails: {
      formula: "c‚Çñ = (1/|C‚Çñ|) √ó Œ£x·µ¢ (f√ºr alle x·µ¢ im Cluster k)",
      calculation: "Mittelwert aller Punkte im Cluster f√ºr jede Dimension",
      interpretation: "Repr√§sentiert den 'typischen' Datenpunkt eines Clusters",
      caveats: [
        "Nur bei K-Means und √§hnlichen Algorithmen",
        "Empfindlich gegen√ºber Ausrei√üern",
        "Bei hierarchischem Clustering gibt es keine Centroids",
      ],
    },
  },
  {
    id: "polynomiale-regression",
    name: "Polynomiale Regression",
    category: "algorithmen",
    shortDefinition: "Erweiterung der linearen Regression mit Polynomtermen (x¬≤, x¬≥, etc.) f√ºr nicht-lineare Zusammenh√§nge.",
    quickExample: "Formel: y = a + bx + cx¬≤ + dx¬≥ + ...",
    businessTranslation: "Regression f√ºr gekr√ºmmte Zusammenh√§nge",
    fullExplanation: "Wenn der Zusammenhang zwischen Features und Ziel nicht linear ist, k√∂nnen Polynomterme helfen. Achtung: H√∂here Grade erh√∂hen die Overfitting-Gefahr!",
    relatedTerms: ["steigung", "achsenabschnitt", "overfitting"],
    badPractice: ["Grad 10 Polynom auf 20 Datenpunkte ‚Äì klassisches Overfitting!"],
    goodPractice: ["Grad 2-3 f√ºr leicht gekr√ºmmte Zusammenh√§nge"],
    tip: "H√∂herer Grad = mehr Overfitting-Gefahr!",
    technicalDetails: {
      formula: "y = Œ≤‚ÇÄ + Œ≤‚ÇÅx + Œ≤‚ÇÇx¬≤ + Œ≤‚ÇÉx¬≥ + ... + Œ≤‚Çôx‚Åø",
      interpretation: "Grad n = Polynom mit n Wendungen m√∂glich",
      caveats: [
        "Grad 1 = lineare Regression",
        "H√∂herer Grad = mehr Flexibilit√§t, aber Overfitting-Gefahr",
        "Feature Engineering: x¬≤ als neues Feature hinzuf√ºgen",
      ],
    },
  },

  // === METRIKEN (Erg√§nzung) ===
  {
    id: "korrelation",
    name: "Korrelation (r)",
    category: "metriken",
    shortDefinition: "Ma√ü f√ºr die St√§rke und Richtung des linearen Zusammenhangs zwischen zwei Variablen. Wertebereich: -1 bis +1.",
    quickExample: "r = 0.8 bedeutet starker positiver Zusammenhang; r = -0.3 schwacher negativer.",
    businessTranslation: "Wie stark h√§ngen zwei Gr√∂√üen zusammen?",
    fullExplanation: "Die Korrelation (r) zeigt, ob und wie stark zwei Variablen linear zusammenh√§ngen. r = +1 ist perfekt positiv, r = -1 perfekt negativ, r = 0 kein linearer Zusammenhang.",
    detailedExample: {
      scenario: "Werbeausgaben vs. Umsatz",
      explanation: "r = 0.85 zeigt: H√∂here Werbeausgaben korrelieren stark mit h√∂herem Umsatz.",
      numbers: "|r| > 0.7 = starke Korrelation, |r| < 0.3 = schwache Korrelation",
    },
    whenImportant: [
      "Bei der Feature-Auswahl (welche Features h√§ngen mit dem Ziel zusammen?)",
      "Um Multikollinearit√§t zu erkennen (Features, die stark miteinander korrelieren)",
      "F√ºr explorative Datenanalyse",
    ],
    relatedTerms: ["feature-importance", "feature"],
    badPractice: ["Aus hoher Korrelation auf Kausalit√§t schlie√üen"],
    tip: "Korrelation ist NICHT Kausalit√§t! Eisverkauf korreliert mit Ertrinkungsf√§llen ‚Äì beide steigen im Sommer.",
  },

  // === CRISP-DM PHASEN ===
  {
    id: "business-understanding",
    name: "Business Understanding",
    category: "projekt",
    shortDefinition: "Erste CRISP-DM Phase: Gesch√§ftsproblem und Ziele verstehen.",
    quickExample: "Was ist das Gesch√§ftsziel? Wie wird Erfolg gemessen? Wer trifft Entscheidungen?",
    businessTranslation: "Phase 1: Das Problem verstehen",
    fullExplanation: "In dieser Phase werden Gesch√§ftsziele definiert, Erfolgskriterien festgelegt und der Projektumfang bestimmt. Ohne klares Business Understanding scheitern Projekte oft trotz technisch guter Modelle.",
    relatedTerms: ["crisp-dm", "data-understanding"],
  },
  {
    id: "data-understanding",
    name: "Data Understanding",
    category: "projekt",
    shortDefinition: "Zweite CRISP-DM Phase: Verf√ºgbare Daten erkunden und verstehen.",
    quickExample: "Dateninventar erstellen, Datenqualit√§t pr√ºfen, Label definieren.",
    businessTranslation: "Phase 2: Die Daten kennenlernen",
    fullExplanation: "Explorative Datenanalyse (EDA), Datenquellen identifizieren, Qualit√§tsprobleme erkennen und die Label-Definition festlegen. Oft werden hier Leakage-Risiken entdeckt.",
    relatedTerms: ["crisp-dm", "data-preparation", "data-leakage"],
  },
  {
    id: "data-preparation",
    name: "Data Preparation",
    category: "projekt",
    shortDefinition: "Dritte CRISP-DM Phase: Daten f√ºr die Modellierung aufbereiten.",
    quickExample: "Bereinigung, Feature Engineering, Encoding, Train/Test Split.",
    businessTranslation: "Phase 3: Die Daten startklar machen",
    fullExplanation: "Data Cleaning, Feature Engineering, Normalisierung und Aufteilung in Trainings- und Testdaten. Diese Phase nimmt oft 60-80% der Projektzeit ein.",
    relatedTerms: ["crisp-dm", "feature-engineering", "modeling-phase"],
  },
  {
    id: "modeling-phase",
    name: "Modeling",
    category: "projekt",
    shortDefinition: "Vierte CRISP-DM Phase: Modelle trainieren und optimieren.",
    quickExample: "Algorithmus w√§hlen, Training, Hyperparameter Tuning, Baseline definieren.",
    businessTranslation: "Phase 4: Das Modell bauen",
    fullExplanation: "Auswahl geeigneter Algorithmen, Training verschiedener Modelle, Hyperparameter-Optimierung und Vergleich gegen eine Baseline. Oft werden mehrere Ans√§tze parallel getestet.",
    relatedTerms: ["crisp-dm", "evaluation-phase", "hyperparameter"],
  },
  {
    id: "evaluation-phase",
    name: "Evaluation",
    category: "projekt",
    shortDefinition: "F√ºnfte CRISP-DM Phase: Modell gegen Gesch√§ftsziele bewerten.",
    quickExample: "Go/No-Go Entscheidung, Fehleranalyse, Pilotplan erstellen.",
    businessTranslation: "Phase 5: Erf√ºllt das Modell die Anforderungen?",
    fullExplanation: "Bewertung des Modells gegen die Business-Anforderungen aus Phase 1. Detaillierte Fehleranalyse und Entscheidung, ob das Modell produktionsreif ist oder zur√ºck in fr√ºhere Phasen muss.",
    relatedTerms: ["crisp-dm", "deployment", "ab-test"],
  },

  // === DATA SCIENCE ROLLEN ===
  {
    id: "data-scientist",
    name: "Data Scientist",
    category: "rollen",
    shortDefinition: "Entwickelt datenbasierte Anwendungsf√§lle und ML-Modelle.",
    quickExample: "Use Case Definition, EDA, Feature Engineering, Modellierung, Kommunikation.",
    businessTranslation: "Der 'Modellierer' ‚Äì baut die Vorhersagemodelle",
    fullExplanation: "Data Scientists kombinieren Statistik, Programmierung und Business-Verst√§ndnis, um aus Daten Erkenntnisse zu gewinnen und ML-Modelle zu entwickeln. Sie arbeiten eng mit Stakeholdern zusammen.",
    relatedTerms: ["data-engineer", "ml-engineer", "citizen-data-scientist"],
  },
  {
    id: "data-engineer",
    name: "Data Engineer",
    category: "rollen",
    shortDefinition: "Baut und wartet Daten-Infrastruktur und Pipelines.",
    quickExample: "ETL/ELT Pipelines, Data Warehouse, Datenqualit√§t sicherstellen.",
    businessTranslation: "Der 'Datenarchitekt' ‚Äì sorgt f√ºr verf√ºgbare Daten",
    fullExplanation: "Data Engineers stellen sicher, dass Daten zuverl√§ssig, sauber und zug√§nglich sind. Sie bauen die Pipelines, die Rohdaten in nutzbare Datens√§tze transformieren.",
    relatedTerms: ["data-scientist", "etl", "data-pipeline"],
  },
  {
    id: "ml-engineer",
    name: "ML Engineer",
    category: "rollen",
    shortDefinition: "Bringt ML-Modelle in Produktion und skaliert sie.",
    quickExample: "Model Deployment, API-Entwicklung, Skalierung, Monitoring.",
    businessTranslation: "Der 'Produktionsexperte' ‚Äì macht Modelle einsatzbereit",
    fullExplanation: "ML Engineers √ºberbr√ºcken die L√ºcke zwischen Modellentwicklung und Produktivbetrieb. Sie sorgen f√ºr skalierbare, zuverl√§ssige ML-Systeme mit Monitoring und automatisiertem Retraining.",
    relatedTerms: ["data-scientist", "deployment", "mlops"],
  },
  {
    id: "business-stakeholder",
    name: "Business Stakeholder",
    category: "rollen",
    shortDefinition: "Auftraggeber und Nutzer der Data Science L√∂sung.",
    quickExample: "Anforderungen definieren, Dom√§nenwissen einbringen, Abnahme.",
    businessTranslation: "Der Auftraggeber ‚Äì definiert das Problem und nutzt die L√∂sung",
    fullExplanation: "Business Stakeholder kennen das Gesch√§ftsproblem und die Anforderungen. Ihre Einbindung ist kritisch f√ºr den Erfolg ‚Äì sie definieren, was 'n√ºtzlich' bedeutet.",
    relatedTerms: ["subject-matter-expert", "business-understanding"],
  },
  {
    id: "subject-matter-expert",
    name: "Subject Matter Expert (SME)",
    category: "rollen",
    shortDefinition: "Fachexperte f√ºr den spezifischen Anwendungsbereich.",
    quickExample: "Dom√§nenwissen teilen, Ergebnisse validieren, Edge Cases erkl√§ren.",
    businessTranslation: "Der Fachexperte ‚Äì versteht den Kontext",
    fullExplanation: "SMEs verstehen die fachlichen Zusammenh√§nge, die das Modell abbilden soll. Sie erkennen, ob Vorhersagen plausibel sind und k√∂nnen Datenfehler identifizieren.",
    relatedTerms: ["business-stakeholder", "business-understanding"],
  },
  {
    id: "citizen-data-scientist",
    name: "Citizen Data Scientist",
    category: "rollen",
    shortDefinition: "Fachexperte mit Data Science Grundkenntnissen.",
    quickExample: "Einfache Analysen, Datenaufbereitung, Dashboards, Br√ºcke zu Data Scientists.",
    businessTranslation: "Der 'Power User' ‚Äì verbindet Fachlichkeit und Daten",
    fullExplanation: "Citizen Data Scientists sind keine professionellen Data Scientists, aber beherrschen grundlegende Analysetechniken. Sie k√∂nnen einfache Modelle selbst bauen und komplexere an Experten √ºbergeben.",
    relatedTerms: ["data-scientist", "data-analyst"],
  },
  {
    id: "data-analyst",
    name: "Data Analyst / BI Analyst",
    category: "rollen",
    shortDefinition: "Analysiert Daten und erstellt Reports und Dashboards.",
    quickExample: "Deskriptive Analyse, Visualisierung, Reporting, Ad-hoc Analysen.",
    businessTranslation: "Der Reporter ‚Äì macht Daten verst√§ndlich",
    fullExplanation: "Data Analysts fokussieren auf deskriptive Analyse und Reporting. Im Gegensatz zu Data Scientists bauen sie weniger Vorhersagemodelle, sondern erkl√§ren, was passiert ist und warum.",
    relatedTerms: ["data-scientist", "citizen-data-scientist"],
  },

  // === DATEN & INFRASTRUKTUR ===
  {
    id: "dataset",
    name: "Dataset (Datensatz)",
    category: "infrastruktur",
    shortDefinition: "Sammlung von Datenpunkten, typischerweise in Tabellenform.",
    quickExample: "Zeilen = Samples/Beobachtungen, Spalten = Features/Variablen.",
    businessTranslation: "Die Tabelle mit allen Daten",
    fullExplanation: "Ein Dataset ist die strukturierte Datengrundlage f√ºr ML. Jede Zeile ist ein Datenpunkt (z.B. ein Kunde), jede Spalte ein Feature (z.B. Alter, Umsatz).",
    relatedTerms: ["sample", "feature"],
  },
  {
    id: "sample",
    name: "Sample (Beobachtung)",
    category: "infrastruktur",
    shortDefinition: "Eine einzelne Zeile im Datensatz ‚Äì ein Beispiel.",
    quickExample: "Ein Kunde, eine Transaktion, ein Bild.",
    businessTranslation: "Ein einzelner Datenpunkt",
    fullExplanation: "Jedes Sample ist ein eigenst√§ndiges Beispiel, aus dem das Modell lernt. Die Anzahl der Samples beeinflusst, wie robust das Modell wird.",
    relatedTerms: ["dataset", "feature"],
  },
  {
    id: "data-warehouse",
    name: "Data Warehouse",
    category: "infrastruktur",
    shortDefinition: "Zentrales Speichersystem f√ºr strukturierte, aufbereitete Daten.",
    quickExample: "Reporting, Business Intelligence, historische Analysen.",
    businessTranslation: "Das zentrale 'Daten-Lager' f√ºr Analysen",
    fullExplanation: "Ein Data Warehouse speichert aufbereitete Daten aus verschiedenen Quellen in einem konsistenten Schema. Es ist optimiert f√ºr Abfragen und Analysen, nicht f√ºr Transaktionen.",
    relatedTerms: ["data-lake", "etl"],
  },
  {
    id: "data-lake",
    name: "Data Lake",
    category: "infrastruktur",
    shortDefinition: "Speicher f√ºr Rohdaten in beliebigen Formaten.",
    quickExample: "Strukturierte, semi-strukturierte und unstrukturierte Daten gemeinsam.",
    businessTranslation: "Der 'Rohdaten-See' ‚Äì alles sammeln, sp√§ter strukturieren",
    fullExplanation: "Im Gegensatz zum Data Warehouse speichert ein Data Lake Daten ohne Vorverarbeitung (Schema-on-Read). Das erm√∂glicht Flexibilit√§t, birgt aber das Risiko eines 'Data Swamp'.",
    relatedTerms: ["data-warehouse", "big-data"],
  },
  {
    id: "etl",
    name: "ETL (Extract, Transform, Load)",
    category: "infrastruktur",
    shortDefinition: "Prozess zum Extrahieren, Transformieren und Laden von Daten.",
    quickExample: "Daten aus CRM ziehen, bereinigen, ins Warehouse laden.",
    businessTranslation: "Daten von A nach B mit Aufbereitung",
    fullExplanation: "ETL-Prozesse holen Daten aus Quellsystemen (Extract), wandeln sie um (Transform) und laden sie in ein Zielsystem (Load). Moderne Variante: ELT (erst laden, dann transformieren).",
    relatedTerms: ["data-pipeline", "data-warehouse"],
  },
  {
    id: "data-pipeline",
    name: "Data Pipeline",
    category: "infrastruktur",
    shortDefinition: "Automatisierter Workflow f√ºr Datenverarbeitung.",
    quickExample: "Jeden Montag werden neue Daten verarbeitet und Scores berechnet.",
    businessTranslation: "Die 'Datenautobahn' ‚Äì automatischer Datenfluss",
    fullExplanation: "Eine Data Pipeline automatisiert den Datenfluss von der Quelle bis zum Endprodukt. Sie kann Datenextraktion, Transformation, Modell-Scoring und Ergebnisauslieferung umfassen.",
    relatedTerms: ["etl", "batch-processing"],
  },
  {
    id: "big-data",
    name: "Big Data",
    category: "infrastruktur",
    shortDefinition: "Datenmengen, die zu gro√ü f√ºr traditionelle Verarbeitung sind.",
    quickExample: "Die 3 Vs: Volume (Menge), Velocity (Geschwindigkeit), Variety (Vielfalt).",
    businessTranslation: "Daten, die nicht mehr in Excel passen",
    fullExplanation: "Big Data erfordert spezialisierte Tools wie Hadoop oder Spark, um Daten verteilt zu verarbeiten. Die Definition ist relativ ‚Äì was heute Big Data ist, kann morgen normal sein.",
    relatedTerms: ["data-lake", "batch-processing", "streaming"],
  },
  {
    id: "batch-processing",
    name: "Batch Processing",
    category: "infrastruktur",
    shortDefinition: "Verarbeitung von Daten in gro√üen Mengen zu festgelegten Zeiten.",
    quickExample: "N√§chtliche Neuberechnung aller Churn-Scores.",
    businessTranslation: "Datenverarbeitung nach Zeitplan",
    fullExplanation: "Batch Processing verarbeitet angesammelte Daten in regelm√§√üigen Intervallen. Es ist einfacher und g√ºnstiger als Echtzeit, aber die Ergebnisse sind nicht sofort verf√ºgbar.",
    relatedTerms: ["streaming", "data-pipeline"],
  },
  {
    id: "streaming",
    name: "Real-time / Streaming",
    category: "infrastruktur",
    shortDefinition: "Kontinuierliche Verarbeitung von Daten in Echtzeit.",
    quickExample: "Fraud Detection bei jeder einzelnen Transaktion.",
    businessTranslation: "Sofortige Datenverarbeitung",
    fullExplanation: "Streaming verarbeitet Daten unmittelbar, sobald sie eintreffen. Notwendig f√ºr Anwendungen wie Betrugserkennung oder Echtzeitempfehlungen, aber komplexer und teurer als Batch.",
    relatedTerms: ["batch-processing", "data-pipeline"],
  },
  {
    id: "api",
    name: "API (Application Programming Interface)",
    category: "infrastruktur",
    shortDefinition: "Schnittstelle, √ºber die Systeme miteinander kommunizieren.",
    quickExample: "Das Modell wird als REST API bereitgestellt und liefert Scores auf Anfrage.",
    businessTranslation: "Die 'Steckdose' f√ºr System-Verbindungen",
    fullExplanation: "Im ML-Kontext werden Modelle oft als APIs bereitgestellt. Andere Systeme senden Daten an die API und erhalten Vorhersagen zur√ºck.",
    relatedTerms: ["deployment", "inferenz"],
  },
  {
    id: "mlops",
    name: "MLOps",
    category: "infrastruktur",
    shortDefinition: "Praktiken f√ºr Deployment, Monitoring und Management von ML-Modellen.",
    quickExample: "Automatisiertes Training, Versionierung, Monitoring, Rollback.",
    businessTranslation: "DevOps f√ºr Machine Learning",
    fullExplanation: "MLOps kombiniert ML mit DevOps-Praktiken, um Modelle zuverl√§ssig in Produktion zu bringen und zu halten. Dazu geh√∂ren CI/CD f√ºr Modelle, Monitoring und automatisiertes Retraining.",
    relatedTerms: ["deployment", "monitoring", "ml-engineer"],
  },

  // === KONZEPTE & PH√ÑNOMENE ===
  {
    id: "class-imbalance",
    name: "Class Imbalance (Unbalancierte Klassen)",
    category: "konzepte",
    shortDefinition: "Eine Klasse ist viel h√§ufiger als andere (z.B. 99% vs. 1%).",
    quickExample: "Nur 1% Betrugsf√§lle ‚Äì Accuracy von 99% durch 'nie Betrug' vorhersagen.",
    businessTranslation: "Seltene Ereignisse sind schwer zu finden",
    fullExplanation: "Bei stark unbalancierten Klassen wird Accuracy irref√ºhrend. Das Modell kann die Minderheitsklasse ignorieren und trotzdem hohe Accuracy erreichen. L√∂sungen: SMOTE, Class Weights, andere Metriken.",
    relatedTerms: ["accuracy", "smote", "precision", "recall"],
    tip: "Bei unbalancierten Klassen immer Precision, Recall und F1 statt nur Accuracy betrachten!",
  },
  {
    id: "smote",
    name: "SMOTE",
    category: "konzepte",
    shortDefinition: "Synthetic Minority Over-sampling Technique ‚Äì erzeugt synthetische Beispiele der Minderheitsklasse.",
    quickExample: "Aus 100 Betrugsf√§llen werden durch Interpolation 500 synthetische erstellt.",
    businessTranslation: "K√ºnstliche Vermehrung seltener Beispiele",
    fullExplanation: "SMOTE erzeugt neue, synthetische Datenpunkte der Minderheitsklasse durch Interpolation zwischen existierenden Beispielen. Das hilft dem Modell, die seltene Klasse besser zu lernen.",
    relatedTerms: ["class-imbalance", "training"],
  },
  {
    id: "curse-of-dimensionality",
    name: "Curse of Dimensionality",
    category: "konzepte",
    shortDefinition: "Probleme, die bei vielen Features (hoher Dimensionalit√§t) auftreten.",
    quickExample: "Bei 100 Features braucht man exponentiell mehr Daten f√ºr robuste Muster.",
    businessTranslation: "Zu viele Features machen Modelle instabil",
    fullExplanation: "Mit steigender Anzahl von Features werden Daten 'd√ºnn' ‚Äì Distanzen verlieren ihre Bedeutung, Overfitting wird wahrscheinlicher. L√∂sung: Feature Selection oder Dimensionsreduktion (z.B. PCA).",
    relatedTerms: ["dimensionsreduktion", "pca", "feature-selection"],
    technicalDetails: {
      interpretation: "Volumen w√§chst exponentiell: Bei d Dimensionen braucht man n^d Datenpunkte f√ºr gleiche Dichte.",
      caveats: [
        "Distanzen werden bedeutungslos (alle Punkte 'gleich weit')",
        "Overfitting wahrscheinlicher",
        "KNN leidet besonders stark",
        "L√∂sung: Dimensionsreduktion (PCA), Feature Selection",
      ],
    },
  },
  {
    id: "dimensionsreduktion",
    name: "Dimensionsreduktion",
    category: "konzepte",
    shortDefinition: "Reduzierung der Anzahl von Features bei minimalem Informationsverlust.",
    quickExample: "PCA reduziert 100 Features auf 10 wichtige Komponenten.",
    businessTranslation: "Weniger Features, fast gleiche Information",
    fullExplanation: "Dimensionsreduktion bek√§mpft den Curse of Dimensionality. Methoden wie PCA finden die wichtigsten 'Richtungen' in den Daten und projizieren auf weniger Dimensionen.",
    relatedTerms: ["pca", "curse-of-dimensionality", "feature-selection"],
    technicalDetails: {
      interpretation: "Lineare Methoden: PCA. Nicht-lineare: t-SNE, UMAP (v.a. Visualisierung).",
      caveats: [
        "PCA: Maximale Varianz erhalten, aber Komponenten schwer interpretierbar",
        "t-SNE/UMAP: Gut f√ºr Visualisierung, aber nicht f√ºr Modelle",
        "Feature Selection: Features komplett entfernen vs. transformieren",
        "Ziel: 95% erkl√§rte Varianz mit weniger Dimensionen",
      ],
    },
  },
  {
    id: "anomalie-erkennung",
    name: "Anomalie-Erkennung",
    category: "konzepte",
    shortDefinition: "Identifikation von ungew√∂hnlichen Datenpunkten (Ausrei√üern).",
    quickExample: "Betrugserkennung, Fehlererkennung in der Produktion.",
    businessTranslation: "Ungew√∂hnliche Muster finden",
    fullExplanation: "Anomalie-Erkennung findet Datenpunkte, die stark vom Normalen abweichen. Oft als Unsupervised Learning umgesetzt, da Anomalien per Definition selten sind.",
    relatedTerms: ["unsupervised-learning", "outlier"],
  },
  {
    id: "outlier",
    name: "Outlier (Ausrei√üer)",
    category: "konzepte",
    shortDefinition: "Datenpunkte, die stark vom Rest abweichen.",
    quickExample: "Ein Kunde mit 100x h√∂herem Umsatz als der Durchschnitt.",
    businessTranslation: "Extreme Werte, die 'aus der Reihe tanzen'",
    fullExplanation: "Outlier k√∂nnen echte Extremf√§lle sein (interessant!) oder Datenfehler (l√∂schen!). Erkennung durch Z-Score, IQR-Methode oder Visualisierung. Umgang: entfernen, begrenzen oder robust-Methoden nutzen.",
    relatedTerms: ["anomalie-erkennung", "data-preparation"],
  },
  {
    id: "ensemble-learning",
    name: "Ensemble Learning",
    category: "konzepte",
    shortDefinition: "Kombination mehrerer Modelle f√ºr bessere Vorhersagen.",
    quickExample: "Random Forest kombiniert viele Decision Trees.",
    businessTranslation: "Mehrere Modelle sind besser als eines",
    fullExplanation: "Ensemble-Methoden kombinieren verschiedene Modelle, um St√§rken zu nutzen und Schw√§chen auszugleichen. Hauptarten: Bagging (parallele Kombination), Boosting (sequentielle Verbesserung), Stacking (Metamodell).",
    relatedTerms: ["bagging", "boosting", "random-forest"],
  },
  {
    id: "bagging",
    name: "Bagging (Bootstrap Aggregating)",
    category: "konzepte",
    shortDefinition: "Trainiert viele Modelle auf verschiedenen Bootstrap-Samples und mittelt.",
    quickExample: "Random Forest ist Bagging mit Decision Trees.",
    businessTranslation: "Viele Modelle auf leicht unterschiedlichen Daten",
    fullExplanation: "Bagging reduziert Varianz durch Mittelung mehrerer Modelle. Jedes Modell sieht eine leicht andere Stichprobe der Trainingsdaten (Bootstrap-Sample mit Zur√ºcklegen).",
    relatedTerms: ["ensemble-learning", "random-forest", "bootstrap"],
  },
  {
    id: "boosting",
    name: "Boosting",
    category: "konzepte",
    shortDefinition: "Trainiert Modelle sequenziell, wobei jedes die Fehler des vorherigen korrigiert.",
    quickExample: "XGBoost, Gradient Boosting, AdaBoost.",
    businessTranslation: "Modelle lernen aus den Fehlern der Vorg√§nger",
    fullExplanation: "Boosting fokussiert jedes neue Modell auf die Fehler der bisherigen. Das f√ºhrt oft zu sehr hoher Genauigkeit, birgt aber Overfitting-Risiko und ist langsamer zu trainieren.",
    relatedTerms: ["ensemble-learning", "xgboost", "gradient-boosting"],
  },
  {
    id: "bootstrap",
    name: "Bootstrap",
    category: "konzepte",
    shortDefinition: "Ziehen von Stichproben mit Zur√ºcklegen aus dem Datensatz.",
    quickExample: "Aus 1000 Datenpunkten werden 1000 gezogen ‚Äì manche mehrfach, manche nie.",
    businessTranslation: "K√ºnstliche Variation durch Neu-Stichproben",
    fullExplanation: "Bootstrap ist eine statistische Technik, um Varianz zu sch√§tzen oder Daten-Variabilit√§t zu simulieren. Grundlage f√ºr Bagging und Konfidenzintervalle.",
    relatedTerms: ["bagging", "ensemble-learning"],
  },
  {
    id: "transfer-learning",
    name: "Transfer Learning",
    category: "konzepte",
    shortDefinition: "Nutzen eines vortrainierten Modells f√ºr eine neue Aufgabe.",
    quickExample: "Ein auf Millionen Bildern trainiertes Modell wird f√ºr eigene Bildklassifikation angepasst.",
    businessTranslation: "Wissen aus anderen Projekten √ºbertragen",
    fullExplanation: "Transfer Learning erm√∂glicht gute Modelle mit weniger eigenen Daten, indem Wissen aus gro√üen, vortrainierten Modellen √ºbernommen wird. Besonders wichtig bei Deep Learning.",
    relatedTerms: ["deep-learning", "training"],
  },
  {
    id: "interpretability",
    name: "Interpretability / Explainability",
    category: "konzepte",
    shortDefinition: "Wie verst√§ndlich sind die Entscheidungen eines Modells?",
    quickExample: "Feature Importance, SHAP-Werte, Partial Dependence Plots.",
    businessTranslation: "Kann man die Modell-Entscheidung erkl√§ren?",
    fullExplanation: "Interpretierbarkeit ist wichtig f√ºr Compliance, Debugging und Stakeholder-Vertrauen. Einfache Modelle (Lineare Regression, Decision Trees) sind von Natur aus interpretierbar, komplexe (Deep Learning) brauchen Erkl√§rungsmethoden.",
    relatedTerms: ["black-box-model", "shap", "feature-importance"],
  },
  {
    id: "black-box-model",
    name: "Black Box Model",
    category: "konzepte",
    shortDefinition: "Modell, dessen interne Entscheidungslogik nicht nachvollziehbar ist.",
    quickExample: "Tiefe neuronale Netze, komplexe Ensembles.",
    businessTranslation: "Das Modell ist eine 'undurchsichtige Kiste'",
    fullExplanation: "Black-Box-Modelle k√∂nnen sehr genau sein, aber ihre Entscheidungen sind schwer zu erkl√§ren. Das kann problematisch sein bei regulatorischen Anforderungen oder wenn Vertrauen wichtig ist.",
    relatedTerms: ["interpretability", "shap"],
  },
  {
    id: "shap",
    name: "SHAP (SHapley Additive exPlanations)",
    category: "konzepte",
    shortDefinition: "Methode zur Erkl√§rung von Vorhersagen basierend auf Spieltheorie.",
    quickExample: "F√ºr jeden Datenpunkt: 'Feature X hat +15% zum Score beigetragen.'",
    businessTranslation: "Individuelle Erkl√§rung pro Vorhersage",
    fullExplanation: "SHAP berechnet den Beitrag jedes Features zur Vorhersage f√ºr jeden einzelnen Datenpunkt. Das erm√∂glicht sowohl globale (welche Features sind generell wichtig?) als auch lokale (warum diese spezifische Vorhersage?) Erkl√§rungen.",
    relatedTerms: ["interpretability", "feature-importance"],
  },
  {
    id: "multikollinearitaet",
    name: "Multikollinearit√§t",
    category: "konzepte",
    shortDefinition: "Starke Korrelation zwischen Features untereinander.",
    quickExample: "K√∂rpergr√∂√üe und Schuhgr√∂√üe korrelieren stark ‚Äì beide als Features ist redundant.",
    businessTranslation: "Features enthalten √§hnliche Information",
    fullExplanation: "Multikollinearit√§t f√ºhrt zu instabilen Koeffizienten in linearer Regression und erschwert die Interpretation von Feature Importance. Erkennung durch VIF, L√∂sung durch Feature-Entfernung oder PCA.",
    relatedTerms: ["korrelation", "feature-selection", "pca"],
  },
  {
    id: "cold-start-problem",
    name: "Cold Start Problem",
    category: "konzepte",
    shortDefinition: "Keine oder wenige Daten f√ºr neue Items/User verf√ºgbar.",
    quickExample: "Empfehlungssystem f√ºr einen neuen User ohne Kaufhistorie.",
    businessTranslation: "Neue Nutzer/Produkte ohne Datenhistorie",
    fullExplanation: "Das Cold Start Problem tritt auf, wenn f√ºr neue Entit√§ten keine Trainingsdaten existieren. L√∂sungen: Content-basierte Fallbacks, demografische Daten nutzen, popul√§re Items empfehlen.",
    relatedTerms: ["training", "feature"],
  },

  // === FEATURE ENGINEERING ===
  {
    id: "one-hot-encoding",
    name: "One-Hot Encoding",
    category: "modell",
    shortDefinition: "Umwandlung kategorischer Variablen in bin√§re Spalten (0/1).",
    quickExample: "Farbe: [Rot, Blau] ‚Üí Farbe_Rot: [1,0], Farbe_Blau: [0,1].",
    businessTranslation: "Kategorien in Zahlen √ºbersetzen",
    fullExplanation: "Da ML-Modelle Zahlen brauchen, m√ºssen Kategorien kodiert werden. One-Hot Encoding erstellt eine Spalte pro Kategorie. Problem: Bei vielen Kategorien entstehen sehr viele Spalten.",
    relatedTerms: ["feature-engineering", "label-encoding"],
  },
  {
    id: "label-encoding",
    name: "Label Encoding",
    category: "modell",
    shortDefinition: "Umwandlung kategorischer Variablen in Zahlen.",
    quickExample: "[Klein, Mittel, Gro√ü] ‚Üí [0, 1, 2].",
    businessTranslation: "Kategorien als Zahlen darstellen",
    fullExplanation: "Label Encoding ersetzt Kategorien durch Zahlen. Vorsicht: Das impliziert eine Ordnung (0 < 1 < 2), was nur bei ordinalen Variablen sinnvoll ist.",
    relatedTerms: ["one-hot-encoding", "feature-engineering"],
    tip: "Nur bei ordinalen Variablen verwenden ‚Äì sonst One-Hot Encoding!",
  },
  {
    id: "normalisierung",
    name: "Normalisierung",
    category: "modell",
    shortDefinition: "Skalierung von Features auf einen Bereich (z.B. 0 bis 1).",
    quickExample: "Alter 18-80 wird zu 0-1 skaliert.",
    businessTranslation: "Alle Features auf gleiche Skala bringen",
    fullExplanation: "Normalisierung (Min-Max-Scaling) transformiert Features auf [0,1]. Wichtig f√ºr Algorithmen, die Distanzen nutzen (KNN, SVM, Neuronale Netze), da sonst gro√üe Werte dominieren.",
    relatedTerms: ["standardisierung", "feature-engineering"],
    tip: "Formel: x_norm = (x - min) / (max - min)",
    technicalDetails: {
      formula: "x' = (x - x_min) / (x_max - x_min)",
      interpretation: "Skaliert auf [0, 1]. 0 = Minimum der Trainingsdaten, 1 = Maximum.",
      caveats: [
        "Min/Max aus TRAININGSDATEN berechnen!",
        "Neue Werte k√∂nnen au√üerhalb [0,1] liegen",
        "Empfindlich gegen√ºber Ausrei√üern",
        "Alternative: Robust Scaling mit IQR",
      ],
    },
  },
  {
    id: "standardisierung",
    name: "Standardisierung (Z-Score)",
    category: "modell",
    shortDefinition: "Transformation zu Mittelwert 0 und Standardabweichung 1.",
    quickExample: "Nach Standardisierung: Durchschnitt = 0, Streuung = 1.",
    businessTranslation: "Features 'normieren'",
    fullExplanation: "Standardisierung (Z-Score Normalisierung) zentriert Daten um 0 mit Streuung 1. Oft robuster als Min-Max-Scaling, da Ausrei√üer weniger Einfluss haben.",
    relatedTerms: ["normalisierung", "feature-engineering"],
    tip: "Formel: z = (x - Œº) / œÉ",
    technicalDetails: {
      formula: "z = (x - Œº) / œÉ",
      interpretation: "z-Score: Anzahl Standardabweichungen vom Mittelwert. z=0 ‚Üí Mittelwert, z=2 ‚Üí 2œÉ √ºber Mittelwert.",
      caveats: [
        "Œº und œÉ aus TRAININGSDATEN berechnen!",
        "Kein fester Wertebereich (nicht [0,1])",
        "Robuster gegen Ausrei√üer als Min-Max",
        "Standard bei vielen Algorithmen (SVM, NN, PCA)",
      ],
    },
  },
  {
    id: "missing-values",
    name: "Missing Values (Fehlende Werte)",
    category: "modell",
    shortDefinition: "Datenpunkte ohne Wert in einer oder mehreren Spalten.",
    quickExample: "10% der Kunden haben kein Geburtsdatum angegeben.",
    businessTranslation: "L√ºcken in den Daten",
    fullExplanation: "Missing Values sind ein h√§ufiges Problem. Strategien: L√∂schen (wenn wenige), Mittelwert/Median einsetzen, Modell-basierte Imputation. Wichtig: Verstehen, warum Werte fehlen (zuf√§llig oder systematisch?).",
    relatedTerms: ["imputation", "data-preparation"],
  },
  {
    id: "imputation",
    name: "Imputation",
    category: "modell",
    shortDefinition: "Ersetzen fehlender Werte durch gesch√§tzte Werte.",
    quickExample: "Fehlende Alter werden durch den Median aller Alter ersetzt.",
    businessTranslation: "L√ºcken intelligent f√ºllen",
    fullExplanation: "Imputation sch√§tzt fehlende Werte. Methoden: Mean, Median, Mode (einfach), KNN-Imputation, MICE (fortgeschritten). Die Wahl h√§ngt vom Datentyp und dem Fehlensmuster ab.",
    relatedTerms: ["missing-values", "data-preparation"],
  },
  {
    id: "feature-selection",
    name: "Feature Selection",
    category: "modell",
    shortDefinition: "Auswahl der relevantesten Features, Entfernung unwichtiger.",
    quickExample: "Von 50 Features werden die 10 wichtigsten ausgew√§hlt.",
    businessTranslation: "Nur die wichtigen Variablen behalten",
    fullExplanation: "Feature Selection reduziert Dimensionalit√§t und verhindert Overfitting. Methoden: Korrelationsanalyse, Feature Importance, L1 Regularisierung (automatische Selektion), Domain-Expertise.",
    relatedTerms: ["feature-importance", "curse-of-dimensionality", "dimensionsreduktion"],
  },

  // === ALGORITHMEN (Erg√§nzung) ===
  {
    id: "lineare-regression",
    name: "Lineare Regression",
    category: "algorithmen",
    shortDefinition: "Findet die beste Gerade (oder Hyperebene) durch die Datenpunkte.",
    quickExample: "Hauspreis = 18.500 + 107 √ó Quadratmeter.",
    businessTranslation: "Die einfachste Vorhersagemethode ‚Äì eine Linie durch die Daten",
    fullExplanation: "Lineare Regression ist das Basismodell f√ºr Vorhersagen kontinuierlicher Werte. Schnell, interpretierbar, gute Baseline ‚Äì aber nur f√ºr lineare Zusammenh√§nge geeignet.",
    relatedTerms: ["steigung", "achsenabschnitt", "least-squares"],
    technicalDetails: {
      formula: "y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô (einfach: y = mx + b)",
      calculation: "Koeffizienten via Least Squares: Œ≤ = (X'X)‚Åª¬πX'y",
      interpretation: "Jeder Koeffizient Œ≤·µ¢ zeigt: √Ñnderung von y pro Einheit x·µ¢ (ceteris paribus)",
      caveats: [
        "Setzt linearen Zusammenhang voraus",
        "Empfindlich gegen√ºber Ausrei√üern",
        "Multikollinearit√§t macht Koeffizienten instabil",
        "Residuen sollten normalverteilt sein",
      ],
    },
  },
  {
    id: "logistische-regression",
    name: "Logistische Regression",
    category: "algorithmen",
    shortDefinition: "Klassifikationsalgorithmus, der Wahrscheinlichkeiten f√ºr Klassen sch√§tzt.",
    quickExample: "Ausgabe: 'Dieser Kunde k√ºndigt mit 73% Wahrscheinlichkeit.'",
    businessTranslation: "Ja/Nein-Vorhersage mit Wahrscheinlichkeit",
    fullExplanation: "Trotz des Namens ein Klassifikator, kein Regressionsverfahren. Die Sigmoid-Funktion transformiert lineare Ausgaben in Wahrscheinlichkeiten (0-1). Interpretierbar durch Odds Ratios.",
    relatedTerms: ["sigmoid", "decision-boundary", "threshold"],
    technicalDetails: {
      formula: "P(y=1|x) = 1 / (1 + e^(-z)) mit z = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ... + Œ≤‚Çôx‚Çô",
      calculation: "Logit: log(p/(1-p)) = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ... (linearisiert)",
      interpretation: "Odds Ratio = e^Œ≤: Faktor, um den sich die Odds √§ndern pro Einheit x",
      caveats: [
        "Output ist Wahrscheinlichkeit [0,1]",
        "Threshold (z.B. 0.5) bestimmt Klassenzuordnung",
        "Koeffizienten sind √Ñnderung des Log-Odds",
        "Odds Ratio: e^0.5 ‚âà 1.65 ‚Üí Odds steigen um 65% pro Einheit",
      ],
    },
  },
  {
    id: "sigmoid",
    name: "Sigmoid-Funktion",
    category: "algorithmen",
    shortDefinition: "S-f√∂rmige Funktion, die beliebige Zahlen auf den Bereich 0 bis 1 abbildet.",
    quickExample: "œÉ(0) = 0.5, œÉ(2) ‚âà 0.88, œÉ(-2) ‚âà 0.12.",
    businessTranslation: "Umwandlung in Wahrscheinlichkeiten",
    fullExplanation: "Die Sigmoid-Funktion 'quetscht' beliebige Werte auf [0,1]. In der logistischen Regression wandelt sie die lineare Kombination der Features in eine Wahrscheinlichkeit um.",
    relatedTerms: ["logistische-regression", "softmax"],
    technicalDetails: {
      formula: "œÉ(x) = 1 / (1 + e^(-x))",
      interpretation: "x ‚Üí ‚àû: œÉ(x) ‚Üí 1 | x ‚Üí -‚àû: œÉ(x) ‚Üí 0 | x = 0: œÉ(x) = 0.5",
      caveats: [
        "Wertebereich: (0, 1) ‚Äì nie exakt 0 oder 1",
        "Ableitung: œÉ'(x) = œÉ(x) √ó (1 - œÉ(x))",
        "Problem: Vanishing Gradients bei sehr gro√üen/kleinen x",
        "Alternative: ReLU in neuronalen Netzen",
      ],
    },
  },
  {
    id: "softmax",
    name: "Softmax-Funktion",
    category: "algorithmen",
    shortDefinition: "Verallgemeinerung der Sigmoid-Funktion f√ºr mehr als 2 Klassen.",
    quickExample: "Ausgabe: [Katze: 0.75, Hund: 0.20, Vogel: 0.05] (Summe = 1).",
    businessTranslation: "Wahrscheinlichkeiten f√ºr mehrere Kategorien",
    fullExplanation: "Softmax normalisiert Ausgaben zu einer Wahrscheinlichkeitsverteilung √ºber alle Klassen. Wird in Multi-Class-Klassifikation und neuronalen Netzen verwendet.",
    relatedTerms: ["sigmoid", "multi-class", "neuronales-netz"],
    technicalDetails: {
      formula: "softmax(z·µ¢) = e^(z·µ¢) / Œ£‚±º e^(z‚±º)",
      interpretation: "H√∂herer z-Wert ‚Üí h√∂here Wahrscheinlichkeit. Summe aller Ausgaben = 1.",
      caveats: [
        "Bei 2 Klassen: Softmax = Sigmoid",
        "Numerisch stabil: Subtrahiere max(z) vor Berechnung",
        "Output-Schicht in Multi-Class Neural Networks",
        "Verst√§rkt Unterschiede: Gr√∂√üte Werte dominieren",
      ],
    },
  },
  {
    id: "knn",
    name: "K-Nearest Neighbors (KNN)",
    category: "algorithmen",
    shortDefinition: "Klassifiziert basierend auf den k n√§chsten Nachbarn im Feature-Raum.",
    quickExample: "Neuer Punkt wird die Klasse seiner 5 n√§chsten Nachbarn zugeordnet.",
    businessTranslation: "'Zeig mir deine Nachbarn, und ich sage dir, wer du bist'",
    fullExplanation: "KNN ist ein einfacher, intuitiver Algorithmus ohne Trainingsphase. Zur Vorhersagezeit werden die k √§hnlichsten Datenpunkte gesucht. Nachteil: Langsam bei gro√üen Datens√§tzen.",
    relatedTerms: ["normalisierung", "curse-of-dimensionality"],
    tip: "Braucht unbedingt Normalisierung ‚Äì sonst dominieren gro√üe Wertebereiche!",
    technicalDetails: {
      formula: "Euklidische Distanz: d = ‚àö(Œ£(x·µ¢ - y·µ¢)¬≤)",
      calculation: "1. k n√§chste Nachbarn finden ‚Üí 2. Mehrheitsentscheidung (Klassifikation) oder Mittelwert (Regression)",
      interpretation: "k = 1: N√§chster Nachbar entscheidet. k = n: Alle Daten entscheiden (=Baseline).",
      caveats: [
        "Distanzmetriken: Euklidisch, Manhattan, Minkowski",
        "k ungerade w√§hlen bei 2 Klassen (vermeidet Gleichstand)",
        "Lazy Learning: Kein Training, aber langsame Inferenz",
        "Curse of Dimensionality: Bei vielen Features verliert Distanz Bedeutung",
      ],
    },
  },
  {
    id: "gradient-boosting",
    name: "Gradient Boosting",
    category: "algorithmen",
    shortDefinition: "Ensemble-Methode, die Trees sequenziell trainiert und Fehler korrigiert.",
    quickExample: "XGBoost, LightGBM, CatBoost sind popul√§re Implementierungen.",
    businessTranslation: "Modelle verbessern sich Schritt f√ºr Schritt",
    fullExplanation: "Gradient Boosting baut Modelle iterativ auf, wobei jedes neue Modell die Residuen (Fehler) des bisherigen Ensembles modelliert. Oft beste Performance bei tabellarischen Daten.",
    relatedTerms: ["boosting", "xgboost", "random-forest"],
    technicalDetails: {
      formula: "F_m(x) = F_{m-1}(x) + Œ≥ √ó h_m(x)",
      calculation: "Jeder neue Tree h_m modelliert den negativen Gradienten der Verlustfunktion",
      interpretation: "Iterative Fehlerkorrektur: Jeder Baum verbessert die Vorhersage des Ensembles",
      caveats: [
        "Sequenziell = nicht parallelisierbar (langsamer als Bagging)",
        "Learning Rate (Œ≥) steuert Schrittgr√∂√üe",
        "Mehr B√§ume k√∂nnen zu Overfitting f√ºhren",
        "Early Stopping gegen Overfitting",
      ],
    },
  },
  {
    id: "xgboost",
    name: "XGBoost",
    category: "algorithmen",
    shortDefinition: "Optimierte Implementierung von Gradient Boosting.",
    quickExample: "Gewinner vieler Kaggle-Wettbewerbe.",
    businessTranslation: "Der 'Turbo' unter den Baum-Modellen",
    fullExplanation: "XGBoost ist schneller und oft genauer als Standard-Gradient-Boosting. Eingebaute Regularisierung verhindert Overfitting. LightGBM und CatBoost sind Alternativen.",
    relatedTerms: ["gradient-boosting", "random-forest"],
    technicalDetails: {
      formula: "Objective = Œ£ Loss(y·µ¢, ≈∑·µ¢) + Œ£ Œ©(f‚Çñ) mit Œ© = Œ≥T + ¬ΩŒª||w||¬≤",
      calculation: "T = Anzahl Bl√§tter, w = Blattgewichte. L1 (Œ±) und L2 (Œª) Regularisierung.",
      interpretation: "Bestraft komplexe B√§ume (viele Bl√§tter, gro√üe Gewichte) ‚Üí weniger Overfitting",
      caveats: [
        "Hyperparameter: max_depth, learning_rate, n_estimators",
        "Shrinkage: Niedrige Learning Rate + viele B√§ume",
        "LightGBM: Schneller bei gro√üen Daten (leaf-wise growth)",
        "CatBoost: Besser mit kategorialen Features",
      ],
    },
  },
  {
    id: "naive-bayes",
    name: "Naive Bayes",
    category: "algorithmen",
    shortDefinition: "Probabilistischer Klassifikator basierend auf Bayes-Theorem.",
    quickExample: "Spam-Filter: Wahrscheinlichkeit von 'Spam' gegeben der W√∂rter in der Mail.",
    businessTranslation: "Vorhersage durch Wahrscheinlichkeitsrechnung",
    fullExplanation: "Naive Bayes ist sehr schnell und braucht wenig Daten. Die 'naive' Annahme der Unabh√§ngigkeit der Features ist oft unrealistisch, funktioniert aber erstaunlich gut, besonders bei Textklassifikation.",
    relatedTerms: ["logistische-regression"],
    technicalDetails: {
      formula: "P(y|x‚ÇÅ,...,x‚Çô) ‚àù P(y) √ó Œ† P(x·µ¢|y)",
      calculation: "Bayes: P(A|B) = P(B|A) √ó P(A) / P(B)",
      interpretation: "Posterior ‚àù Prior √ó Likelihood. 'Naiv': Features sind unabh√§ngig gegeben y.",
      caveats: [
        "Unabh√§ngigkeitsannahme fast nie erf√ºllt, funktioniert trotzdem oft gut",
        "Varianten: Gaussian (kontinuierlich), Multinomial (Counts), Bernoulli (bin√§r)",
        "Sehr schnell und braucht wenig Trainingsdaten",
        "Probabilities sind oft schlecht kalibriert",
      ],
    },
  },
  {
    id: "neuronales-netz",
    name: "Neuronales Netz (Neural Network)",
    category: "algorithmen",
    shortDefinition: "Netzwerk aus verbundenen 'Neuronen', die Daten durch Schichten verarbeiten.",
    quickExample: "Bilderkennung, Sprachverarbeitung, GPT.",
    businessTranslation: "Modell inspiriert vom menschlichen Gehirn",
    fullExplanation: "Neuronale Netze k√∂nnen sehr komplexe Muster lernen und sind universelle Approximatoren. Sie brauchen aber viele Daten und sind schwer zu interpretieren (Black Box).",
    relatedTerms: ["deep-learning", "black-box-model"],
    technicalDetails: {
      formula: "Neuron: y = f(Œ£ w·µ¢x·µ¢ + b) mit Aktivierungsfunktion f",
      calculation: "Forward Pass: Input ‚Üí Hidden Layers ‚Üí Output. Backpropagation: Gradienten zur√ºckpropagieren.",
      interpretation: "Jede Schicht lernt zunehmend abstrakte Repr√§sentationen der Daten",
      caveats: [
        "Aktivierungsfunktionen: ReLU, Sigmoid, Tanh, Softmax",
        "Training: Gradient Descent mit Backpropagation",
        "Braucht viele Daten und Rechenleistung",
        "Hyperparameter: Layers, Neurons, Learning Rate, Batch Size",
      ],
    },
  },
  {
    id: "pca",
    name: "PCA (Principal Component Analysis)",
    category: "algorithmen",
    shortDefinition: "Dimensionsreduktion durch Projektion auf Achsen maximaler Varianz.",
    quickExample: "100 Features werden auf 10 Hauptkomponenten reduziert.",
    businessTranslation: "Die wichtigsten 'Richtungen' in den Daten finden",
    fullExplanation: "PCA findet die Richtungen in den Daten mit der gr√∂√üten Variation und projiziert auf diese. Reduziert Dimensionen und entfernt Multikollinearit√§t, aber Komponenten sind schwer zu interpretieren.",
    relatedTerms: ["dimensionsreduktion", "curse-of-dimensionality"],
    technicalDetails: {
      formula: "Kovarianzmatrix C = X'X / n ‚Üí Eigenwertzerlegung: Cv = Œªv",
      calculation: "1. Daten standardisieren ‚Üí 2. Kovarianzmatrix ‚Üí 3. Eigenwerte/-vektoren ‚Üí 4. Top-k Komponenten w√§hlen",
      interpretation: "Erkl√§rte Varianz: Œ£(Œª‚ÇÅ...Œª‚Çñ) / Œ£(alle Œª). Oft 95% Varianz als Ziel.",
      caveats: [
        "Immer vorher standardisieren!",
        "Komponenten sind Linearkombinationen ‚Äì schwer interpretierbar",
        "Alternative: t-SNE, UMAP (nicht-linear, f√ºr Visualisierung)",
        "Scree Plot: Eigenwerte plotten, Elbow finden",
      ],
    },
  },
  {
    id: "svm",
    name: "Support Vector Machine (SVM)",
    category: "algorithmen",
    shortDefinition: "Findet die Hyperebene, die Klassen mit maximalem Abstand trennt.",
    quickExample: "Maximiert den 'Sicherheitsabstand' zwischen den Klassen.",
    businessTranslation: "Trennlinie mit gr√∂√ütm√∂glichem Spielraum",
    fullExplanation: "SVM sucht die Trennebene mit maximaler Marge zu den n√§chsten Datenpunkten (Support Vectors). Der Kernel-Trick erm√∂glicht nicht-lineare Grenzen. Weniger popul√§r seit Deep Learning.",
    relatedTerms: ["decision-boundary", "normalisierung"],
    technicalDetails: {
      formula: "Maximiere Marge: 2 / ||w|| unter Nebenbedingung y·µ¢(w¬∑x·µ¢ + b) ‚â• 1",
      calculation: "Kernel-Trick: K(x,y) = œÜ(x)¬∑œÜ(y) ‚Äì Transformation ohne explizite Berechnung",
      interpretation: "Support Vectors = Datenpunkte auf der Marge (bestimmen die Grenze)",
      caveats: [
        "Kernels: Linear, RBF (Gaussian), Polynomial",
        "C-Parameter: Trade-off Marge vs. Fehlklassifikation",
        "Braucht Normalisierung!",
        "Langsam bei gro√üen Datens√§tzen (O(n¬≤) bis O(n¬≥))",
      ],
    },
  },

  // === KLASSIFIKATION (Erg√§nzung) ===
  {
    id: "binaere-klassifikation",
    name: "Bin√§re Klassifikation",
    category: "klassifikation",
    shortDefinition: "Klassifikation mit genau zwei m√∂glichen Klassen.",
    quickExample: "Spam/Kein Spam, Krebs/Kein Krebs, Ja/Nein.",
    businessTranslation: "Entweder-oder-Entscheidung",
    fullExplanation: "Die h√§ufigste Form der Klassifikation. Eine Klasse ist typischerweise die 'positive' (interessante), die andere die 'negative'. Confusion Matrix und Precision/Recall beziehen sich auf diese Unterscheidung.",
    relatedTerms: ["multi-class", "logistische-regression", "confusion-matrix"],
    technicalDetails: {
      calculation: "Modell gibt Wahrscheinlichkeit P(y=1|x) aus ‚Üí Threshold (z.B. 0.5) ‚Üí Klasse",
      interpretation: "Positiv = interessante/seltene Klasse (Betrug, Krankheit). Negativ = Normalfall.",
      caveats: [
        "Threshold verschieben = Trade-off Precision/Recall",
        "Sigmoid f√ºr Wahrscheinlichkeiten",
        "Confusion Matrix: TP, FP, TN, FN",
        "Class Imbalance beachten!",
      ],
    },
  },
  {
    id: "multi-class",
    name: "Multi-Class Klassifikation",
    category: "klassifikation",
    shortDefinition: "Klassifikation mit mehr als zwei m√∂glichen Klassen.",
    quickExample: "Bildklassifikation: Katze/Hund/Vogel/Fisch.",
    businessTranslation: "Eine von vielen Kategorien w√§hlen",
    fullExplanation: "Bei Multi-Class wird genau eine Klasse aus mehreren zugeordnet. Softmax gibt Wahrscheinlichkeiten f√ºr jede Klasse aus. Metriken werden oft pro Klasse oder gewichtet gemittelt berechnet.",
    relatedTerms: ["binaere-klassifikation", "softmax"],
    technicalDetails: {
      calculation: "Strategien: One-vs-Rest (OvR), One-vs-One (OvO), native Multi-Class (Softmax)",
      interpretation: "OvR: k bin√§re Klassifikatoren. OvO: k(k-1)/2 Klassifikatoren.",
      caveats: [
        "Softmax: Direkte Multi-Class-Wahrscheinlichkeiten",
        "Metriken: Macro (Durchschnitt √ºber Klassen) vs. Micro (√ºber alle Samples)",
        "Weighted: Gewichtet nach Klassengr√∂√üe",
        "Confusion Matrix wird k√ók",
      ],
    },
  },
  {
    id: "specificity",
    name: "Specificity (Spezifit√§t)",
    category: "klassifikation",
    shortDefinition: "Wie viele der tats√§chlich negativen F√§lle wurden korrekt als negativ erkannt?",
    quickExample: "Von 100 gesunden Patienten werden 95 korrekt als gesund klassifiziert.",
    businessTranslation: "Wie gut erkennt das Modell 'Nein'-F√§lle?",
    fullExplanation: "Specificity = TN / (TN + FP). Das Gegenst√ºck zu Recall (Sensitivity). Hohe Specificity bedeutet wenige False Positives. Wichtig, wenn Fehlalarme vermieden werden sollen.",
    relatedTerms: ["recall", "precision", "confusion-matrix"],
    tip: "Andere Namen: True Negative Rate (TNR).",
    technicalDetails: {
      formula: "Specificity = TN / (TN + FP) = 1 - FPR",
      interpretation: "Anteil der korrekt als negativ erkannten F√§lle. Gegenst√ºck zu Recall (Sensitivity).",
      caveats: [
        "Specificity + FPR = 1",
        "Recall (Sensitivity) + FNR = 1",
        "Hohe Specificity = wenige Fehlalarme",
        "ROC-Kurve: Sensitivity vs. 1-Specificity",
      ],
    },
  },
  {
    id: "auc-roc",
    name: "AUC-ROC",
    category: "klassifikation",
    shortDefinition: "Fl√§che unter der ROC-Kurve. Misst Trennf√§higkeit √ºber alle Thresholds.",
    quickExample: "AUC = 0.85 bedeutet 85% korrekte Unterscheidung zwischen Klassen.",
    businessTranslation: "Wie gut unterscheidet das Modell generell?",
    fullExplanation: "Die ROC-Kurve zeigt True Positive Rate vs. False Positive Rate bei verschiedenen Thresholds. AUC fasst dies in einer Zahl zusammen. AUC = 0.5 ist Zufall, AUC = 1.0 perfekt.",
    detailedExample: {
      scenario: "Interpretation",
      explanation: "AUC = 0.5: Nicht besser als M√ºnzwurf. AUC 0.7-0.8: Akzeptabel. AUC 0.8-0.9: Gut. AUC > 0.9: Sehr gut.",
      numbers: "Wertebereich: 0.5 bis 1.0",
    },
    relatedTerms: ["threshold", "precision", "recall"],
    technicalDetails: {
      formula: "AUC = ‚à´ TPR d(FPR) = P(Score_positiv > Score_negativ)",
      calculation: "ROC: Plot TPR (y) vs. FPR (x) f√ºr alle Thresholds. AUC = Fl√§che darunter.",
      interpretation: "Wahrscheinlichkeit, dass ein zuf√§lliger positiver Fall h√∂her gerankt wird als ein negativer",
      caveats: [
        "AUC = 0.5: Zufall (Diagonale)",
        "AUC = 1.0: Perfekte Trennung",
        "Unabh√§ngig vom gew√§hlten Threshold",
        "Bei Class Imbalance: PR-AUC oft aussagekr√§ftiger",
      ],
    },
  },

  // === VALIDIERUNG (Erg√§nzung) ===
  {
    id: "train-test-split",
    name: "Train/Test Split",
    category: "validierung",
    shortDefinition: "Aufteilung der Daten in Trainings- und Test-Set um Generalisierung zu pr√ºfen.",
    quickExample: "80% Training, 20% Test ‚Äì Test-Daten NIEMALS f√ºr Training verwenden!",
    businessTranslation: "Daten aufteilen: Lernen und Pr√ºfen trennen",
    fullExplanation: "Das Modell lernt auf Trainingsdaten und wird auf separaten Testdaten bewertet. Das simuliert den Produktiveinsatz und zeigt, ob das Modell generalisiert oder nur auswendig lernt.",
    relatedTerms: ["cross-validation", "overfitting", "validation-set"],
    tip: "Goldene Regel: Das Test-Set darf das Modell erst am Ende sehen!",
    technicalDetails: {
      calculation: "Typische Splits: 70/30, 80/20, 90/10 (Train/Test)",
      interpretation: "Training: Modell lernt. Test: Finale, unabh√§ngige Bewertung.",
      caveats: [
        "Stratified Split: Klassenverteilung in beiden Sets gleich",
        "Bei Zeitreihen: Zeitliche Trennung (kein Shuffling!)",
        "Test-Set nie f√ºr Hyperparameter-Tuning nutzen",
        "Kleine Datens√§tze: Cross-Validation statt Split",
      ],
    },
  },
  {
    id: "validation-set",
    name: "Validation Set",
    category: "validierung",
    shortDefinition: "Zus√§tzliche Datenmenge f√ºr Hyperparameter-Tuning (zwischen Train und Test).",
    quickExample: "60% Train, 20% Validation, 20% Test.",
    businessTranslation: "Ein 'Probelauf'-Set vor dem echten Test",
    fullExplanation: "Das Validation Set wird f√ºr Hyperparameter-Tuning und Modellauswahl verwendet, ohne das Test-Set zu 'verbrauchen'. So bleibt der Test wirklich unabh√§ngig.",
    relatedTerms: ["train-test-split", "hyperparameter", "cross-validation"],
    technicalDetails: {
      calculation: "Typisch: 60% Train, 20% Validation, 20% Test",
      interpretation: "Train: Lernen. Validation: Hyperparameter optimieren. Test: Finale Bewertung.",
      caveats: [
        "Validation-Performance f√ºr Modellauswahl nutzen",
        "Test-Performance nur einmal am Ende messen",
        "Bei wenig Daten: k-Fold CV statt Hold-out Validation",
        "Early Stopping: Validation-Loss als Abbruchkriterium",
      ],
    },
  },
  {
    id: "k-fold-cv",
    name: "k-Fold Cross-Validation",
    category: "validierung",
    shortDefinition: "Daten werden in k gleiche Teile geteilt, k Trainingsl√§ufe durchgef√ºhrt.",
    quickExample: "5-Fold: 5 Durchl√§ufe, jeder Teil ist einmal Test-Set.",
    businessTranslation: "Jeder Datenpunkt wird einmal getestet",
    fullExplanation: "Cross-Validation ist robuster als ein einzelner Split. Die Daten werden in k Folds aufgeteilt, k Modelle werden trainiert (jedes mit einem anderen Fold als Test). Das Ergebnis ist der Durchschnitt.",
    relatedTerms: ["cross-validation", "train-test-split"],
    technicalDetails: {
      formula: "CV-Score = (1/k) √ó Œ£ Score_i",
      calculation: "k Durchl√§ufe: Jeder Fold ist einmal Test-Set, restliche k-1 sind Training",
      interpretation: "Durchschnitt und Standardabweichung √ºber k Folds ‚Üí robustere Sch√§tzung",
      caveats: [
        "Typisch: k = 5 oder k = 10",
        "Stratified k-Fold: Klassenverteilung in jedem Fold gleich",
        "Leave-One-Out (LOO): k = n (teuer, aber minimal Bias)",
        "Bei Zeitreihen: TimeSeriesSplit statt k-Fold",
      ],
    },
  },
  {
    id: "underfitting",
    name: "Underfitting",
    category: "validierung",
    shortDefinition: "Modell ist zu einfach und erfasst die Muster in den Daten nicht.",
    quickExample: "Sowohl Training- als auch Test-Performance sind schlecht.",
    businessTranslation: "Das Modell lernt zu wenig",
    fullExplanation: "Underfitting tritt auf, wenn das Modell zu einfach ist, um die Zusammenh√§nge zu erfassen. L√∂sung: Komplexeres Modell, mehr Features, weniger Regularisierung.",
    relatedTerms: ["overfitting", "bias-variance-tradeoff"],
    technicalDetails: {
      interpretation: "Training-Accuracy niedrig UND Test-Accuracy niedrig ‚Üí Underfitting (hohes Bias)",
      caveats: [
        "Ursache: Modell zu einfach f√ºr die Daten",
        "L√∂sung: Komplexeres Modell (mehr Parameter, tiefere Netze)",
        "Mehr oder bessere Features hinzuf√ºgen",
        "Regularisierung reduzieren (Œª kleiner)",
      ],
    },
  },
  {
    id: "bias-variance-tradeoff",
    name: "Bias-Variance Trade-off",
    category: "validierung",
    shortDefinition: "Balance zwischen Modell-Einfachheit (Bias) und Flexibilit√§t (Variance).",
    quickExample: "Zu einfach = Underfitting (Bias), zu komplex = Overfitting (Variance).",
    businessTranslation: "Die goldene Mitte zwischen zu simpel und zu komplex",
    fullExplanation: "Hoher Bias bedeutet systematische Fehler (Underfitting), hohe Variance bedeutet Empfindlichkeit gegen√ºber Trainingsdaten (Overfitting). Das Ziel ist der optimale Punkt mit niedrigstem Gesamtfehler.",
    relatedTerms: ["overfitting", "underfitting", "regularisierung"],
    technicalDetails: {
      formula: "Gesamtfehler = Bias¬≤ + Variance + Irreduzibler Fehler",
      interpretation: "Bias: Systematischer Fehler (Modell zu einfach). Variance: Zuf√§lliger Fehler (Modell zu komplex).",
      caveats: [
        "Hohes Bias ‚Üí Underfitting: Train und Test beide schlecht",
        "Hohe Variance ‚Üí Overfitting: Train gut, Test schlecht",
        "Optimum: Minimaler Gesamtfehler (Bias und Variance balanciert)",
        "Regularisierung erh√∂ht Bias, senkt Variance",
      ],
    },
  },
  {
    id: "generalisierung",
    name: "Generalisierung",
    category: "validierung",
    shortDefinition: "F√§higkeit des Modells, auf neuen, ungesehenen Daten gut zu performen.",
    quickExample: "Gute Generalisierung: Test-Accuracy √§hnlich wie Train-Accuracy.",
    businessTranslation: "Das Modell funktioniert auch mit neuen Daten",
    fullExplanation: "Generalisierung ist das Hauptziel des ML: Das Modell soll nicht nur Trainingsdaten auswendig lernen, sondern √ºbertragbare Muster erkennen, die auch auf neue Daten zutreffen.",
    relatedTerms: ["overfitting", "cross-validation", "train-test-split"],
    technicalDetails: {
      formula: "Generalisierungsfehler = E[(y - ≈∑)¬≤] auf ungesehenen Daten",
      interpretation: "Gute Generalisierung: Train-Performance ‚âà Test-Performance",
      caveats: [
        "Test-Set simuliert ungesehene Produktionsdaten",
        "Generalisierung ‚â† Auswendiglernen",
        "Cross-Validation f√ºr robuste Sch√§tzung",
        "Drift kann Generalisierung √ºber Zeit verschlechtern",
      ],
    },
  },
  {
    id: "regularisierung",
    name: "Regularisierung",
    category: "validierung",
    shortDefinition: "Technik um Overfitting zu reduzieren durch Bestrafung komplexer Modelle.",
    quickExample: "L1 (Lasso) kann Features auf 0 setzen, L2 (Ridge) schrumpft sie.",
    businessTranslation: "Komplexit√§t wird 'bestraft'",
    fullExplanation: "Regularisierung f√ºgt einen Strafterm zur Verlustfunktion hinzu, der gro√üe Gewichte bestraft. L1 f√ºhrt zu sparseren Modellen (Feature Selection), L2 zu kleineren, aber nicht null-Gewichten.",
    relatedTerms: ["overfitting", "feature-selection"],
    technicalDetails: {
      formula: "L1 (Lasso): Œª √ó Œ£|Œ≤·µ¢| | L2 (Ridge): Œª √ó Œ£Œ≤·µ¢¬≤",
      calculation: "Loss_reg = Loss + Regularisierungsterm. Œª steuert St√§rke.",
      interpretation: "H√∂heres Œª = st√§rkere Regularisierung = einfacheres Modell (mehr Bias, weniger Variance)",
      caveats: [
        "L1 setzt Koeffizienten auf exakt 0 ‚Üí Feature Selection",
        "L2 schrumpft alle Koeffizienten, aber nie auf 0",
        "Elastic Net = Œ± √ó L1 + (1-Œ±) √ó L2 kombiniert",
        "Œª via Cross-Validation optimieren",
      ],
    },
  },
];

// Business-Fragen
export const businessQuestions: BusinessQuestion[] = [
  {
    id: "wie-genau",
    question: "Wie genau ist das Modell?",
    category: "genauigkeit",
    dsAnswer: "Das h√§ngt davon ab, was wir unter 'genau' verstehen ‚Äì und welche Fehler teurer sind.",
    explanation: "Genauigkeit kann verschiedenes bedeuten: Accuracy (Gesamttrefferquote), Precision (Zuverl√§ssigkeit positiver Vorhersagen) oder Recall (Vollst√§ndigkeit). Je nach Business-Kontext ist eine andere Metrik relevant. Bei Betrugserkennung ist Recall wichtiger (nichts √ºbersehen), bei Marketing-Kampagnen oft Precision (kein Budget verschwenden).",
    relatedTerms: ["accuracy", "precision", "recall", "f1-score"],
  },
  {
    id: "warum-nicht-95",
    question: "Warum nicht 95% Accuracy?",
    category: "genauigkeit",
    dsAnswer: "95% klingt gut, aber bei seltenen Ereignissen kann das irref√ºhrend sein.",
    explanation: "Wenn nur 5% der Kunden abwandern, erreicht ein Modell, das 'niemand wandert ab' vorhersagt, 95% Accuracy ‚Äì ohne echten Nutzen. Relevanter sind hier Precision (wie viele der vorhergesagten Abwanderer wandern wirklich ab?) und Recall (wie viele echte Abwanderer finden wir?). Die richtige Metrik h√§ngt vom Business Case ab.",
    relatedTerms: ["accuracy", "baseline", "precision", "recall"],
  },
  {
    id: "vertrauen",
    question: "K√∂nnen wir dem Modell vertrauen?",
    category: "vertrauen",
    dsAnswer: "Vertrauen entsteht durch Transparenz, Tests und kontinuierliche √úberwachung.",
    explanation: "Wir zeigen Feature Importance (welche Faktoren beeinflussen die Entscheidung?), validieren mit Fachexperten (macht das Sinn?), testen auf verschiedenen Datens√§tzen (ist es robust?) und √ºberwachen in Produktion (bleibt es gut?). A/B-Tests zeigen den echten Business-Impact. Modelle sollten nie blind vertraut werden.",
    relatedTerms: ["feature-importance", "cross-validation", "ab-test", "drift"],
  },
  {
    id: "aktualisierung",
    question: "Wann muss das Modell aktualisiert werden?",
    category: "betrieb",
    dsAnswer: "Wenn sich die Performance verschlechtert oder die Umwelt signifikant √§ndert.",
    explanation: "Wir √ºberwachen kontinuierlich auf Drift (Performance-Abfall). Typische Trigger: Accuracy f√§llt unter Schwellenwert, signifikante Marktver√§nderungen, neue Datenquellen verf√ºgbar, √Ñnderungen in Gesch√§ftsprozessen. Regelm√§√üige Retraining-Zyklen (z.B. quartalsweise) sind oft sinnvoll, selbst ohne sichtbaren Drift.",
    relatedTerms: ["drift", "training", "ab-test"],
  },
  {
    id: "daten",
    question: "Warum brauchen wir so viele Daten?",
    category: "betrieb",
    dsAnswer: "Mehr relevante Daten = bessere Mustererkennung und robustere Vorhersagen.",
    explanation: "ML-Modelle lernen Muster aus Daten. Bei wenigen Daten k√∂nnen zuf√§llige Zusammenh√§nge f√§lschlicherweise als Muster erkannt werden (Overfitting). Mehr Daten erm√∂glichen: robustere Muster, bessere Generalisierung auf neue F√§lle, zuverl√§ssigere Performance-Sch√§tzungen. Aber: Datenqualit√§t ist wichtiger als Quantit√§t!",
    relatedTerms: ["training", "overfitting", "feature"],
  },
  {
    id: "fehler",
    question: "Was passiert, wenn das Modell falsch liegt?",
    category: "risiken",
    dsAnswer: "Es gibt zwei Arten von Fehlern ‚Äì mit unterschiedlichen Konsequenzen.",
    explanation: "False Positives (Fehlalarme) verursachen unn√∂tige Aktionen: blockierte Transaktionen, unn√∂tige Anrufe. False Negatives (verpasste F√§lle) bedeuten verpasste Chancen oder Risiken: nicht erkannter Betrug, verpasste Verkaufschance. Die Kosten-Abw√§gung bestimmt, welchen Fehler wir minimieren. Der Threshold steuert diese Balance.",
    relatedTerms: ["false-positive", "false-negative", "threshold", "confusion-matrix"],
  },
  {
    id: "fairness",
    question: "Ist das Modell fair/unvoreingenommen?",
    category: "vertrauen",
    dsAnswer: "Fairness muss aktiv gepr√ºft und sichergestellt werden.",
    explanation: "Modelle k√∂nnen Vorurteile aus historischen Daten lernen (z.B. wenn historisch bestimmte Gruppen benachteiligt wurden). Wir pr√ºfen: Sind die Ergebnisse f√ºr verschiedene Gruppen √§hnlich? Nutzen wir sensible Attribute direkt oder indirekt? Gibt es rechtliche Vorgaben? Fairness ist keine technische Metrik, sondern eine Business-Entscheidung.",
    relatedTerms: ["feature", "feature-importance", "training"],
  },
  {
    id: "timeline",
    question: "Wie schnell k√∂nnen wir das Modell nutzen?",
    category: "betrieb",
    dsAnswer: "Es h√§ngt von Datenqualit√§t, Komplexit√§t und Integration ab.",
    explanation: "Typische Timeline: 2-4 Wochen f√ºr Proof-of-Concept, 2-3 Monate f√ºr produktionsreifes Modell, plus Integrationszeit. Hauptfaktoren: Datenqualit√§t und -verf√ºgbarkeit (oft der Engpass), Komplexit√§t des Problems, IT-Integrationsaufwand, Testzyklen. Schnelle Prototypen sind m√∂glich, robuste Produktion braucht Zeit.",
    relatedTerms: ["training", "feature", "ab-test"],
  },
  {
    id: "kosten",
    question: "Was kostet es, das Modell zu betreiben?",
    category: "betrieb",
    dsAnswer: "Neben IT-Kosten fallen vor allem Wartungs- und √úberwachungsaufw√§nde an.",
    explanation: "Laufende Kosten: Infrastruktur (Cloud-Computing, Speicher), Monitoring (Performance-√úberwachung, Alerting), Wartung (Bug-Fixes, Anpassungen), Retraining (regelm√§√üige Updates), Personal (Data Scientists f√ºr Pflege). Die gr√∂√üten Kosten entstehen oft durch fehlende Automatisierung und manuelle Interventionen.",
    relatedTerms: ["drift", "training", "ab-test"],
  },
  {
    id: "erklaerung",
    question: "Wie erkl√§ren wir Kunden die Entscheidung?",
    category: "vertrauen",
    dsAnswer: "Durch verst√§ndliche Hauptgr√ºnde, nicht durch technische Details.",
    explanation: "Feature Importance zeigt die wichtigsten Faktoren. F√ºr Kunden relevant: 'Die drei Hauptgr√ºnde f√ºr diese Entscheidung waren X, Y, Z.' Technische Details (Modelltyp, Hyperparameter) sind meist irrelevant. Bei regulierten Bereichen: Dokumentation der Entscheidungslogik. SHAP-Werte k√∂nnen individuelle Erkl√§rungen liefern.",
    relatedTerms: ["feature-importance", "feature"],
  },
];

// Hilfsfunktionen
export function searchTerms(query: string): Term[] {
  const normalizedQuery = query.toLowerCase().trim();
  if (!normalizedQuery) return terms;
  
  return terms.filter(
    (t) =>
      t.name.toLowerCase().includes(normalizedQuery) ||
      t.shortDefinition.toLowerCase().includes(normalizedQuery) ||
      t.businessTranslation?.toLowerCase().includes(normalizedQuery) ||
      t.relatedTerms?.some((rt) => rt.toLowerCase().includes(normalizedQuery))
  );
}

export function searchBusinessQuestions(query: string): BusinessQuestion[] {
  const normalizedQuery = query.toLowerCase().trim();
  if (!normalizedQuery) return businessQuestions;
  
  return businessQuestions.filter(
    (q) =>
      q.question.toLowerCase().includes(normalizedQuery) ||
      q.dsAnswer.toLowerCase().includes(normalizedQuery)
  );
}

export function getTermById(id: string): Term | undefined {
  return terms.find((t) => t.id === id);
}

export function getTermsByCategory(categoryId: string): Term[] {
  return terms.filter((t) => t.category === categoryId);
}

export function getQuestionsByCategory(categoryId: string): BusinessQuestion[] {
  return businessQuestions.filter((q) => q.category === categoryId);
}
